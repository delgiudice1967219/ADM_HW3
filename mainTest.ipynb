{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4E4cWhSzcIK9"
   },
   "source": [
    "# ADM-HW3: GROUP #14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Xavier Del Giudice, Alessio Iacono, Geraldine Maurer\n",
    "\n",
    "\n",
    "| STUDENT |   ID    |                 E-mail                  |\n",
    "| :-: |:-------:|:---------------------------------------:|\n",
    "| Xavier Del Giudice | 1967219 | delgiudice.1967219@studenti.uniroma1.it |\n",
    "| Alessio Iacono |   ...   |                   ...                   |\n",
    "| Geraldine Maurer |   ...   |                   ...                   |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T16:15:24.396001Z",
     "start_time": "2024-11-14T16:15:22.249848Z"
    }
   },
   "source": [
    "import heapq\n",
    "import os\n",
    "import re\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "import functions\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from unidecode import unidecode\n",
    "import string\n",
    "import unicodedata\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import pickle"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\xavie\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\xavie\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\xavie\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\xavie\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T17:48:16.539848Z",
     "start_time": "2024-11-10T17:48:06.445644Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "illQRCTCZg4v",
    "outputId": "45f1c85d-efd3-40f6-eebf-364c9b9493de"
   },
   "source": [
    "%pip install unidecode geopy plotly dash aiofiles aiohttp nltk ipywidgets requests bs4 pandas"
   ],
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T16:29:44.264271Z",
     "start_time": "2024-11-14T16:29:43.288137Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import heapq\n",
    "import os\n",
    "import re\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "import functions\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from unidecode import unidecode\n",
    "import string\n",
    "import unicodedata\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import pickle\n",
    "import ipywidgets\n",
    "import ipywidgets as ipw\n",
    "from itertools import chain\n",
    "import functions\n",
    "from IPython.display import display"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\xavie\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\xavie\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\xavie\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\xavie\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H4za-YIOXRhy"
   },
   "source": [
    "# 1. Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T17:50:12.229730Z",
     "start_time": "2024-11-10T17:49:27.992096Z"
    }
   },
   "source": [
    "base_url = \"https://guide.michelin.com/en/it/restaurants\"\n",
    "pages = 100\n",
    "functions.scrape_michelin_restaurants(base_url, pages)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T17:51:02.537557Z",
     "start_time": "2024-11-10T17:51:02.533544Z"
    }
   },
   "source": [
    "# Read and visualize the lines of the file\n",
    "with open(\"michelin_restaurant_urls.txt\", \"r\") as file:\n",
    "    urls = file.readlines()\n",
    "# Remove the empty spaces\n",
    "urls = [url.strip() for url in urls]\n",
    "print(f\"Total number of URL collected: {len(urls)}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T17:52:25.062835Z",
     "start_time": "2024-11-10T17:52:25.059087Z"
    }
   },
   "source": [
    "# Remope the duplicates\n",
    "unique_urls = list(set(urls))\n",
    "print(f\"Number of unique URL: {len(unique_urls)}\")\n",
    "# Filter the URLs that contains \"/restaurant/\"\n",
    "restaurant_urls = [url for url in unique_urls if \"/restaurant/\" in url]\n",
    "print(f\"Number of valid URLs: {len(restaurant_urls)}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T17:52:51.216799Z",
     "start_time": "2024-11-10T17:52:51.211289Z"
    }
   },
   "source": [
    "with open(\"michelin_restaurant_urls_cleaned.txt\", \"w\") as file:\n",
    "    for url in restaurant_urls:\n",
    "        file.write(url + \"\\n\")\n",
    "\n",
    "print(\"Cleaned file saved as 'michelin_restaurant_urls_cleaned.txt'\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T17:55:02.176945Z",
     "start_time": "2024-11-10T17:55:02.172437Z"
    }
   },
   "source": [
    "# Legge e visualizza le prime righe del file\n",
    "with open(\"michelin_restaurant_urls_cleaned.txt\", \"r\") as file:\n",
    "    urls = file.readlines()\n",
    "    \n",
    "# Rimuove gli spazi vuoti e visualizza un esempio di URL raccolti\n",
    "urls = [url.strip() for url in urls]\n",
    "print(f\"Total number of URL collected: {len(urls)}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T18:08:03.115094Z",
     "start_time": "2024-11-10T17:55:22.948998Z"
    }
   },
   "source": [
    "# Path with all the URLs\n",
    "file_path = \"C:/Users/xavie/Downloads/michelin_restaurant_urls_cleaned.txt\"\n",
    "\n",
    "functions.process_urls(file_path)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-13T10:16:10.024040Z",
     "start_time": "2024-11-13T10:14:43.073510Z"
    }
   },
   "source": [
    "import glob\n",
    "# Directory di base contenente tutte le cartelle di download\n",
    "base_dir = 'C:/Users/xavie/Documents/ADM_HW3'\n",
    "\n",
    "# Lista per memorizzare i dati di ogni ristorante\n",
    "restaurants_data = []\n",
    "\n",
    "# Iterazione su tutte le cartelle page_1, page_2, ..., page_100\n",
    "for page_num in range(1, 101):\n",
    "    folder_path = os.path.join(base_dir, f\"page_{page_num}\")\n",
    "    \n",
    "    # Trova tutti i file di testo che iniziano con \"html_\" nella cartella corrente\n",
    "    html_files = glob.glob(os.path.join(folder_path, \"html_*.txt\"))\n",
    "    print(html_files)\n",
    "    \n",
    "    for file_path in html_files:\n",
    "        restaurant_info = functions.extract_restaurant_info(file_path)\n",
    "        restaurants_data.append(restaurant_info)\n",
    "\n",
    "# Creazione del DataFrame Pandas\n",
    "df = pd.DataFrame(restaurants_data)\n",
    "\n",
    "output_file_path = \"C:/Users/xavie/Documents/ADM_HW3/restaurants_data.tsv\"\n",
    "df.to_csv(output_file_path, sep='\\t', index=False)\n",
    "print(f\"Data has been saved in {output_file_path}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wbUTH0t-UMUS"
   },
   "source": [
    "Create TXT with urls of each restaurant page (just let it run, usually 2 minutes to finish)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jWjzIJ4hUMUV",
    "outputId": "ddbcd81e-01c5-4aee-b499-4a398b4f1dea"
   },
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# URL di partenza\n",
    "base_url = 'https://guide.michelin.com/en/it/restaurants/page/'\n",
    "\n",
    "def scrape_restaurant_links():\n",
    "    print(\"I'm starting to Scrape!\")\n",
    "    page = 1\n",
    "    all_links = []\n",
    "\n",
    "    while True:\n",
    "        # Costruisci l'URL della pagina corrente\n",
    "        url = f\"{base_url}{page}\"\n",
    "        response = requests.get(url)\n",
    "\n",
    "        # Verifica che la richiesta sia andata a buon fine\n",
    "        if response.status_code != 200:\n",
    "            print(f\"Errore nel caricamento della pagina {page}\")\n",
    "            break\n",
    "\n",
    "        # Parsing della pagina HTML\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "        # Trova tutti i div con la classe specificata\n",
    "        for class1_div in soup.select(\"div.card__menu-content.card__menu-content--flex.js-match-height-content\"):\n",
    "            # Cerca il tag <h3> con classe specificata e il tag <a> figlio\n",
    "            h3 = class1_div.select_one(\"h3.card__menu-content--title.pl-text.pl-big.js-match-height-title a\")\n",
    "            if h3:\n",
    "                link = h3.get(\"href\")\n",
    "                full_link = \"https://guide.michelin.com\" + link if link else None\n",
    "                if full_link:\n",
    "                    all_links.append(full_link)\n",
    "\n",
    "        # Trova la sezione di paginazione\n",
    "        pagination_lis = soup.select(\"div.js-restaurant__bottom-pagination ul li\")\n",
    "\n",
    "        # Trova l'elemento <li> con la classe \"active\"\n",
    "        active_index = None\n",
    "        for i, li in enumerate(pagination_lis):\n",
    "            if li.select_one(\"a.active\"):\n",
    "                active_index = i\n",
    "                break\n",
    "\n",
    "        # Se c'è una pagina successiva, incrementa il numero di pagina\n",
    "        if active_index is not None and active_index + 1 < len(pagination_lis):\n",
    "            next_page = pagination_lis[active_index + 1].select_one(\"a\")\n",
    "            if next_page and next_page.get(\"href\"):\n",
    "                page += 1\n",
    "            else:\n",
    "                break\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    # Salva tutti i link dei ristoranti in un file\n",
    "    with open(\"soupUrls.txt\", \"w\") as file:\n",
    "        for link in all_links:\n",
    "            file.write(link + \"\\n\")\n",
    "\n",
    "    print(f\"Scraping completed. {len(all_links)} link saved in soupUrls.txt.\")\n",
    "\n",
    "# Avvia lo scraping\n",
    "scrape_restaurant_links()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kab5xGTzUMUY"
   },
   "source": [
    "Download each HTML page using .txt file just created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "BORgWhZlUMUZ",
    "outputId": "4b8a885c-a916-4454-b394-0608b3f810bc"
   },
   "source": [
    "#Scaricare html content da url\n",
    "\n",
    "import aiohttp\n",
    "import asyncio\n",
    "import aiofiles\n",
    "import os\n",
    "\n",
    "CONCURRENT_REQUESTS = 20  # Lowered to reduce load on the server\n",
    "\n",
    "async def load_urls(file_path):\n",
    "    async with aiofiles.open(file_path, 'r') as f:\n",
    "        urls = [line.strip() for line in await f.readlines()]\n",
    "    return urls\n",
    "\n",
    "async def download_url(session, url, output_dir):\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/86.0.4240.198 Safari/537.36',\n",
    "        'Referer': 'https://guide.michelin.com/',\n",
    "        'Accept-Language': 'en-US,en;q=0.9',\n",
    "    }\n",
    "    try:\n",
    "        async with session.get(url, headers=headers) as response:\n",
    "            if response.status == 200:\n",
    "                content = await response.text()\n",
    "                filename = f\"{output_dir}/{hash(url)}.html\"\n",
    "                async with aiofiles.open(filename, 'w') as f:\n",
    "                    await f.write(content)\n",
    "                print(f\"Downloaded: {url}\")\n",
    "            else:\n",
    "                print(f\"Failed to download {url}: Status {response.status}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading {url}: {e}\")\n",
    "\n",
    "async def download_all(urls, output_dir):\n",
    "    connector = aiohttp.TCPConnector(limit=CONCURRENT_REQUESTS)\n",
    "    async with aiohttp.ClientSession(connector=connector) as session:\n",
    "        tasks = [download_url(session, url, output_dir) for url in urls]\n",
    "        await asyncio.gather(*tasks)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    file_path = 'soupUrls.txt'\n",
    "    output_dir = 'downloads'\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    urls = await load_urls(file_path)\n",
    "    await download_all(urls, output_dir)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "swY8mI6HUMUa"
   },
   "source": [
    "Scrape each HTML page and create dataframe from data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "UIsD-WkjUMUa",
    "outputId": "a6f13703-8400-4a14-90f0-a592ffd8e7ff"
   },
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Directory containing the downloaded HTML files\n",
    "output_dir = 'downloads'\n",
    "\n",
    "# List to store restaurant data\n",
    "restaurants_data = []\n",
    "\n",
    "# Function to extract restaurant information from HTML\n",
    "def extract_restaurant_info(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        soup = BeautifulSoup(file, 'html.parser')\n",
    "\n",
    "        # Extract information using CSS selectors or HTML structure of the page\n",
    "        restaurant_info = {}\n",
    "\n",
    "        # Ricerca div contenente info principali\n",
    "        restaurantDetailsDiv = soup.find(\"div\", class_=\"restaurant-details__components\")\n",
    "\n",
    "        # Ottiene tutte le row contenenti: Nome del ristorante (row1),\n",
    "        # Indirizzo, prezzo e tipo cucina (row2), row 3 da scartare\n",
    "        mainInfo = restaurantDetailsDiv.select(\"div.data-sheet > div.row\")\n",
    "\n",
    "        if mainInfo[0]:\n",
    "            restaurant_info['restaurantName'] = mainInfo[0].find(\"h1\", class_=\"data-sheet__title\").text\n",
    "        if mainInfo[1]:\n",
    "            indirizzo_price = mainInfo[1].select(\"div.data-sheet__block > div.data-sheet__block--text\")\n",
    "\n",
    "            # Splitta la stringa contenente indirizzo, citta, CAP e nazione\n",
    "            indirizzoList = indirizzo_price[0].text.strip().split(\",\")\n",
    "\n",
    "            # Seleziona gli ultimi tre e li assegna a country, postalCode e city, tutto il resto verrà assegnato ad indirizzo\n",
    "            restaurant_info['city'] = indirizzoList[-3]\n",
    "            restaurant_info['postalCode'] = indirizzoList[-2]\n",
    "            restaurant_info['country'] = indirizzoList[-1]\n",
    "            restaurant_info['address'] = \" \".join(indirizzoList[:-3]).strip().replace(\"\\n\", \"\") # Unisce tutti gli elementi precedenti agli ultimi tre\n",
    "\n",
    "            # Split della riga contenente price e cuisineType info\n",
    "            restaurant_info['priceRange'], restaurant_info['cuisineType'] = indirizzo_price[1].text.strip().split(\"·\")\n",
    "\n",
    "            restaurant_info['priceRange'] = restaurant_info['priceRange'].strip()\n",
    "            # Possibili multiple cuisineType, dividi in lista\n",
    "            restaurant_info['cuisineType'] = restaurant_info['cuisineType'].strip().split(\",\")\n",
    "\n",
    "        # Description\n",
    "        restaurant_info['description'] = soup.find(\"div\", class_=\"data-sheet__description\").text.strip().replace(\"\\n\", \"\")\n",
    "\n",
    "        # Facilities and Services\n",
    "        facilities = soup.select(\"div.restaurant-details__services ul li\")\n",
    "        restaurant_info['facilitiesServices'] = [s.text.strip() for s in facilities]\n",
    "\n",
    "        # Accepted Credit Cards\n",
    "        credit_cards = soup.select(\"div.list--card img\")\n",
    "        restaurant_info['creditCards'] = [re.search(r\"(?<=\\/)[a-z]*(?=-)\", c.get(\"data-src\"))[0] for c in credit_cards]\n",
    "\n",
    "        # Phone Number\n",
    "        spansDetails = restaurantDetailsDiv.select(\"section.section.section-main.section__text-componets.section__text-separator div.collapse__block-title div.d-flex span\")\n",
    "        restaurant_info['phoneNumber'] = spansDetails[0].text.strip()\n",
    "\n",
    "        # URL\n",
    "        restaurant_info['website'] = soup.find(\"meta\", property=\"og:url\")[\"content\"]\n",
    "\n",
    "    return restaurant_info\n",
    "\n",
    "# Loop through all files in the directory and extract information\n",
    "for filename in os.listdir(output_dir):\n",
    "    if filename.endswith(\".html\"):\n",
    "        print(filename)\n",
    "        file_path = os.path.join(output_dir, filename)\n",
    "        restaurant_info = extract_restaurant_info(file_path)\n",
    "        restaurants_data.append(restaurant_info)\n",
    "\n",
    "# Create a pandas DataFrame\n",
    "df = pd.DataFrame(restaurants_data)\n",
    "\n",
    "# Save the data to a CSV file\n",
    "df.to_csv(\"restaurants_data.tsv\", sep='\\t', index=False)\n",
    "print(\"Data saved to restaurants_data.csv\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q1i9zzfhXXhb"
   },
   "source": [
    "# 2. Search Engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "utldng-rXa_9"
   },
   "source": [
    "## 2.0 Preprocessing"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The first step is to preprocess the restaurant descriptions. For this, we use the custom-made function ```preprocessing```, and save all pre-processed documents in a list of documents ```preprocessed_docs```."
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T16:29:46.509337Z",
     "start_time": "2024-11-14T16:29:46.488089Z"
    }
   },
   "cell_type": "code",
   "source": "df = pd.read_csv('restaurants_data.tsv', sep = '\\t')",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T16:29:47.598382Z",
     "start_time": "2024-11-14T16:29:47.581501Z"
    }
   },
   "cell_type": "code",
   "source": "df.head()",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                      restaurantName                      city  postalCode  \\\n",
       "0                               Arca  San Benedetto del Tronto       63074   \n",
       "1  Cannavacciuolo Le Cattedrali Asti                      Asti       14100   \n",
       "2                          Capriccio         Manerba del Garda       25080   \n",
       "3                   Cestello Firenze                  Florence       50124   \n",
       "4                       Corte Sconta                    Venice       30122   \n",
       "\n",
       "  country                                     address priceRange  \\\n",
       "0   Italy                      viale Rinascimento 137        €€€   \n",
       "1   Italy                    frazione Valleandona 1/b       €€€€   \n",
       "2   Italy  piazza San Bernardo 6  località Montinelle        €€€   \n",
       "3   Italy                        piazza di Cestello 8        €€€   \n",
       "4   Italy   calle del Pestrin  sestiere Castello 3886        €€€   \n",
       "\n",
       "                            cuisineType  \\\n",
       "0  Modern Cuisine, Cuisine from Abruzzo   \n",
       "1                              Creative   \n",
       "2               Modern Cuisine, Seafood   \n",
       "3                 Seafood, Contemporary   \n",
       "4                     Seafood, Venetian   \n",
       "\n",
       "                                         description  \\\n",
       "0  In business for over 20 years, Arca is definit...   \n",
       "1  Situated in the hills outside Asti, this moder...   \n",
       "2  This restaurant standing on the shores of Lake...   \n",
       "3  Situated in the beautiful piazza overlooked by...   \n",
       "4  From its flooring to its tables, this restaura...   \n",
       "\n",
       "                                  facilitiesServices  \\\n",
       "0  ['Air conditioning', 'Restaurant offering vege...   \n",
       "1  ['Air conditioning', 'Car park', 'Garden or pa...   \n",
       "2  ['Air conditioning', 'Car park', 'Great view',...   \n",
       "3                    ['Air conditioning', 'Terrace']   \n",
       "4                    ['Air conditioning', 'Terrace']   \n",
       "\n",
       "                                     creditCards        phoneNumber  \\\n",
       "0                 ['Amex', 'Mastercard', 'Visa']    +39 0735 488908   \n",
       "1   ['Amex', 'Dinersclub', 'Mastercard', 'Visa']  +39 0141 185 8888   \n",
       "2  ['Amex', 'Maestrocard', 'Mastercard', 'Visa']    +39 0365 551124   \n",
       "3   ['Amex', 'Dinersclub', 'Mastercard', 'Visa']   +39 055 264 5364   \n",
       "4                         ['Mastercard', 'Visa']   +39 041 522 7024   \n",
       "\n",
       "                           website  \n",
       "0   https://www.arcaristorante.it/  \n",
       "1    https://www.lecattedrali.com/  \n",
       "2  https://ristorantecapriccio.it/  \n",
       "3                              NaN  \n",
       "4    https://www.cortescontave.com  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>restaurantName</th>\n",
       "      <th>city</th>\n",
       "      <th>postalCode</th>\n",
       "      <th>country</th>\n",
       "      <th>address</th>\n",
       "      <th>priceRange</th>\n",
       "      <th>cuisineType</th>\n",
       "      <th>description</th>\n",
       "      <th>facilitiesServices</th>\n",
       "      <th>creditCards</th>\n",
       "      <th>phoneNumber</th>\n",
       "      <th>website</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Arca</td>\n",
       "      <td>San Benedetto del Tronto</td>\n",
       "      <td>63074</td>\n",
       "      <td>Italy</td>\n",
       "      <td>viale Rinascimento 137</td>\n",
       "      <td>€€€</td>\n",
       "      <td>Modern Cuisine, Cuisine from Abruzzo</td>\n",
       "      <td>In business for over 20 years, Arca is definit...</td>\n",
       "      <td>['Air conditioning', 'Restaurant offering vege...</td>\n",
       "      <td>['Amex', 'Mastercard', 'Visa']</td>\n",
       "      <td>+39 0735 488908</td>\n",
       "      <td>https://www.arcaristorante.it/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cannavacciuolo Le Cattedrali Asti</td>\n",
       "      <td>Asti</td>\n",
       "      <td>14100</td>\n",
       "      <td>Italy</td>\n",
       "      <td>frazione Valleandona 1/b</td>\n",
       "      <td>€€€€</td>\n",
       "      <td>Creative</td>\n",
       "      <td>Situated in the hills outside Asti, this moder...</td>\n",
       "      <td>['Air conditioning', 'Car park', 'Garden or pa...</td>\n",
       "      <td>['Amex', 'Dinersclub', 'Mastercard', 'Visa']</td>\n",
       "      <td>+39 0141 185 8888</td>\n",
       "      <td>https://www.lecattedrali.com/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Capriccio</td>\n",
       "      <td>Manerba del Garda</td>\n",
       "      <td>25080</td>\n",
       "      <td>Italy</td>\n",
       "      <td>piazza San Bernardo 6  località Montinelle</td>\n",
       "      <td>€€€</td>\n",
       "      <td>Modern Cuisine, Seafood</td>\n",
       "      <td>This restaurant standing on the shores of Lake...</td>\n",
       "      <td>['Air conditioning', 'Car park', 'Great view',...</td>\n",
       "      <td>['Amex', 'Maestrocard', 'Mastercard', 'Visa']</td>\n",
       "      <td>+39 0365 551124</td>\n",
       "      <td>https://ristorantecapriccio.it/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cestello Firenze</td>\n",
       "      <td>Florence</td>\n",
       "      <td>50124</td>\n",
       "      <td>Italy</td>\n",
       "      <td>piazza di Cestello 8</td>\n",
       "      <td>€€€</td>\n",
       "      <td>Seafood, Contemporary</td>\n",
       "      <td>Situated in the beautiful piazza overlooked by...</td>\n",
       "      <td>['Air conditioning', 'Terrace']</td>\n",
       "      <td>['Amex', 'Dinersclub', 'Mastercard', 'Visa']</td>\n",
       "      <td>+39 055 264 5364</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Corte Sconta</td>\n",
       "      <td>Venice</td>\n",
       "      <td>30122</td>\n",
       "      <td>Italy</td>\n",
       "      <td>calle del Pestrin  sestiere Castello 3886</td>\n",
       "      <td>€€€</td>\n",
       "      <td>Seafood, Venetian</td>\n",
       "      <td>From its flooring to its tables, this restaura...</td>\n",
       "      <td>['Air conditioning', 'Terrace']</td>\n",
       "      <td>['Mastercard', 'Visa']</td>\n",
       "      <td>+39 041 522 7024</td>\n",
       "      <td>https://www.cortescontave.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T16:29:51.084245Z",
     "start_time": "2024-11-14T16:29:49.269199Z"
    }
   },
   "cell_type": "code",
   "source": [
    "preprocessed_docs = defaultdict(list) # initialize defaultdict to store preprocessed docs\n",
    "for doc_id, doc in enumerate(df.description):\n",
    "  preprocessed_docs[doc_id] = functions.preprocessing(doc) # preprocess doc at position doc_id"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rRWQ7HxDX1oY",
    "outputId": "1a78081f-abe8-4cf5-f25d-c9b19976a6f9",
    "ExecuteTime": {
     "end_time": "2024-11-14T16:29:51.772466Z",
     "start_time": "2024-11-14T16:29:51.763224Z"
    }
   },
   "source": [
    "# Test description\n",
    "text = '''After many years' experience in Michelin-starred restaurants, Luigi Tramontano and his wife Nicoletta\n",
    "have opened their first restaurant in the chef's native Gargnano. Previously a pasta factory, the building has been converted\n",
    "into an elegant, contemporary-style restaurant which has nonetheless retained its charming high ceilings.\n",
    "The cuisine is inspired by regional traditions which are reinterpreted to create gourmet dishes,\n",
    "all prepared with respect for the ingredients used and a strong focus on local produce.'''\n",
    "\n",
    "# Test preprocessing on test description\n",
    "print(functions.preprocessing(text))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mani', 'year', 'experi', 'michelin', 'star', 'restaur', 'luigi', 'tramontano', 'wife', 'nicoletta', 'open', 'first', 'restaur', 'chef', 'nativ', 'gargnano', 'previous', 'pasta', 'factori', 'build', 'convert', 'eleg', 'contemporary', 'styl', 'restaur', 'nonetheless', 'retain', 'charm', 'high', 'ceil', 'cuisin', 'inspir', 'region', 'tradit', 'reinterpret', 'creat', 'gourmet', 'dish', 'prepar', 'respect', 'ingredi', 'use', 'strong', 'focu', 'local', 'produc']\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DO0y6xQyfcyJ"
   },
   "source": [
    "## 2.1 Conjunctive Query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "faZun-BPfgJm"
   },
   "source": [
    "### 2.1.1 Create your Index!"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "In the following code cells, we preprocess all restaurant descriptions and 1. save unique tokens in a DataFrame ```vocabulary_df``` that maps terms to unique integer IDs, then 2. compute the inverted index for the documents."
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "jCv8kfkcfnKl",
    "ExecuteTime": {
     "end_time": "2024-11-14T16:29:53.954989Z",
     "start_time": "2024-11-14T16:29:53.741671Z"
    }
   },
   "source": [
    "# 1. Vocabulary File\n",
    "\n",
    "# Retrieve the restaurants DataFrame\n",
    "df = pd.read_csv('restaurants_data.tsv', sep='\\t')\n",
    "\n",
    "doc_tokens = [] # initialize list to store all tokens\n",
    "\n",
    "# Find unique tokens\n",
    "for doc in preprocessed_docs.values():\n",
    "  doc_tokens.extend(doc)\n",
    "  doc_tokens = list(set(doc_tokens)) # remove duplicates\n",
    "\n",
    "vocabulary_dict = {term: i for i,term in enumerate(doc_tokens)} # dictionary of all vocabulary terms\n",
    "vocabulary_df = pd.DataFrame({'term': vocabulary_dict.keys(), 'term_id': vocabulary_dict.values()}) # dataframe that maps terms to IDs\n",
    "\n",
    "vocabulary_df.to_csv('vocabulary.csv', index=False) # save vocabulary dataframe in a csv file"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "QI3YYNZMhpC_",
    "ExecuteTime": {
     "end_time": "2024-11-14T16:29:55.509571Z",
     "start_time": "2024-11-14T16:29:55.424758Z"
    }
   },
   "source": [
    "# 2. Inverted Index\n",
    "\n",
    "inverted_index = defaultdict(list) # initialize inverted_index dictionary\n",
    "\n",
    "# Compute the inverted_index\n",
    "for doc_id, row in enumerate(df.description):\n",
    "  tokens = set(preprocessed_docs[doc_id]) # preprocessed description\n",
    "  for token in tokens: # eliminate duplicates\n",
    "    # Look up the term_id of the current term/token\n",
    "    term_id = vocabulary_dict[token]\n",
    "    # If the doc_id is not in the term_id's list in inverted_index, add it\n",
    "    if doc_id not in inverted_index[term_id]:\n",
    "      inverted_index[term_id].append(doc_id)\n",
    "\n",
    "# Save the inverted_index dictionary to a file\n",
    "with open(\"inverted_index.pkl\", \"wb\") as file:\n",
    "    pickle.dump(inverted_index, file)"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Next, we allow the user to input a query. After clicking on search, the first search engine will be triggered to retrieve all restaurants that contain in their description the same terms as the query."
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "mstIv_0qlqXw",
    "ExecuteTime": {
     "end_time": "2024-11-14T16:29:57.258370Z",
     "start_time": "2024-11-14T16:29:57.233693Z"
    }
   },
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "# re-load inverted index in case it was modified somewhere\n",
    "with open('inverted_index.pkl', 'rb') as file:\n",
    "    inverted_index = pickle.load(file)\n",
    "\n",
    "# Text input field for query\n",
    "text_input = widgets.Text(\n",
    "    value='',\n",
    "    placeholder='Type your query',\n",
    "    description='Query:',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "# Search button\n",
    "search_button = widgets.Button(\n",
    "    description='Search',\n",
    "    disabled=False,\n",
    "    button_style='primary'\n",
    ")\n",
    "\n",
    "output = widgets.Output()\n",
    "\n",
    "# Define a function to handle button press\n",
    "def on_search_button_clicked(b):\n",
    "    with output:\n",
    "        output.clear_output()  # clear previous output if there are any\n",
    "        query = text_input.value\n",
    "        if query.strip():  # Check if there's an input\n",
    "            display(functions.find_restaurants(query, vocabulary_df, inverted_index, df)) # display query results\n",
    "        else:\n",
    "            print(\"Please enter something to search for.\")\n",
    "\n",
    "# Link the function to the button\n",
    "search_button.on_click(on_search_button_clicked)\n",
    "\n",
    "# Display the widgets\n",
    "display(text_input, search_button, output)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(value='', description='Query:', placeholder='Type your query')"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5d7e3dbb08b34f8fa25c0d2f8afd7466"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Button(button_style='primary', description='Search', style=ButtonStyle())"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0d9177743a9c4f37b1e439474aa8b0a0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Output()"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6a7f355a202f48a1adc38dac5d88f997"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "92JOh6oFyPuz"
   },
   "source": [
    "## 2.2 Ranked Search Engine with TF-IDF and Cosine Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uXxrWEbzyVV2"
   },
   "source": [
    "### 2.2.1 Inverted Index with TF-IDF Scores"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "In the following exercise, we will first compute the inverted index with TF-IDF scores using the custom-made function ```tf_idf``` and save the ```updated_inverted_index``` in a pickle file."
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "id": "KNv23rrBWtxx",
    "ExecuteTime": {
     "end_time": "2024-11-14T16:30:13.000823Z",
     "start_time": "2024-11-14T16:30:12.788197Z"
    }
   },
   "source": [
    "# Preliminary steps\n",
    "n = len(preprocessed_docs)\n",
    "updated_inverted_index = defaultdict(list) # initialize default dictionary to store the inverted_index values with TF-IDF scores\n",
    "inverted_index_copy = inverted_index.copy() # Create a copy of the inverted_index to iterate over\n",
    "\n",
    "# Compute updated_inverted_index\n",
    "for term_id, docs in inverted_index_copy.items():\n",
    "  tf_idf_scores = functions.tf_idf(int(term_id), inverted_index, preprocessed_docs, vocabulary_df, n)\n",
    "  updated_inverted_index[term_id] = list(zip(docs, tf_idf_scores))\n",
    "\n",
    "with open('updated_inverted_index.pkl', 'wb') as file:\n",
    "    pickle.dump(updated_inverted_index, file)"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Next, we retrieve from ```updated_inverted_index``` the TF-IDF scores related to documents, and memorize only the tuples (term, tf-idf) where tf-idf != 0 for each document in a pickle file."
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "id": "rLbjRaqLS9bj",
    "ExecuteTime": {
     "end_time": "2024-11-14T16:30:14.192288Z",
     "start_time": "2024-11-14T16:30:14.068646Z"
    }
   },
   "source": [
    "# Compute the TF-IDF vectors of all documents and store them in a pickle file\n",
    "doc_tf_idf_scores = defaultdict(list) # initialize dictionary to store non-zero TF-IDF scores for each document\n",
    "\n",
    "for term_id, docs_scores in updated_inverted_index.items():\n",
    "  for doc_id, tf_idf_score in docs_scores:\n",
    "    if tf_idf_score != 0:\n",
    "      doc_tf_idf_scores[doc_id].append((term_id,tf_idf_score))\n",
    "  doc_tf_idf_scores[doc_id].sort(key=lambda x: x[0]) # sort the terms\n",
    "\n",
    "with open('doc_tf_idf_scores.pkl', 'wb') as file:\n",
    "    pickle.dump(doc_tf_idf_scores, file)"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Finally, we enable the user to input a text query, and return the top-k ranked restaurants by cosine similarity."
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "LXzqp1nkQ661",
    "ExecuteTime": {
     "end_time": "2024-11-14T16:30:40.948103Z",
     "start_time": "2024-11-14T16:30:40.925313Z"
    }
   },
   "source": [
    "# re-load inverted index in case it was modified somewhere\n",
    "with open('inverted_index.pkl', 'rb') as file:\n",
    "    inverted_index = pickle.load(file)\n",
    "\n",
    "# Text input field for query\n",
    "text_input = widgets.Text(\n",
    "    value='',\n",
    "    placeholder='Type your query',\n",
    "    description='Query:',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "# Search button\n",
    "search_button = widgets.Button(\n",
    "    description='Search',\n",
    "    disabled=False,\n",
    "    button_style='primary'\n",
    ")\n",
    "\n",
    "output = widgets.Output()\n",
    "\n",
    "# Define a function to handle button press\n",
    "def on_search_button_clicked(b):\n",
    "    with output:\n",
    "        output.clear_output()  # clear previous output if there are any\n",
    "        query = text_input.value\n",
    "        if query.strip():  # Check if there's an input\n",
    "            k = 10\n",
    "            display(functions.top_k_restaurants(query, inverted_index, vocabulary_dict, doc_tf_idf_scores, df, k, n)) # display query results\n",
    "        else:\n",
    "            print(\"Please enter something to search for.\")\n",
    "\n",
    "# Link the function to the button\n",
    "search_button.on_click(on_search_button_clicked)\n",
    "\n",
    "# Display the widgets\n",
    "display(text_input, search_button, output)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(value='', description='Query:', placeholder='Type your query')"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9f6b376b754442d7903a48dbdc6763d9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Button(button_style='primary', description='Search', style=ButtonStyle())"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6cc3167340904447bb7b40c57a5174a7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Output()"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "45c43e44ae404f598db479eebb3b7181"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Define a New Score!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A user interface(UI) is used to consider the user's additive information, which allows the user to enter the fields they prefer to find the restaurant.\n",
    "We will use this additional information to predicate some of the rows in our dataset.\n",
    "Since all restaurants are filtered by text initially, we want to give lower weight to the similarity between the description and the input query.  \n",
    "Rather we want to give higher weight to user input details, which are the key to finding restaurants to which a user can bring interest.\n",
    "Specifically we prefer to give higher weight to the type of cuisine, if I were to search for a restaurant and I have a particular desire to eat that cuisine I would want those as the pirmiest search results. Sucessively we give slightly less weight to the services available and finally the least weight to the price, speaking of Michelin restaurants the price is not an issue\n",
    "We can also find this behavior in very popular search engines, for example amazon search, prefers user-selected filters over the user's even detailed content in the search bar.\n",
    "\n",
    "The results in the end turn out to be better, more accurate. We also have to consider that in the previous Engine based on the cosine similarity we are just considering the score based on the similarity between the input query and the description which is way larger than a possible query. Instead now we are building our own custom score where we give more importance to the details, infact we havebigger score for the ones that perfectly fit thee search. We are basically considernig more fileds so its obvious that the results are more accurated. But there is also to note that at the computational level this type of search is less performant since we have to initially load all the restaurants that respect the query input and then create a new score based on matching the user input and finally sort to select only the first k."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T16:31:35.878679Z",
     "start_time": "2024-11-14T16:31:35.871334Z"
    }
   },
   "source": [
    "from search_restaurant_ui import SearchRestaurantUI"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T16:31:36.901677Z",
     "start_time": "2024-11-14T16:31:36.871653Z"
    }
   },
   "source": [
    "search_ui = SearchRestaurantUI(df, vocabulary_df, inverted_index)\n",
    "search_ui.display()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VBox(children=(Text(value='', description='Search:', placeholder='Insert your text...'), Dropdown(description=…"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "088eea58d1a940308cb29a60a8d6a79c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 4. Visualizing the Most Relevant Restaurants"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### 4.1 Geocode Locations"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In 4.1 we use geopy to get the coordinates of the restaurants and save them in the .tsv file. \n",
    "\n",
    "If some data of these restaurants is not found using geopy, their name, postal code and country are saved in a second file \"noDataRest.tsv\" to be used in any (possible) subsequent processing to recover the missing data of these restaurants."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T16:32:31.472419Z",
     "start_time": "2024-11-14T16:32:00.942978Z"
    }
   },
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "import glob\n",
    "\n",
    "# Directory where .html files are stored\n",
    "output_dir = 'C:/Users/xavie/Documents/ADM_HW3'\n",
    "\n",
    "# List to store restaurant data\n",
    "restaurants_data = []\n",
    "\n",
    "# Function to extract restaurant information from HTML\n",
    "def extract_restaurant_info(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        soup = BeautifulSoup(file, 'html.parser')\n",
    "\n",
    "        # Extract information using HTML structure of the page\n",
    "        restaurant_info = {}\n",
    "\n",
    "        script_tag = soup.find(\"script\", type=\"application/ld+json\")\n",
    "\n",
    "        if script_tag:\n",
    "            json_content = json.loads(script_tag.string)\n",
    "\n",
    "            restaurant_info['restaurantName'] = json_content['name']\n",
    "            restaurant_info['region'] = json_content['address']['addressRegion']\n",
    "            restaurant_info['latitude'] = json_content['latitude']\n",
    "            restaurant_info['longitude'] = json_content['longitude']\n",
    "\n",
    "    return restaurant_info\n",
    "\n",
    "# Loop through all files in the directory and extract information\n",
    "# Itera attraverso le pagine da 1 a 100\n",
    "for page_num in range(1, 101):\n",
    "    # Costruisci il percorso della cartella per ciascuna pagina\n",
    "    folder_path = os.path.join(output_dir, f\"page_{page_num}\")\n",
    "    \n",
    "    # Trova tutti i file di testo che iniziano con \"html_\" nella cartella corrente\n",
    "    html_files = glob.glob(os.path.join(folder_path, \"html_*.txt\"))\n",
    "    \n",
    "    # Itera attraverso i file trovati e processa ciascuno\n",
    "    for file_path in html_files:\n",
    "        print(file_path)\n",
    "        restaurant_info = extract_restaurant_info(file_path)\n",
    "        restaurants_data.append(restaurant_info)\n",
    "\n",
    "# Create a pandas DataFrame\n",
    "df = pd.DataFrame(restaurants_data)\n",
    "\n",
    "# Translation of italian region from english to italian\n",
    "translations = {\n",
    "    \"Aosta Valley\": \"Valle d'Aosta/Vallée d'Aoste\",\n",
    "    \"Piedmont\": \"Piemonte\",\n",
    "    \"Lombardy\": \"Lombardia\",\n",
    "    \"Sicily\": \"Sicilia\",\n",
    "    \"Tuscany\": \"Toscana\",\n",
    "    \"Apulia\": \"Puglia\",\n",
    "    \"Trentino-South Tyrol\": \"Trentino-Alto Adige/Südtirol\",\n",
    "    \"Sardinia\": \"Sardegna\"\n",
    "}\n",
    "df['region'] = df['region'].replace(translations) \n",
    "\n",
    "# Save the data to a CSV file\n",
    "df.to_csv(\"geodata.tsv\", sep='\\t', index=False)\n",
    "print(\"Data saved to restaurants_data.csv\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/xavie/Documents/ADM_HW3\\page_1\\html_arca.txt\n",
      "C:/Users/xavie/Documents/ADM_HW3\\page_1\\html_cannavacciuolo-le-cattedrali-asti.txt\n",
      "C:/Users/xavie/Documents/ADM_HW3\\page_1\\html_capriccio.txt\n",
      "C:/Users/xavie/Documents/ADM_HW3\\page_1\\html_cestello-ristoclub.txt\n",
      "C:/Users/xavie/Documents/ADM_HW3\\page_1\\html_corte-sconta.txt\n",
      "C:/Users/xavie/Documents/ADM_HW3\\page_1\\html_del-belbo-da-bardon.txt\n",
      "C:/Users/xavie/Documents/ADM_HW3\\page_1\\html_essentia.txt\n",
      "C:/Users/xavie/Documents/ADM_HW3\\page_1\\html_feria.txt\n",
      "C:/Users/xavie/Documents/ADM_HW3\\page_1\\html_filippino.txt\n",
      "C:/Users/xavie/Documents/ADM_HW3\\page_1\\html_gimmi-restaurant.txt\n",
      "C:/Users/xavie/Documents/ADM_HW3\\page_1\\html_la-coccinella.txt\n",
      "C:/Users/xavie/Documents/ADM_HW3\\page_1\\html_la-ferrata.txt\n",
      "C:/Users/xavie/Documents/ADM_HW3\\page_1\\html_la-gioconda.txt\n",
      "C:/Users/xavie/Documents/ADM_HW3\\page_1\\html_la-madia.txt\n",
      "C:/Users/xavie/Documents/ADM_HW3\\page_1\\html_la-torre153575.txt\n",
      "C:/Users/xavie/Documents/ADM_HW3\\page_1\\html_locanda-marchesani.txt\n",
      "C:/Users/xavie/Documents/ADM_HW3\\page_1\\html_makore.txt\n",
      "C:/Users/xavie/Documents/ADM_HW3\\page_1\\html_mezzolitro-vini-e-cucina.txt\n",
      "C:/Users/xavie/Documents/ADM_HW3\\page_1\\html_n-uovo-vino-e-cucina.txt\n",
      "C:/Users/xavie/Documents/ADM_HW3\\page_1\\html_osteria-dei-segreti.txt\n",
      "C:/Users/xavie/Documents/ADM_HW3\\page_1\\html_osteria-del-gran-fritto334900.txt\n",
      "C:/Users/xavie/Documents/ADM_HW3\\page_1\\html_osteria-la-sangiovesa.txt\n",
      "C:/Users/xavie/Documents/ADM_HW3\\page_1\\html_osteria-manzoni.txt\n",
      "C:/Users/xavie/Documents/ADM_HW3\\page_1\\html_osteria-ophis.txt\n",
      "C:/Users/xavie/Documents/ADM_HW3\\page_1\\html_pierre-trattoria-sartoriale.txt\n",
      "C:/Users/xavie/Documents/ADM_HW3\\page_1\\html_pinocchio.txt\n",
      "C:/Users/xavie/Documents/ADM_HW3\\page_1\\html_podere-san-faustino.txt\n",
      "C:/Users/xavie/Documents/ADM_HW3\\page_1\\html_porta-di-basso.txt\n",
      "C:/Users/xavie/Documents/ADM_HW3\\page_1\\html_sa-cardiga-e-su-schironi.txt\n",
      "C:/Users/xavie/Documents/ADM_HW3\\page_1\\html_sa-musciara.txt\n",
      "C:/Users/xavie/Documents/ADM_HW3\\page_1\\html_sala-dei-grappoli.txt\n",
      "C:/Users/xavie/Documents/ADM_HW3\\page_1\\html_sale-grosso384785.txt\n",
      "C:/Users/xavie/Documents/ADM_HW3\\page_1\\html_sapereta.txt\n",
      "C:/Users/xavie/Documents/ADM_HW3\\page_1\\html_savo.txt\n",
      "C:/Users/xavie/Documents/ADM_HW3\\page_1\\html_stefano-mocellin-al-padovanino.txt\n",
      "C:/Users/xavie/Documents/ADM_HW3\\page_1\\html_trattoria-al-pompiere.txt\n",
      "C:/Users/xavie/Documents/ADM_HW3\\page_1\\html_trattoria-da-lucio.txt\n",
      "C:/Users/xavie/Documents/ADM_HW3\\page_1\\html_trattoria-da-marino.txt\n",
      "C:/Users/xavie/Documents/ADM_HW3\\page_1\\html_trattoria-della-fortuna.txt\n",
      "C:/Users/xavie/Documents/ADM_HW3\\page_1\\html_zash.txt\n",
      "C:/Users/xavie/Documents/ADM_HW3\\page_2\\html_bel-ami.txt\n",
      "C:/Users/xavie/Documents/ADM_HW3\\page_2\\html_brindo-by-orlando.txt\n",
      "C:/Users/xavie/Documents/ADM_HW3\\page_2\\html_campocori.txt\n",
      "C:/Users/xavie/Documents/ADM_HW3\\page_2\\html_fre.txt\n",
      "C:/Users/xavie/Documents/ADM_HW3\\page_2\\html_giglio.txt\n",
      "C:/Users/xavie/Documents/ADM_HW3\\page_2\\html_gu-sta-re-oltrecucina.txt\n",
      "C:/Users/xavie/Documents/ADM_HW3\\page_2\\html_i-5-sensi.txt\n",
      "C:/Users/xavie/Documents/ADM_HW3\\page_2\\html_il-cavallino.txt\n",
      "C:/Users/xavie/Documents/ADM_HW3\\page_2\\html_il-convivio-troiani.txt\n",
      "C:/Users/xavie/Documents/ADM_HW3\\page_2\\html_il-galeone.txt\n",
      "C:/Users/xavie/Documents/ADM_HW3\\page_2\\html_il-ristorante-niko-romito-1209165.txt\n",
      "C:/Users/xavie/Documents/ADM_HW3\\page_2\\html_indigeno.txt\n",
      "C:/Users/xavie/Documents/ADM_HW3\\page_2\\html_l-osteria-del-castellazzo.txt\n",
      "C:/Users/xavie/Documents/ADM_HW3\\page_2\\html_la-ciotola.txt\n",
      "C:/Users/xavie/Documents/ADM_HW3\\page_2\\html_lu-pisantinu.txt\n",
      "C:/Users/xavie/Documents/ADM_HW3\\page_2\\html_materia.txt\n",
      "C:/Users/xavie/Documents/ADM_HW3\\page_2\\html_molin-vecio.txt\n",
      "C:/Users/xavie/Documents/ADM_HW3\\page_2\\html_paca.txt\n",
      "C:/Users/xavie/Documents/ADM_HW3\\page_2\\html_ps-ristorante-1192505.txt\n",
      "C:/Users/xavie/Documents/ADM_HW3\\page_2\\html_riccio-restaurant.txt\n",
      "C:/Users/xavie/Documents/ADM_HW3\\page_2\\html_saporium.txt\n",
      "C:/Users/xavie/Documents/ADM_HW3\\page_2\\html_w-villadorata-country-restaurant.txt\n",
      "C:/Users/xavie/Documents/ADM_HW3\\page_2\\html_walser-schtuba.txt\n",
      "C:/Users/xavie/Documents/ADM_HW3\\page_2\\html_zum-lowen.txt\n",
      "C:/Users/xavie/Documents/ADM_HW3\\page_3\\html_al-monastero.txt\n",
      "C:/Users/xavie/Documents/ADM_HW3\\page_3\\html_alessandro-feo.txt\n",
      "C:/Users/xavie/Documents/ADM_HW3\\page_3\\html_altatto-bistrot.txt\n",
      "C:/Users/xavie/Documents/ADM_HW3\\page_3\\html_cielo.txt\n",
      "C:/Users/xavie/Documents/ADM_HW3\\page_3\\html_da-peppe.txt\n",
      "C:/Users/xavie/Documents/ADM_HW3\\page_3\\html_da-tonino.txt\n",
      "C:/Users/xavie/Documents/ADM_HW3\\page_3\\html_de-minimi.txt\n",
      "C:/Users/xavie/Documents/ADM_HW3\\page_3\\html_fracia.txt\n",
      "C:/Users/xavie/Documents/ADM_HW3\\page_3\\html_gasthofstube-stafler.txt\n",
      "C:/Users/xavie/Documents/ADM_HW3\\page_3\\html_glicine.txt\n",
      "C:/Users/xavie/Documents/ADM_HW3\\page_3\\html_gune-san-frediano.txt\n",
      "C:/Users/xavie/Documents/ADM_HW3\\page_3\\html_il-faggio.txt\n",
      "C:/Users/xavie/Documents/ADM_HW3\\page_3\\html_l-insolita-trattoria-tre-soldi.txt\n",
      "C:/Users/xavie/Documents/ADM_HW3\\page_3\\html_la-terrazza160806.txt\n",
      "C:/Users/xavie/Documents/ADM_HW3\\page_3\\html_locanda-gulfi.txt\n",
      "C:/Users/xavie/Documents/ADM_HW3\\page_3\\html_nerina.txt\n",
      "C:/Users/xavie/Documents/ADM_HW3\\page_3\\html_olona-da-venanzio-dal-1922.txt\n",
      "C:/Users/xavie/Documents/ADM_HW3\\page_3\\html_ristorante-alpes-la-fuga.txt\n",
      "C:/Users/xavie/Documents/ADM_HW3\\page_3\\html_taverna-kerkira.txt\n",
      "C:/Users/xavie/Documents/ADM_HW3\\page_3\\html_villa-de-winckels.txt\n",
      "C:/Users/xavie/Documents/ADM_HW3\\page_4\\html_a-paranza.txt\n",
      "C:/Users/xavie/Documents/ADM_HW3\\page_4\\html_alle-codole.txt\n",
      "C:/Users/xavie/Documents/ADM_HW3\\page_4\\html_antica-moka.txt\n",
      "C:/Users/xavie/Documents/ADM_HW3\\page_4\\html_antico-ristorante-forassiepi.txt\n",
      "C:/Users/xavie/Documents/ADM_HW3\\page_4\\html_battaglino.txt\n",
      "C:/Users/xavie/Documents/ADM_HW3\\page_4\\html_boccon-divino.txt\n",
      "C:/Users/xavie/Documents/ADM_HW3\\page_4\\html_carlo-e-camillo.txt\n",
      "C:/Users/xavie/Documents/ADM_HW3\\page_4\\html_green-t.txt\n",
      "C:/Users/xavie/Documents/ADM_HW3\\page_4\\html_hosteria-giusti.txt\n",
      "C:/Users/xavie/Documents/ADM_HW3\\page_4\\html_il-basilisco.txt\n",
      "C:/Users/xavie/Documents/ADM_HW3\\page_4\\html_il-gusto-di-xinge.txt\n",
      "C:/Users/xavie/Documents/ADM_HW3\\page_4\\html_il-tiglio-di-piazza-da-nilo.txt\n",
      "C:/Users/xavie/Documents/ADM_HW3\\page_4\\html_kuppelrain.txt\n",
      "C:/Users/xavie/Documents/ADM_HW3\\page_4\\html_la-capanna-di-eraclio.txt\n",
      "C:/Users/xavie/Documents/ADM_HW3\\page_4\\html_locanda-pincelli.txt\n",
      "C:/Users/xavie/Documents/ADM_HW3\\page_4\\html_oishi-teramo.txt\n",
      "C:/Users/xavie/Documents/ADM_HW3\\page_4\\html_ortica.txt\n",
      "C:/Users/xavie/Documents/ADM_HW3\\page_4\\html_rifugio-col-alt.txt\n",
      "C:/Users/xavie/Documents/ADM_HW3\\page_4\\html_stube-ladina.txt\n",
      "C:/Users/xavie/Documents/ADM_HW3\\page_4\\html_vecio-macello.txt\n",
      "C:/Users/xavie/Documents/ADM_HW3\\page_5\\html_85-bistrot.txt\n",
      "C:/Users/xavie/Documents/ADM_HW3\\page_5\\html_antica-osteria-del-mare.txt\n",
      "C:/Users/xavie/Documents/ADM_HW3\\page_5\\html_antica-trattoria-giovanelli.txt\n",
      "C:/Users/xavie/Documents/ADM_HW3\\page_5\\html_anticofurlo.txt\n",
      "C:/Users/xavie/Documents/ADM_HW3\\page_5\\html_ca-7.txt\n",
      "C:/Users/xavie/Documents/ADM_HW3\\page_5\\html_da-politano.txt\n",
      "C:/Users/xavie/Documents/ADM_HW3\\page_5\\html_da-sapi.txt\n",
      "C:/Users/xavie/Documents/ADM_HW3\\page_5\\html_eea.txt\n",
      "C:/Users/xavie/Documents/ADM_HW3\\page_5\\html_estro-vino-e-cucina.txt\n",
      "C:/Users/xavie/Documents/ADM_HW3\\page_5\\html_il-fuoco-sacro.txt\n",
      "C:/Users/xavie/Documents/ADM_HW3\\page_5\\html_il-marin-eataly.txt\n",
      "C:/Users/xavie/Documents/ADM_HW3\\page_5\\html_il-pozzo.txt\n",
      "C:/Users/xavie/Documents/ADM_HW3\\page_5\\html_il-sottomarino.txt\n",
      "C:/Users/xavie/Documents/ADM_HW3\\page_5\\html_lido-84.txt\n",
      "C:/Users/xavie/Documents/ADM_HW3\\page_5\\html_locanda-san-michele.txt\n",
      "C:/Users/xavie/Documents/ADM_HW3\\page_5\\html_mildas.txt\n",
      "C:/Users/xavie/Documents/ADM_HW3\\page_5\\html_mima.txt\n",
      "C:/Users/xavie/Documents/ADM_HW3\\page_5\\html_osteria-la-fefa.txt\n",
      "C:/Users/xavie/Documents/ADM_HW3\\page_5\\html_stefenelli-desk.txt\n",
      "C:/Users/xavie/Documents/ADM_HW3\\page_5\\html_villa-maiella.txt\n",
      "C:/Users/xavie/Documents/ADM_HW3\\page_6\\html_alpenroyal-gourmet.txt\n",
      "C:/Users/xavie/Documents/ADM_HW3\\page_6\\html_antica-corte-pallavicina.txt\n",
      "C:/Users/xavie/Documents/ADM_HW3\\page_6\\html_atelier-moessmer-norbert-niederkofler.txt\n",
      "C:/Users/xavie/Documents/ADM_HW3\\page_6\\html_buca-di-bacco.txt\n",
      "C:/Users/xavie/Documents/ADM_HW3\\page_6\\html_camana-veglia.txt\n",
      "C:/Users/xavie/Documents/ADM_HW3\\page_6\\html_gusto-by-sadler.txt\n",
      "C:/Users/xavie/Documents/ADM_HW3\\page_6\\html_il-luogo-di-aimo-e-nadia.txt\n",
      "C:/Users/xavie/Documents/ADM_HW3\\page_6\\html_il-sereno-al-lago.txt\n",
      "C:/Users/xavie/Documents/ADM_HW3\\page_6\\html_l-arcade-1196110.txt\n",
      "C:/Users/xavie/Documents/ADM_HW3\\page_6\\html_le-macine.txt\n",
      "C:/Users/xavie/Documents/ADM_HW3\\page_6\\html_locanda-stella-d-oro.txt\n",
      "C:/Users/xavie/Documents/ADM_HW3\\page_6\\html_maso-runch-hof.txt\n",
      "C:/Users/xavie/Documents/ADM_HW3\\page_6\\html_osteria-numero-2.txt\n",
      "C:/Users/xavie/Documents/ADM_HW3\\page_6\\html_pellico-3.txt\n",
      "C:/Users/xavie/Documents/ADM_HW3\\page_6\\html_porcino.txt\n",
      "C:/Users/xavie/Documents/ADM_HW3\\page_6\\html_primo-restaurant.txt\n",
      "C:/Users/xavie/Documents/ADM_HW3\\page_6\\html_san-giorgio1077324.txt\n",
      "C:/Users/xavie/Documents/ADM_HW3\\page_6\\html_sensi536205.txt\n",
      "C:/Users/xavie/Documents/ADM_HW3\\page_6\\html_taverna-dell-oca.txt\n",
      "C:/Users/xavie/Documents/ADM_HW3\\page_6\\html_trattoria-lanzagallo.txt\n",
      "C:/Users/xavie/Documents/ADM_HW3\\page_7\\html_agora.txt\n",
      "C:/Users/xavie/Documents/ADM_HW3\\page_7\\html_al-gatto-rosso.txt\n",
      "C:/Users/xavie/Documents/ADM_HW3\\page_7\\html_bentoteca.txt\n",
      "C:/Users/xavie/Documents/ADM_HW3\\page_7\\html_caffetteria-la-fugascina.txt\n",
      "C:/Users/xavie/Documents/ADM_HW3\\page_7\\html_contrada-bricconi.txt\n",
      "C:/Users/xavie/Documents/ADM_HW3\\page_7\\html_dispensa-pani-e-vini-franciacorta.txt\n",
      "C:/Users/xavie/Documents/ADM_HW3\\page_7\\html_filia-ristorante.txt\n",
      "C:/Users/xavie/Documents/ADM_HW3\\page_7\\html_guido.txt\n",
      "C:/Users/xavie/Documents/ADM_HW3\\page_7\\html_hosteria-toblino.txt\n",
      "C:/Users/xavie/Documents/ADM_HW3\\page_7\\html_il-bikini.txt\n",
      "C:/Users/xavie/Documents/ADM_HW3\\page_7\\html_la-barca.txt\n",
      "C:/Users/xavie/Documents/ADM_HW3\\page_7\\html_la-notizia.txt\n",
      "C:/Users/xavie/Documents/ADM_HW3\\page_7\\html_la-porta-antica.txt\n",
      "C:/Users/xavie/Documents/ADM_HW3\\page_7\\html_la-porta-restaurant.txt\n",
      "C:/Users/xavie/Documents/ADM_HW3\\page_7\\html_locanda-del-pilone.txt\n",
      "C:/Users/xavie/Documents/ADM_HW3\\page_7\\html_radimare.txt\n",
      "C:/Users/xavie/Documents/ADM_HW3\\page_7\\html_risorgimento.txt\n",
      "C:/Users/xavie/Documents/ADM_HW3\\page_7\\html_serpillo.txt\n",
      "C:/Users/xavie/Documents/ADM_HW3\\page_7\\html_terrazza-tiberio.txt\n",
      "C:/Users/xavie/Documents/ADM_HW3\\page_7\\html_visione-restaurant-and-living.txt\n",
      "C:/Users/xavie/Documents/ADM_HW3\\page_8\\html_ad-astra.txt\n",
      "C:/Users/xavie/Documents/ADM_HW3\\page_8\\html_borgo-sant-anna.txt\n",
      "C:/Users/xavie/Documents/ADM_HW3\\page_8\\html_ca-matilde.txt\n",
      "C:/Users/xavie/Documents/ADM_HW3\\page_8\\html_il-falconiere.txt\n",
      "C:/Users/xavie/Documents/ADM_HW3\\page_8\\html_il-pavone.txt\n",
      "C:/Users/xavie/Documents/ADM_HW3\\page_8\\html_kro.txt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[15], line 45\u001B[0m\n\u001B[0;32m     43\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m file_path \u001B[38;5;129;01min\u001B[39;00m html_files:\n\u001B[0;32m     44\u001B[0m         \u001B[38;5;28mprint\u001B[39m(file_path)\n\u001B[1;32m---> 45\u001B[0m         restaurant_info \u001B[38;5;241m=\u001B[39m \u001B[43mextract_restaurant_info\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfile_path\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     46\u001B[0m         restaurants_data\u001B[38;5;241m.\u001B[39mappend(restaurant_info)\n\u001B[0;32m     48\u001B[0m \u001B[38;5;66;03m# Create a pandas DataFrame\u001B[39;00m\n",
      "Cell \u001B[1;32mIn[15], line 21\u001B[0m, in \u001B[0;36mextract_restaurant_info\u001B[1;34m(file_path)\u001B[0m\n\u001B[0;32m     18\u001B[0m \u001B[38;5;66;03m# Extract information using HTML structure of the page\u001B[39;00m\n\u001B[0;32m     19\u001B[0m restaurant_info \u001B[38;5;241m=\u001B[39m {}\n\u001B[1;32m---> 21\u001B[0m script_tag \u001B[38;5;241m=\u001B[39m \u001B[43msoup\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfind\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mscript\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mtype\u001B[39;49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mapplication/ld+json\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m     23\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m script_tag:\n\u001B[0;32m     24\u001B[0m     json_content \u001B[38;5;241m=\u001B[39m json\u001B[38;5;241m.\u001B[39mloads(script_tag\u001B[38;5;241m.\u001B[39mstring)\n",
      "File \u001B[1;32m~\\PycharmProjects\\FDS\\venv\\Lib\\site-packages\\bs4\\element.py:2006\u001B[0m, in \u001B[0;36mTag.find\u001B[1;34m(self, name, attrs, recursive, string, **kwargs)\u001B[0m\n\u001B[0;32m   1989\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Look in the children of this PageElement and find the first\u001B[39;00m\n\u001B[0;32m   1990\u001B[0m \u001B[38;5;124;03mPageElement that matches the given criteria.\u001B[39;00m\n\u001B[0;32m   1991\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   2003\u001B[0m \u001B[38;5;124;03m:rtype: bs4.element.Tag | bs4.element.NavigableString\u001B[39;00m\n\u001B[0;32m   2004\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   2005\u001B[0m r \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m-> 2006\u001B[0m l \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfind_all\u001B[49m\u001B[43m(\u001B[49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrecursive\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstring\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m_stacklevel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m3\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2007\u001B[0m \u001B[43m                  \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   2008\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m l:\n\u001B[0;32m   2009\u001B[0m     r \u001B[38;5;241m=\u001B[39m l[\u001B[38;5;241m0\u001B[39m]\n",
      "File \u001B[1;32m~\\PycharmProjects\\FDS\\venv\\Lib\\site-packages\\bs4\\element.py:2035\u001B[0m, in \u001B[0;36mTag.find_all\u001B[1;34m(self, name, attrs, recursive, string, limit, **kwargs)\u001B[0m\n\u001B[0;32m   2033\u001B[0m     generator \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mchildren\n\u001B[0;32m   2034\u001B[0m _stacklevel \u001B[38;5;241m=\u001B[39m kwargs\u001B[38;5;241m.\u001B[39mpop(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m_stacklevel\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;241m2\u001B[39m)\n\u001B[1;32m-> 2035\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_find_all\u001B[49m\u001B[43m(\u001B[49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstring\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlimit\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgenerator\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2036\u001B[0m \u001B[43m                      \u001B[49m\u001B[43m_stacklevel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m_stacklevel\u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\FDS\\venv\\Lib\\site-packages\\bs4\\element.py:841\u001B[0m, in \u001B[0;36mPageElement._find_all\u001B[1;34m(self, name, attrs, string, limit, generator, **kwargs)\u001B[0m\n\u001B[0;32m    839\u001B[0m     \u001B[38;5;28;01mbreak\u001B[39;00m\n\u001B[0;32m    840\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m i:\n\u001B[1;32m--> 841\u001B[0m     found \u001B[38;5;241m=\u001B[39m \u001B[43mstrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msearch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mi\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    842\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m found:\n\u001B[0;32m    843\u001B[0m         results\u001B[38;5;241m.\u001B[39mappend(found)\n",
      "File \u001B[1;32m~\\PycharmProjects\\FDS\\venv\\Lib\\site-packages\\bs4\\element.py:2315\u001B[0m, in \u001B[0;36mSoupStrainer.search\u001B[1;34m(self, markup)\u001B[0m\n\u001B[0;32m   2312\u001B[0m found \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   2313\u001B[0m \u001B[38;5;66;03m# If given a list of items, scan it for a text element that\u001B[39;00m\n\u001B[0;32m   2314\u001B[0m \u001B[38;5;66;03m# matches.\u001B[39;00m\n\u001B[1;32m-> 2315\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(markup, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m__iter__\u001B[39m\u001B[38;5;124m'\u001B[39m) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(markup, (Tag, \u001B[38;5;28mstr\u001B[39m)):\n\u001B[0;32m   2316\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m element \u001B[38;5;129;01min\u001B[39;00m markup:\n\u001B[0;32m   2317\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(element, NavigableString) \\\n\u001B[0;32m   2318\u001B[0m                \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msearch(element):\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T16:32:33.542093Z",
     "start_time": "2024-11-14T16:32:33.515525Z"
    }
   },
   "source": "df = pd.read_csv(\"restaurants_data.tsv\", sep='\\t')",
   "outputs": [],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T16:32:34.654729Z",
     "start_time": "2024-11-14T16:32:34.636369Z"
    }
   },
   "source": [
    "df.head()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                      restaurantName                      city  postalCode  \\\n",
       "0                               Arca  San Benedetto del Tronto       63074   \n",
       "1  Cannavacciuolo Le Cattedrali Asti                      Asti       14100   \n",
       "2                          Capriccio         Manerba del Garda       25080   \n",
       "3                   Cestello Firenze                  Florence       50124   \n",
       "4                       Corte Sconta                    Venice       30122   \n",
       "\n",
       "  country                                     address priceRange  \\\n",
       "0   Italy                      viale Rinascimento 137        €€€   \n",
       "1   Italy                    frazione Valleandona 1/b       €€€€   \n",
       "2   Italy  piazza San Bernardo 6  località Montinelle        €€€   \n",
       "3   Italy                        piazza di Cestello 8        €€€   \n",
       "4   Italy   calle del Pestrin  sestiere Castello 3886        €€€   \n",
       "\n",
       "                            cuisineType  \\\n",
       "0  Modern Cuisine, Cuisine from Abruzzo   \n",
       "1                              Creative   \n",
       "2               Modern Cuisine, Seafood   \n",
       "3                 Seafood, Contemporary   \n",
       "4                     Seafood, Venetian   \n",
       "\n",
       "                                         description  \\\n",
       "0  In business for over 20 years, Arca is definit...   \n",
       "1  Situated in the hills outside Asti, this moder...   \n",
       "2  This restaurant standing on the shores of Lake...   \n",
       "3  Situated in the beautiful piazza overlooked by...   \n",
       "4  From its flooring to its tables, this restaura...   \n",
       "\n",
       "                                  facilitiesServices  \\\n",
       "0  ['Air conditioning', 'Restaurant offering vege...   \n",
       "1  ['Air conditioning', 'Car park', 'Garden or pa...   \n",
       "2  ['Air conditioning', 'Car park', 'Great view',...   \n",
       "3                    ['Air conditioning', 'Terrace']   \n",
       "4                    ['Air conditioning', 'Terrace']   \n",
       "\n",
       "                                     creditCards        phoneNumber  \\\n",
       "0                 ['Amex', 'Mastercard', 'Visa']    +39 0735 488908   \n",
       "1   ['Amex', 'Dinersclub', 'Mastercard', 'Visa']  +39 0141 185 8888   \n",
       "2  ['Amex', 'Maestrocard', 'Mastercard', 'Visa']    +39 0365 551124   \n",
       "3   ['Amex', 'Dinersclub', 'Mastercard', 'Visa']   +39 055 264 5364   \n",
       "4                         ['Mastercard', 'Visa']   +39 041 522 7024   \n",
       "\n",
       "                           website  \n",
       "0   https://www.arcaristorante.it/  \n",
       "1    https://www.lecattedrali.com/  \n",
       "2  https://ristorantecapriccio.it/  \n",
       "3                              NaN  \n",
       "4    https://www.cortescontave.com  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>restaurantName</th>\n",
       "      <th>city</th>\n",
       "      <th>postalCode</th>\n",
       "      <th>country</th>\n",
       "      <th>address</th>\n",
       "      <th>priceRange</th>\n",
       "      <th>cuisineType</th>\n",
       "      <th>description</th>\n",
       "      <th>facilitiesServices</th>\n",
       "      <th>creditCards</th>\n",
       "      <th>phoneNumber</th>\n",
       "      <th>website</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Arca</td>\n",
       "      <td>San Benedetto del Tronto</td>\n",
       "      <td>63074</td>\n",
       "      <td>Italy</td>\n",
       "      <td>viale Rinascimento 137</td>\n",
       "      <td>€€€</td>\n",
       "      <td>Modern Cuisine, Cuisine from Abruzzo</td>\n",
       "      <td>In business for over 20 years, Arca is definit...</td>\n",
       "      <td>['Air conditioning', 'Restaurant offering vege...</td>\n",
       "      <td>['Amex', 'Mastercard', 'Visa']</td>\n",
       "      <td>+39 0735 488908</td>\n",
       "      <td>https://www.arcaristorante.it/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cannavacciuolo Le Cattedrali Asti</td>\n",
       "      <td>Asti</td>\n",
       "      <td>14100</td>\n",
       "      <td>Italy</td>\n",
       "      <td>frazione Valleandona 1/b</td>\n",
       "      <td>€€€€</td>\n",
       "      <td>Creative</td>\n",
       "      <td>Situated in the hills outside Asti, this moder...</td>\n",
       "      <td>['Air conditioning', 'Car park', 'Garden or pa...</td>\n",
       "      <td>['Amex', 'Dinersclub', 'Mastercard', 'Visa']</td>\n",
       "      <td>+39 0141 185 8888</td>\n",
       "      <td>https://www.lecattedrali.com/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Capriccio</td>\n",
       "      <td>Manerba del Garda</td>\n",
       "      <td>25080</td>\n",
       "      <td>Italy</td>\n",
       "      <td>piazza San Bernardo 6  località Montinelle</td>\n",
       "      <td>€€€</td>\n",
       "      <td>Modern Cuisine, Seafood</td>\n",
       "      <td>This restaurant standing on the shores of Lake...</td>\n",
       "      <td>['Air conditioning', 'Car park', 'Great view',...</td>\n",
       "      <td>['Amex', 'Maestrocard', 'Mastercard', 'Visa']</td>\n",
       "      <td>+39 0365 551124</td>\n",
       "      <td>https://ristorantecapriccio.it/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cestello Firenze</td>\n",
       "      <td>Florence</td>\n",
       "      <td>50124</td>\n",
       "      <td>Italy</td>\n",
       "      <td>piazza di Cestello 8</td>\n",
       "      <td>€€€</td>\n",
       "      <td>Seafood, Contemporary</td>\n",
       "      <td>Situated in the beautiful piazza overlooked by...</td>\n",
       "      <td>['Air conditioning', 'Terrace']</td>\n",
       "      <td>['Amex', 'Dinersclub', 'Mastercard', 'Visa']</td>\n",
       "      <td>+39 055 264 5364</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Corte Sconta</td>\n",
       "      <td>Venice</td>\n",
       "      <td>30122</td>\n",
       "      <td>Italy</td>\n",
       "      <td>calle del Pestrin  sestiere Castello 3886</td>\n",
       "      <td>€€€</td>\n",
       "      <td>Seafood, Venetian</td>\n",
       "      <td>From its flooring to its tables, this restaura...</td>\n",
       "      <td>['Air conditioning', 'Terrace']</td>\n",
       "      <td>['Mastercard', 'Visa']</td>\n",
       "      <td>+39 041 522 7024</td>\n",
       "      <td>https://www.cortescontave.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T16:32:35.995678Z",
     "start_time": "2024-11-14T16:32:35.989050Z"
    }
   },
   "source": [
    "df['restaurantId'] = range(1, len(df) + 1)\n",
    "\n",
    "df.head()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                      restaurantName                      city  postalCode  \\\n",
       "0                               Arca  San Benedetto del Tronto       63074   \n",
       "1  Cannavacciuolo Le Cattedrali Asti                      Asti       14100   \n",
       "2                          Capriccio         Manerba del Garda       25080   \n",
       "3                   Cestello Firenze                  Florence       50124   \n",
       "4                       Corte Sconta                    Venice       30122   \n",
       "\n",
       "  country                                     address priceRange  \\\n",
       "0   Italy                      viale Rinascimento 137        €€€   \n",
       "1   Italy                    frazione Valleandona 1/b       €€€€   \n",
       "2   Italy  piazza San Bernardo 6  località Montinelle        €€€   \n",
       "3   Italy                        piazza di Cestello 8        €€€   \n",
       "4   Italy   calle del Pestrin  sestiere Castello 3886        €€€   \n",
       "\n",
       "                            cuisineType  \\\n",
       "0  Modern Cuisine, Cuisine from Abruzzo   \n",
       "1                              Creative   \n",
       "2               Modern Cuisine, Seafood   \n",
       "3                 Seafood, Contemporary   \n",
       "4                     Seafood, Venetian   \n",
       "\n",
       "                                         description  \\\n",
       "0  In business for over 20 years, Arca is definit...   \n",
       "1  Situated in the hills outside Asti, this moder...   \n",
       "2  This restaurant standing on the shores of Lake...   \n",
       "3  Situated in the beautiful piazza overlooked by...   \n",
       "4  From its flooring to its tables, this restaura...   \n",
       "\n",
       "                                  facilitiesServices  \\\n",
       "0  ['Air conditioning', 'Restaurant offering vege...   \n",
       "1  ['Air conditioning', 'Car park', 'Garden or pa...   \n",
       "2  ['Air conditioning', 'Car park', 'Great view',...   \n",
       "3                    ['Air conditioning', 'Terrace']   \n",
       "4                    ['Air conditioning', 'Terrace']   \n",
       "\n",
       "                                     creditCards        phoneNumber  \\\n",
       "0                 ['Amex', 'Mastercard', 'Visa']    +39 0735 488908   \n",
       "1   ['Amex', 'Dinersclub', 'Mastercard', 'Visa']  +39 0141 185 8888   \n",
       "2  ['Amex', 'Maestrocard', 'Mastercard', 'Visa']    +39 0365 551124   \n",
       "3   ['Amex', 'Dinersclub', 'Mastercard', 'Visa']   +39 055 264 5364   \n",
       "4                         ['Mastercard', 'Visa']   +39 041 522 7024   \n",
       "\n",
       "                           website  restaurantId  \n",
       "0   https://www.arcaristorante.it/             1  \n",
       "1    https://www.lecattedrali.com/             2  \n",
       "2  https://ristorantecapriccio.it/             3  \n",
       "3                              NaN             4  \n",
       "4    https://www.cortescontave.com             5  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>restaurantName</th>\n",
       "      <th>city</th>\n",
       "      <th>postalCode</th>\n",
       "      <th>country</th>\n",
       "      <th>address</th>\n",
       "      <th>priceRange</th>\n",
       "      <th>cuisineType</th>\n",
       "      <th>description</th>\n",
       "      <th>facilitiesServices</th>\n",
       "      <th>creditCards</th>\n",
       "      <th>phoneNumber</th>\n",
       "      <th>website</th>\n",
       "      <th>restaurantId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Arca</td>\n",
       "      <td>San Benedetto del Tronto</td>\n",
       "      <td>63074</td>\n",
       "      <td>Italy</td>\n",
       "      <td>viale Rinascimento 137</td>\n",
       "      <td>€€€</td>\n",
       "      <td>Modern Cuisine, Cuisine from Abruzzo</td>\n",
       "      <td>In business for over 20 years, Arca is definit...</td>\n",
       "      <td>['Air conditioning', 'Restaurant offering vege...</td>\n",
       "      <td>['Amex', 'Mastercard', 'Visa']</td>\n",
       "      <td>+39 0735 488908</td>\n",
       "      <td>https://www.arcaristorante.it/</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cannavacciuolo Le Cattedrali Asti</td>\n",
       "      <td>Asti</td>\n",
       "      <td>14100</td>\n",
       "      <td>Italy</td>\n",
       "      <td>frazione Valleandona 1/b</td>\n",
       "      <td>€€€€</td>\n",
       "      <td>Creative</td>\n",
       "      <td>Situated in the hills outside Asti, this moder...</td>\n",
       "      <td>['Air conditioning', 'Car park', 'Garden or pa...</td>\n",
       "      <td>['Amex', 'Dinersclub', 'Mastercard', 'Visa']</td>\n",
       "      <td>+39 0141 185 8888</td>\n",
       "      <td>https://www.lecattedrali.com/</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Capriccio</td>\n",
       "      <td>Manerba del Garda</td>\n",
       "      <td>25080</td>\n",
       "      <td>Italy</td>\n",
       "      <td>piazza San Bernardo 6  località Montinelle</td>\n",
       "      <td>€€€</td>\n",
       "      <td>Modern Cuisine, Seafood</td>\n",
       "      <td>This restaurant standing on the shores of Lake...</td>\n",
       "      <td>['Air conditioning', 'Car park', 'Great view',...</td>\n",
       "      <td>['Amex', 'Maestrocard', 'Mastercard', 'Visa']</td>\n",
       "      <td>+39 0365 551124</td>\n",
       "      <td>https://ristorantecapriccio.it/</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cestello Firenze</td>\n",
       "      <td>Florence</td>\n",
       "      <td>50124</td>\n",
       "      <td>Italy</td>\n",
       "      <td>piazza di Cestello 8</td>\n",
       "      <td>€€€</td>\n",
       "      <td>Seafood, Contemporary</td>\n",
       "      <td>Situated in the beautiful piazza overlooked by...</td>\n",
       "      <td>['Air conditioning', 'Terrace']</td>\n",
       "      <td>['Amex', 'Dinersclub', 'Mastercard', 'Visa']</td>\n",
       "      <td>+39 055 264 5364</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Corte Sconta</td>\n",
       "      <td>Venice</td>\n",
       "      <td>30122</td>\n",
       "      <td>Italy</td>\n",
       "      <td>calle del Pestrin  sestiere Castello 3886</td>\n",
       "      <td>€€€</td>\n",
       "      <td>Seafood, Venetian</td>\n",
       "      <td>From its flooring to its tables, this restaura...</td>\n",
       "      <td>['Air conditioning', 'Terrace']</td>\n",
       "      <td>['Mastercard', 'Visa']</td>\n",
       "      <td>+39 041 522 7024</td>\n",
       "      <td>https://www.cortescontave.com</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T16:32:38.210495Z",
     "start_time": "2024-11-14T16:32:38.204440Z"
    }
   },
   "source": [
    "df.shape"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2006, 13)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T16:32:39.872977Z",
     "start_time": "2024-11-14T16:32:39.861512Z"
    }
   },
   "source": [
    "df_geo = pd.read_csv(\"geodata.tsv\", sep='\\t')\n",
    "df_geo['restaurantId'] = range(1, len(df) + 1)\n",
    "df_geo.head()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                      restaurantName     region   latitude  longitude  \\\n",
       "0                               Arca     Marche  42.926408  13.897645   \n",
       "1  Cannavacciuolo Le Cattedrali Asti   Piemonte  44.907837   8.117304   \n",
       "2                          Capriccio  Lombardia  45.552850  10.561210   \n",
       "3                   Cestello Firenze    Toscana  43.770306  11.243657   \n",
       "4                       Corte Sconta     Veneto  45.434791  12.347919   \n",
       "\n",
       "   restaurantId  \n",
       "0             1  \n",
       "1             2  \n",
       "2             3  \n",
       "3             4  \n",
       "4             5  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>restaurantName</th>\n",
       "      <th>region</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>restaurantId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Arca</td>\n",
       "      <td>Marche</td>\n",
       "      <td>42.926408</td>\n",
       "      <td>13.897645</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cannavacciuolo Le Cattedrali Asti</td>\n",
       "      <td>Piemonte</td>\n",
       "      <td>44.907837</td>\n",
       "      <td>8.117304</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Capriccio</td>\n",
       "      <td>Lombardia</td>\n",
       "      <td>45.552850</td>\n",
       "      <td>10.561210</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cestello Firenze</td>\n",
       "      <td>Toscana</td>\n",
       "      <td>43.770306</td>\n",
       "      <td>11.243657</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Corte Sconta</td>\n",
       "      <td>Veneto</td>\n",
       "      <td>45.434791</td>\n",
       "      <td>12.347919</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T16:32:41.734788Z",
     "start_time": "2024-11-14T16:32:41.727619Z"
    }
   },
   "source": [
    "df_geo.shape"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2006, 5)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T16:32:43.311379Z",
     "start_time": "2024-11-14T16:32:43.297007Z"
    }
   },
   "source": [
    "df_finale = pd.merge(df, df_geo, on='restaurantId')\n",
    "\n",
    "# Verifica le dimensioni e le prime righe\n",
    "print(df_finale.shape)  # Questo dovrebbe restituire (1962, 15)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2006, 17)\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T16:32:44.763266Z",
     "start_time": "2024-11-14T16:32:44.751231Z"
    }
   },
   "source": [
    "df_finale = df_finale.rename(columns={'restaurantName_x': 'restaurantName'})\n",
    "\n",
    "# Droppa la colonna 'restaurantName_y'\n",
    "df_finale = df_finale.drop(columns=['restaurantName_y'])"
   ],
   "outputs": [],
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T16:32:46.419071Z",
     "start_time": "2024-11-14T16:32:46.399782Z"
    }
   },
   "source": [
    "df_finale.head()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                      restaurantName                      city  postalCode  \\\n",
       "0                               Arca  San Benedetto del Tronto       63074   \n",
       "1  Cannavacciuolo Le Cattedrali Asti                      Asti       14100   \n",
       "2                          Capriccio         Manerba del Garda       25080   \n",
       "3                   Cestello Firenze                  Florence       50124   \n",
       "4                       Corte Sconta                    Venice       30122   \n",
       "\n",
       "  country                                     address priceRange  \\\n",
       "0   Italy                      viale Rinascimento 137        €€€   \n",
       "1   Italy                    frazione Valleandona 1/b       €€€€   \n",
       "2   Italy  piazza San Bernardo 6  località Montinelle        €€€   \n",
       "3   Italy                        piazza di Cestello 8        €€€   \n",
       "4   Italy   calle del Pestrin  sestiere Castello 3886        €€€   \n",
       "\n",
       "                            cuisineType  \\\n",
       "0  Modern Cuisine, Cuisine from Abruzzo   \n",
       "1                              Creative   \n",
       "2               Modern Cuisine, Seafood   \n",
       "3                 Seafood, Contemporary   \n",
       "4                     Seafood, Venetian   \n",
       "\n",
       "                                         description  \\\n",
       "0  In business for over 20 years, Arca is definit...   \n",
       "1  Situated in the hills outside Asti, this moder...   \n",
       "2  This restaurant standing on the shores of Lake...   \n",
       "3  Situated in the beautiful piazza overlooked by...   \n",
       "4  From its flooring to its tables, this restaura...   \n",
       "\n",
       "                                  facilitiesServices  \\\n",
       "0  ['Air conditioning', 'Restaurant offering vege...   \n",
       "1  ['Air conditioning', 'Car park', 'Garden or pa...   \n",
       "2  ['Air conditioning', 'Car park', 'Great view',...   \n",
       "3                    ['Air conditioning', 'Terrace']   \n",
       "4                    ['Air conditioning', 'Terrace']   \n",
       "\n",
       "                                     creditCards        phoneNumber  \\\n",
       "0                 ['Amex', 'Mastercard', 'Visa']    +39 0735 488908   \n",
       "1   ['Amex', 'Dinersclub', 'Mastercard', 'Visa']  +39 0141 185 8888   \n",
       "2  ['Amex', 'Maestrocard', 'Mastercard', 'Visa']    +39 0365 551124   \n",
       "3   ['Amex', 'Dinersclub', 'Mastercard', 'Visa']   +39 055 264 5364   \n",
       "4                         ['Mastercard', 'Visa']   +39 041 522 7024   \n",
       "\n",
       "                           website  restaurantId     region   latitude  \\\n",
       "0   https://www.arcaristorante.it/             1     Marche  42.926408   \n",
       "1    https://www.lecattedrali.com/             2   Piemonte  44.907837   \n",
       "2  https://ristorantecapriccio.it/             3  Lombardia  45.552850   \n",
       "3                              NaN             4    Toscana  43.770306   \n",
       "4    https://www.cortescontave.com             5     Veneto  45.434791   \n",
       "\n",
       "   longitude  \n",
       "0  13.897645  \n",
       "1   8.117304  \n",
       "2  10.561210  \n",
       "3  11.243657  \n",
       "4  12.347919  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>restaurantName</th>\n",
       "      <th>city</th>\n",
       "      <th>postalCode</th>\n",
       "      <th>country</th>\n",
       "      <th>address</th>\n",
       "      <th>priceRange</th>\n",
       "      <th>cuisineType</th>\n",
       "      <th>description</th>\n",
       "      <th>facilitiesServices</th>\n",
       "      <th>creditCards</th>\n",
       "      <th>phoneNumber</th>\n",
       "      <th>website</th>\n",
       "      <th>restaurantId</th>\n",
       "      <th>region</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Arca</td>\n",
       "      <td>San Benedetto del Tronto</td>\n",
       "      <td>63074</td>\n",
       "      <td>Italy</td>\n",
       "      <td>viale Rinascimento 137</td>\n",
       "      <td>€€€</td>\n",
       "      <td>Modern Cuisine, Cuisine from Abruzzo</td>\n",
       "      <td>In business for over 20 years, Arca is definit...</td>\n",
       "      <td>['Air conditioning', 'Restaurant offering vege...</td>\n",
       "      <td>['Amex', 'Mastercard', 'Visa']</td>\n",
       "      <td>+39 0735 488908</td>\n",
       "      <td>https://www.arcaristorante.it/</td>\n",
       "      <td>1</td>\n",
       "      <td>Marche</td>\n",
       "      <td>42.926408</td>\n",
       "      <td>13.897645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cannavacciuolo Le Cattedrali Asti</td>\n",
       "      <td>Asti</td>\n",
       "      <td>14100</td>\n",
       "      <td>Italy</td>\n",
       "      <td>frazione Valleandona 1/b</td>\n",
       "      <td>€€€€</td>\n",
       "      <td>Creative</td>\n",
       "      <td>Situated in the hills outside Asti, this moder...</td>\n",
       "      <td>['Air conditioning', 'Car park', 'Garden or pa...</td>\n",
       "      <td>['Amex', 'Dinersclub', 'Mastercard', 'Visa']</td>\n",
       "      <td>+39 0141 185 8888</td>\n",
       "      <td>https://www.lecattedrali.com/</td>\n",
       "      <td>2</td>\n",
       "      <td>Piemonte</td>\n",
       "      <td>44.907837</td>\n",
       "      <td>8.117304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Capriccio</td>\n",
       "      <td>Manerba del Garda</td>\n",
       "      <td>25080</td>\n",
       "      <td>Italy</td>\n",
       "      <td>piazza San Bernardo 6  località Montinelle</td>\n",
       "      <td>€€€</td>\n",
       "      <td>Modern Cuisine, Seafood</td>\n",
       "      <td>This restaurant standing on the shores of Lake...</td>\n",
       "      <td>['Air conditioning', 'Car park', 'Great view',...</td>\n",
       "      <td>['Amex', 'Maestrocard', 'Mastercard', 'Visa']</td>\n",
       "      <td>+39 0365 551124</td>\n",
       "      <td>https://ristorantecapriccio.it/</td>\n",
       "      <td>3</td>\n",
       "      <td>Lombardia</td>\n",
       "      <td>45.552850</td>\n",
       "      <td>10.561210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cestello Firenze</td>\n",
       "      <td>Florence</td>\n",
       "      <td>50124</td>\n",
       "      <td>Italy</td>\n",
       "      <td>piazza di Cestello 8</td>\n",
       "      <td>€€€</td>\n",
       "      <td>Seafood, Contemporary</td>\n",
       "      <td>Situated in the beautiful piazza overlooked by...</td>\n",
       "      <td>['Air conditioning', 'Terrace']</td>\n",
       "      <td>['Amex', 'Dinersclub', 'Mastercard', 'Visa']</td>\n",
       "      <td>+39 055 264 5364</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>Toscana</td>\n",
       "      <td>43.770306</td>\n",
       "      <td>11.243657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Corte Sconta</td>\n",
       "      <td>Venice</td>\n",
       "      <td>30122</td>\n",
       "      <td>Italy</td>\n",
       "      <td>calle del Pestrin  sestiere Castello 3886</td>\n",
       "      <td>€€€</td>\n",
       "      <td>Seafood, Venetian</td>\n",
       "      <td>From its flooring to its tables, this restaura...</td>\n",
       "      <td>['Air conditioning', 'Terrace']</td>\n",
       "      <td>['Mastercard', 'Visa']</td>\n",
       "      <td>+39 041 522 7024</td>\n",
       "      <td>https://www.cortescontave.com</td>\n",
       "      <td>5</td>\n",
       "      <td>Veneto</td>\n",
       "      <td>45.434791</td>\n",
       "      <td>12.347919</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T16:32:48.097300Z",
     "start_time": "2024-11-14T16:32:48.090789Z"
    }
   },
   "source": [
    "df_finale.shape"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2006, 16)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 25
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### 4.3 Map Setup"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dash used instead of plain Plotly to make the map interactive and to be able to select regions with a simple click instead of using a list."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T16:32:51.738555Z",
     "start_time": "2024-11-14T16:32:50.804447Z"
    }
   },
   "source": [
    "import dash\n",
    "from dash import dcc, html\n",
    "from dash.dependencies import Input, Output\n",
    "import plotly.express as px\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# DEBUG\n",
    "print(df_finale.shape)\n",
    "\n",
    "# Load GeoJSON file of Italian regions in a GeoDataFrame\n",
    "gdf = gpd.read_file(\"./GeoJson/limits_IT_regions.geojson\")\n",
    "\n",
    "# Check CRS and convert it if needed (important to calculate centroid of each region to display it centered)\n",
    "if gdf.crs != \"EPSG:4326\":\n",
    "    gdf = gdf.to_crs(\"EPSG:4326\")\n",
    "\n",
    "# Extract region names from the GeoDataFrame\n",
    "region_names = gdf['reg_name'].tolist()\n",
    "\n",
    "# Create Dash app (Dash provides an easy-to-use API for creating web apps using Python)\n",
    "app = dash.Dash(__name__)\n",
    "\n",
    "# Layout of the app with checkbox for filtering top_k_result.tsv\n",
    "app.layout = html.Div([\n",
    "    html.Div([\n",
    "        # Add checkbox to filter top_k_result.tsv\n",
    "        dcc.Checklist(\n",
    "            id='show-top-k',\n",
    "            options=[{'label': 'Show Top-K Restaurants Only', 'value': 'top_k'}],\n",
    "            value=[],\n",
    "            inline=True\n",
    "        ),\n",
    "    ]),\n",
    "    \n",
    "    # Create 2 maps, one of Italy with selectable region and one for the selected region where we display restaurants\n",
    "    html.Div([\n",
    "        dcc.Graph(id='italy-map', clickData=None, style={'width': '50vw', 'height': '100vh'}),\n",
    "        dcc.Graph(id='region-map', style={'width': '50vw', 'height': '100vh'})\n",
    "    ], style={'display': 'flex', 'flex-direction': 'row'})\n",
    "])\n",
    "\n",
    "# Global variable to store filtered restaurants (default is all restaurants)\n",
    "filtered_restaurants = df_finale\n",
    "\n",
    "@app.callback(\n",
    "    [Output('italy-map', 'figure'),\n",
    "     Output('region-map', 'figure')],\n",
    "    [Input('italy-map', 'clickData'),\n",
    "     Input('show-top-k', 'value')]\n",
    ")\n",
    "def update_maps(clickData, show_top_k):\n",
    "    global filtered_restaurants\n",
    "    \n",
    "    # Se la checkbox \"Top-K\" è selezionata, filtra i ristoranti dal file top_k_result.tsv\n",
    "    if 'top_k' in show_top_k:\n",
    "        top_k_df = pd.read_csv('top_k_result.tsv', sep='\\t')\n",
    "        filtered_restaurants = df_finale[df_finale['restaurantName'].isin(top_k_df['restaurantName'])]\n",
    "    else:\n",
    "        filtered_restaurants = df_finale\n",
    "\n",
    "    # Variabile per gestire se una regione è selezionata\n",
    "    selected_region = None\n",
    "    if clickData:\n",
    "        selected_region = clickData['points'][0]['location']\n",
    "\n",
    "    # Configurazione della mappa dell'Italia\n",
    "    italy_map = px.choropleth_mapbox(\n",
    "        geojson=json.loads(gdf.to_json()),\n",
    "        locations=gdf['reg_name'],\n",
    "        featureidkey=\"properties.reg_name\",\n",
    "        color_continuous_scale=['grey'],\n",
    "        opacity=0.2,\n",
    "        mapbox_style=\"carto-positron\",\n",
    "        zoom=4.5,\n",
    "        center={\"lat\": 41.8719, \"lon\": 12.5674},\n",
    "        title=\"Map of the Italian Regions\"\n",
    "    )\n",
    "    \n",
    "    # Se la checkbox \"Top-K\" è selezionata e una regione è selezionata, mostra i marker\n",
    "    if 'top_k' in show_top_k and selected_region:\n",
    "        for price_range, color in [('€', 'blue'), ('€€', 'green'), ('€€€', 'purple'), ('€€€€', 'brown')]:\n",
    "            price_restaurants = filtered_restaurants[filtered_restaurants['priceRange'] == price_range]\n",
    "            italy_map.add_scattermapbox(\n",
    "                lat=price_restaurants['latitude'].tolist(),\n",
    "                lon=price_restaurants['longitude'].tolist(),\n",
    "                mode='markers',\n",
    "                marker=dict(size=10, color=color, opacity=0.8),\n",
    "                text=price_restaurants['restaurantName'],\n",
    "                name=price_range,\n",
    "                hovertemplate=(\n",
    "                    \"<b>Restaurant Name:</b> %{text}<br>\" +\n",
    "                    \"<b>Latitude:</b> %{lat}<br>\" +\n",
    "                    \"<b>Longitude:</b> %{lon}<br>\"\n",
    "                )\n",
    "            )\n",
    "    \n",
    "    if selected_region:\n",
    "        italy_map.update_traces(marker_line_color=\"red\", selector=dict(location=selected_region))\n",
    "    \n",
    "    # Configurazione della mappa della regione selezionata (se presente)\n",
    "    if selected_region:\n",
    "        region_gdf = gdf[gdf['reg_name'] == selected_region]\n",
    "        region_gdf_proj = region_gdf.to_crs(epsg=32632)\n",
    "        centroid_proj = region_gdf_proj.geometry.centroid.iloc[0]\n",
    "        centroid = gpd.GeoSeries([centroid_proj], crs=\"EPSG:32632\").to_crs(\"EPSG:4326\").iloc[0]\n",
    "        center_lat, center_lon = centroid.y, centroid.x\n",
    "\n",
    "        filtered_restaurants_region = filtered_restaurants[filtered_restaurants['region'] == selected_region]\n",
    "\n",
    "        region_map = px.choropleth_mapbox(\n",
    "            geojson=json.loads(region_gdf.to_json()),\n",
    "            locations=[selected_region],\n",
    "            featureidkey=\"properties.reg_name\",\n",
    "            mapbox_style=\"carto-positron\",\n",
    "            color_discrete_sequence=['red'],\n",
    "            opacity=0.1,\n",
    "            zoom=6,\n",
    "            center={\"lat\": center_lat, \"lon\": center_lon},\n",
    "            title=f\"Map of {selected_region} with Restaurants\"\n",
    "        )\n",
    "        \n",
    "        # Aggiungi marker per i ristoranti nella regione selezionata\n",
    "        for price_range, color in [('€', 'blue'), ('€€', 'green'), ('€€€', 'purple'), ('€€€€', 'brown')]:\n",
    "            price_restaurants = filtered_restaurants_region[filtered_restaurants_region['priceRange'] == price_range]\n",
    "            region_map.add_scattermapbox(\n",
    "                lat=price_restaurants['latitude'].tolist(),\n",
    "                lon=price_restaurants['longitude'].tolist(),\n",
    "                mode='markers',\n",
    "                marker=dict(size=10, color=color, opacity=0.8),\n",
    "                text=price_restaurants['restaurantName'],\n",
    "                name=price_range,\n",
    "                hovertemplate=(\n",
    "                    \"<b>Restaurant Name:</b> %{text}<br>\" +\n",
    "                    \"<b>Latitude:</b> %{lat}<br>\" +\n",
    "                    \"<b>Longitude:</b> %{lon}<br>\"\n",
    "                )\n",
    "            )\n",
    "    else:\n",
    "        # Se nessuna regione è selezionata, restituisci una mappa vuota\n",
    "        region_map = {}\n",
    "\n",
    "    return italy_map, region_map\n",
    "\n",
    "# Start Dash App\n",
    "if __name__ == '__main__':\n",
    "    app.run_server(jupyter_mode = 'external', debug=True)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2006, 16)\n",
      "Dash app running on http://127.0.0.1:8050/\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 5. BONUS: Advanced Search Engine"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# 1. Vocabulary File\n",
    "\n",
    "doc_tokens = [] # initialize list to store all tokens\n",
    "\n",
    "for idx, row in enumerate(df.description):\n",
    "  doc_tokens.extend(functions.preprocessing(row))\n",
    "  doc_tokens = list(set(doc_tokens)) # remove duplicates\n",
    "\n",
    "vocabulary_dict = {term: i for i,term in enumerate(doc_tokens)}\n",
    "\n",
    "vocabulary_df = pd.DataFrame({'term': vocabulary_dict.keys(),\n",
    "                              'term_id': vocabulary_dict.values()})\n",
    "\n",
    "vocabulary_df.to_csv('vocabulary.csv', index=False)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# 2. Inverted Index\n",
    "\n",
    "inverted_index = defaultdict(list) # initialize inverted_index dictionary\n",
    "preprocessed_docs = defaultdict(list) # initialize dictionary to store pre-processed docs (restaurant descriptions)\n",
    "\n",
    "for doc_id, row in enumerate(df.description):\n",
    "  preprocessed_docs[doc_id] = functions.preprocessing(row) # preprocess the description\n",
    "  tokens = set(preprocessed_docs[doc_id]) # preprocess the description\n",
    "  for token in tokens: # eliminate duplicates\n",
    "    # Look up the term_id of the current term/token\n",
    "    term_id = vocabulary_dict[token]\n",
    "    # If the doc_id is not in the term_id's list in inverted_index, add it\n",
    "    if doc_id not in inverted_index[term_id]:\n",
    "      inverted_index[term_id].append(doc_id)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# @title Compute updated_inverted_index\n",
    "\n",
    "n = len(preprocessed_docs)\n",
    "updated_inverted_index = defaultdict(list) # initialize default dictionary to store the inverted_index values with TF-IDF scores\n",
    "\n",
    "# Create a copy of the inverted_index to iterate over\n",
    "inverted_index_copy = inverted_index.copy()\n",
    "\n",
    "for term_id, docs in inverted_index_copy.items():\n",
    "  tf_idf_scores = functions.tf_idf(int(term_id), inverted_index, preprocessed_docs, vocabulary_df, n)\n",
    "  updated_inverted_index[term_id] = list(zip(docs, tf_idf_scores))\n",
    "\n",
    "with open('updated_inverted_index.pkl', 'wb') as file:\n",
    "    pickle.dump(updated_inverted_index, file)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "doc_tf_idf_scores = defaultdict(list) # initialize dictionary to store non-zero TF-IDF scores for each document\n",
    "\n",
    "for term_id, docs_scores in updated_inverted_index.items():\n",
    "  for doc_id, tf_idf_score in docs_scores:\n",
    "    if tf_idf_score != 0:\n",
    "      doc_tf_idf_scores[doc_id].append((term_id,tf_idf_score))\n",
    "  doc_tf_idf_scores[doc_id].sort(key=lambda x: x[0]) # sort the terms\n",
    "\n",
    "with open('doc_tf_idf_scores.pkl', 'wb') as file:\n",
    "    pickle.dump(doc_tf_idf_scores, file)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "  processed_query = functions.preprocessing(query) # processed query\n",
    "  query_tokens = list(set(processed_query)) # unique query tokens\n",
    "  # print(query_tokens) # debugging line\n",
    "  # Find all docs to consider\n",
    "  docs_to_consider = [] # initialize list to store documents to consider (non-zero intersection with the query tokens)\n",
    "\n",
    "  for token in query_tokens:\n",
    "    if vocabulary_dict[token]: # check if the token is in the vocabulary\n",
    "      token_id = vocabulary_dict[token] # get the term_id of the token\n",
    "      docs_to_consider.extend(inverted_index[token_id]) # add the documents that contain the token to the docs to consider\n",
    "\n",
    "  docs_to_consider = list(set(docs_to_consider))\n",
    "   # Calculate the TF-IDF score of the query\n",
    "  query_tf_idf_scores = [] # initialize list to store the TF-IDF scores of the query\n",
    "  for term in query_tokens:\n",
    "    term_id = vocabulary_dict[term] # get the term_id of the term\n",
    "    #print(inverted_index[term_id]) # debugging line\n",
    "    n_term = len(inverted_index[term_id]) # number of documents that contain the term\n",
    "    IDF = np.log10(n / n_term) # calculate IDF of the term\n",
    "    TF = processed_query.count(term) # calculate TF of the term\n",
    "    #print(f\"TF = {TF}\") # debugging line\n",
    "    #print(f\"IDF = {IDF}\") # debuggin line\n",
    "    query_tf_idf_scores.append((term_id, TF * IDF)) # calculate TF-IDF score\n",
    "\n",
    "  query_tf_idf_scores.sort(key=lambda x: x[0]) # sort the query_tf_idf_scores in order of term_id\n",
    "\n",
    "  query_norm = np.linalg.norm(np.array([score for _, score in query_tf_idf_scores])) # calculate the norm of the query\n",
    "  #print(f\"query tf_idf_scores: {query_tf_idf_scores}\") # debuggin line\n",
    "  #print(f\"query norm: {query_norm}\") # debugging line\n",
    "  # calculate document norms\n",
    "  doc_norms = {doc_id: np.linalg.norm(np.array([doc_tf_idf_scores[doc_id][i][1] for i in range(len(doc_tf_idf_scores[doc_id]))])) for doc_id in docs_to_consider}\n",
    "\n",
    "  # Function that returns two lists of tuples (term, query_tf_idf) and (term, doc_tf_idf) such that\n",
    "  # the terms are in the intersection of the query terms and the doc's terms\n",
    "  def query_doc_intersection(query_tf_idf_scores, doc_tf_idf_scores):\n",
    "    '''\n",
    "    Calculate the intersection of the query and the document\n",
    "    Inputs:\n",
    "    query_terms: list of sorted unique query terms\n",
    "    doc_terms: list of sorted unique document terms\n",
    "    Output:\n",
    "    query_intersection: list of tuples (term, query_tf_idf)\n",
    "    doc_intersection: list of tuples (term, doc_tf_idf)\n",
    "    '''\n",
    "    query_intersection = [] # initialize list to store (term, query_tf_idf) tuples in the intersection\n",
    "    doc_intersection = [] # initialize list to store (term, doc_tf_idf) tuples in the intersection\n",
    "    i, j = 0, 0 # initialize two pointers\n",
    "    while i<len(query_tf_idf_scores) and j<len(doc_tf_idf_scores):\n",
    "      if query_tf_idf_scores[i][0] == doc_tf_idf_scores[j][0]:\n",
    "        query_intersection.append(query_tf_idf_scores[i])\n",
    "        doc_intersection.append(doc_tf_idf_scores[j])\n",
    "        i += 1\n",
    "        j += 1\n",
    "      elif query_tf_idf_scores[i][0] < doc_tf_idf_scores[j][0]:\n",
    "        i += 1\n",
    "      else:\n",
    "        j += 1\n",
    "    return query_intersection, doc_intersection\n",
    "\n",
    "  # Calculate cosine-similarity between the query and each document\n",
    "  cosine_similarity = defaultdict(float) # initialize dictionary to store the cosine similarity results\n",
    "  for doc_id in docs_to_consider:\n",
    "    query_intersection, doc_intersection = query_doc_intersection(query_tf_idf_scores, doc_tf_idf_scores[doc_id]) # find the\n",
    "    cosine_similarity[doc_id] = np.dot(np.array([score for _, score in query_intersection]), np.array([score for _, score in doc_intersection])) / (query_norm * doc_norms[doc_id])"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T19:28:52.441987Z",
     "start_time": "2024-11-11T19:28:47.892908Z"
    }
   },
   "source": [
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "# Assuming `df` has `restaurantName`, `city`, `cuisineType`, and `description` columns\n",
    "\n",
    "# Helper function to create vocabulary and inverted index for a field\n",
    "def build_vocabulary_inverted_index(field_data, preprocess_func):\n",
    "    tokens = []\n",
    "    for value in field_data:\n",
    "        tokens.extend(preprocess_func(value))\n",
    "    tokens = list(set(tokens))  # remove duplicates\n",
    "\n",
    "    vocabulary_dict = {term: i for i, term in enumerate(tokens)}\n",
    "    inverted_index = defaultdict(list)\n",
    "\n",
    "    for doc_id, value in enumerate(field_data):\n",
    "        processed_tokens = set(preprocess_func(value))\n",
    "        for token in processed_tokens:\n",
    "            term_id = vocabulary_dict[token]\n",
    "            inverted_index[term_id].append(doc_id)\n",
    "\n",
    "    return vocabulary_dict, inverted_index\n",
    "\n",
    "# Build vocabulary and inverted indexes for each field\n",
    "vocab_restaurantName, inverted_index_restaurantName = build_vocabulary_inverted_index(df['restaurantName'], functions.preprocessing)\n",
    "vocab_city, inverted_index_city = build_vocabulary_inverted_index(df['city'], functions.preprocessing)\n",
    "vocab_cuisineType, inverted_index_cuisineType = build_vocabulary_inverted_index(df['cuisineType'], functions.preprocessing)\n",
    "\n",
    "# Convert each vocabulary dictionary to a DataFrame\n",
    "vocabulary_df_restaurantName = pd.DataFrame({'term': vocab_restaurantName.keys(), 'term_id': vocab_restaurantName.values()})\n",
    "vocabulary_df_city = pd.DataFrame({'term': vocab_city.keys(), 'term_id': vocab_city.values()})\n",
    "vocabulary_df_cuisineType = pd.DataFrame({'term': vocab_cuisineType.keys(), 'term_id': vocab_cuisineType.values()})\n",
    "\n",
    "# Function to compute TF-IDF scores with correct vocabulary_df input\n",
    "def compute_tf_idf_scores(inverted_index, preprocessed_docs, vocabulary_df, n_docs):\n",
    "    updated_inverted_index = defaultdict(list)\n",
    "    for term_id, docs in inverted_index.items():\n",
    "        tf_idf_scores = functions.tf_idf(term_id, inverted_index, preprocessed_docs, vocabulary_df, n_docs)\n",
    "        updated_inverted_index[term_id] = list(zip(docs, tf_idf_scores))\n",
    "    return updated_inverted_index\n",
    "\n",
    "n_docs = len(df)\n",
    "\n",
    "# Process each field with the updated vocabulary DataFrames\n",
    "preprocessed_restaurantName = {doc_id: functions.preprocessing(name) for doc_id, name in enumerate(df['restaurantName'])}\n",
    "updated_inverted_index_restaurantName = compute_tf_idf_scores(inverted_index_restaurantName, preprocessed_restaurantName, vocabulary_df_restaurantName, n_docs)\n",
    "\n",
    "preprocessed_city = {doc_id: functions.preprocessing(city) for doc_id, city in enumerate(df['city'])}\n",
    "updated_inverted_index_city = compute_tf_idf_scores(inverted_index_city, preprocessed_city, vocabulary_df_city, n_docs)\n",
    "\n",
    "preprocessed_cuisineType = {doc_id: functions.preprocessing(cuisine) for doc_id, cuisine in enumerate(df['cuisineType'])}\n",
    "updated_inverted_index_cuisineType = compute_tf_idf_scores(inverted_index_cuisineType, preprocessed_cuisineType, vocabulary_df_cuisineType, n_docs)\n",
    "\n",
    "\n",
    "# 3. Aggregate Cosine Similarity Scores Across Fields\n",
    "def compute_cosine_similarity(query_tf_idf_scores, doc_tf_idf_scores, query_norm, doc_norms, weight=1.0):\n",
    "    cosine_similarity = defaultdict(float)\n",
    "    for doc_id in doc_tf_idf_scores:\n",
    "        query_intersection, doc_intersection = query_doc_intersection(query_tf_idf_scores, doc_tf_idf_scores[doc_id])\n",
    "        score = np.dot(np.array([score for _, score in query_intersection]), np.array([score for _, score in doc_intersection]))\n",
    "        cosine_similarity[doc_id] += weight * score / (query_norm * doc_norms[doc_id]) if doc_norms[doc_id] != 0 else 0\n",
    "    return cosine_similarity\n",
    "\n",
    "# 4. Calculate aggregate similarity scores for all fields\n",
    "def aggregate_similarity(query_tokens, inverted_indices, vocabularies, doc_tf_idf_scores_dict, n_docs, weights):\n",
    "    cosine_scores = defaultdict(float)\n",
    "    for field, inverted_index in inverted_indices.items():\n",
    "        vocabulary = vocabularies[field]\n",
    "        updated_inverted_index = doc_tf_idf_scores_dict[field]\n",
    "        query_tf_idf_scores = []\n",
    "\n",
    "        for token in query_tokens:\n",
    "            if token in vocabulary:\n",
    "                term_id = vocabulary[token]\n",
    "                query_tf_idf_scores.append((term_id, functions.tf_idf(term_id, inverted_index, {0: query_tokens}, vocabulary, n_docs)[0]))\n",
    "\n",
    "        query_tf_idf_scores.sort(key=lambda x: x[0])\n",
    "        query_norm = np.linalg.norm([score for _, score in query_tf_idf_scores])\n",
    "        \n",
    "        field_cosine_scores = compute_cosine_similarity(query_tf_idf_scores, updated_inverted_index, query_norm, weights[field])\n",
    "        for doc_id, score in field_cosine_scores.items():\n",
    "            cosine_scores[doc_id] += score\n",
    "\n",
    "    return cosine_scores\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T19:31:00.307237Z",
     "start_time": "2024-11-11T19:31:00.279431Z"
    }
   },
   "source": [
    "query = \"pizza New York cheap\"  # Example query\n",
    "processed_query = functions.preprocessing(query)\n",
    "inverted_indices = {\n",
    "    \"restaurantName\": updated_inverted_index_restaurantName,\n",
    "    \"city\": updated_inverted_index_city,\n",
    "    \"cuisineType\": updated_inverted_index_cuisineType\n",
    "}\n",
    "vocabularies = {\n",
    "    \"restaurantName\": vocab_restaurantName,\n",
    "    \"city\": vocab_city,\n",
    "    \"cuisineType\": vocab_cuisineType\n",
    "}\n",
    "doc_tf_idf_scores_dict = {\n",
    "    \"restaurantName\": updated_inverted_index_restaurantName,\n",
    "    \"city\": updated_inverted_index_city,\n",
    "    \"cuisineType\": updated_inverted_index_cuisineType\n",
    "}\n",
    "\n",
    "# Weights for each field\n",
    "weights = {\"restaurantName\": 0.5, \"city\": 0.3, \"cuisineType\": 0.2}\n",
    "\n",
    "# Aggregate similarity scores across all fields\n",
    "cosine_scores = aggregate_similarity(processed_query, inverted_indices, vocabularies, doc_tf_idf_scores_dict, n_docs, weights)\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T19:39:07.616952Z",
     "start_time": "2024-11-11T19:39:02.570274Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "# Assuming `df` has `restaurantName`, `city`, `cuisineType` columns\n",
    "# Assuming `functions` module has a `preprocessing` function and a `tf_idf` function\n",
    "\n",
    "# Helper function to create vocabulary and inverted index for a field\n",
    "def build_vocabulary_inverted_index(field_data, preprocess_func):\n",
    "    tokens = []\n",
    "    for value in field_data:\n",
    "        tokens.extend(preprocess_func(value))\n",
    "    tokens = list(set(tokens))  # Remove duplicates\n",
    "\n",
    "    vocabulary_dict = {term: i for i, term in enumerate(tokens)}\n",
    "    inverted_index = defaultdict(list)\n",
    "\n",
    "    for doc_id, value in enumerate(field_data):\n",
    "        processed_tokens = set(preprocess_func(value))\n",
    "        for token in processed_tokens:\n",
    "            term_id = vocabulary_dict[token]\n",
    "            inverted_index[term_id].append(doc_id)\n",
    "\n",
    "    return vocabulary_dict, inverted_index\n",
    "\n",
    "# Build vocabulary and inverted indexes for each field\n",
    "vocab_restaurantName, inverted_index_restaurantName = build_vocabulary_inverted_index(df['restaurantName'], functions.preprocessing)\n",
    "vocab_city, inverted_index_city = build_vocabulary_inverted_index(df['city'], functions.preprocessing)\n",
    "vocab_cuisineType, inverted_index_cuisineType = build_vocabulary_inverted_index(df['cuisineType'], functions.preprocessing)\n",
    "\n",
    "# Convert each vocabulary dictionary to a DataFrame for TF-IDF calculations\n",
    "vocabulary_df_restaurantName = pd.DataFrame({'term': vocab_restaurantName.keys(), 'term_id': vocab_restaurantName.values()})\n",
    "vocabulary_df_city = pd.DataFrame({'term': vocab_city.keys(), 'term_id': vocab_city.values()})\n",
    "vocabulary_df_cuisineType = pd.DataFrame({'term': vocab_cuisineType.keys(), 'term_id': vocab_cuisineType.values()})\n",
    "\n",
    "# Function to compute TF-IDF scores with the appropriate vocabulary_df\n",
    "def compute_tf_idf_scores(inverted_index, preprocessed_docs, vocabulary_df, n_docs):\n",
    "    updated_inverted_index = defaultdict(list)\n",
    "    for term_id, docs in inverted_index.items():\n",
    "        tf_idf_scores = functions.tf_idf(term_id, inverted_index, preprocessed_docs, vocabulary_df, n_docs)\n",
    "        updated_inverted_index[term_id] = list(zip(docs, tf_idf_scores))\n",
    "    return updated_inverted_index\n",
    "\n",
    "n_docs = len(df)\n",
    "\n",
    "# Process each field with the updated vocabulary DataFrames\n",
    "preprocessed_restaurantName = {doc_id: functions.preprocessing(name) for doc_id, name in enumerate(df['restaurantName'])}\n",
    "updated_inverted_index_restaurantName = compute_tf_idf_scores(inverted_index_restaurantName, preprocessed_restaurantName, vocabulary_df_restaurantName, n_docs)\n",
    "\n",
    "preprocessed_city = {doc_id: functions.preprocessing(city) for doc_id, city in enumerate(df['city'])}\n",
    "updated_inverted_index_city = compute_tf_idf_scores(inverted_index_city, preprocessed_city, vocabulary_df_city, n_docs)\n",
    "\n",
    "preprocessed_cuisineType = {doc_id: functions.preprocessing(cuisine) for doc_id, cuisine in enumerate(df['cuisineType'])}\n",
    "updated_inverted_index_cuisineType = compute_tf_idf_scores(inverted_index_cuisineType, preprocessed_cuisineType, vocabulary_df_cuisineType, n_docs)\n",
    "\n",
    "# Aggregate cosine similarity scores across restaurantName, city, and cuisineType fields\n",
    "def aggregate_similarity(query, inverted_indices, vocabularies, updated_inverted_indices, n_docs, weights):\n",
    "    processed_query = functions.preprocessing(query)\n",
    "    cosine_scores = defaultdict(float)\n",
    "\n",
    "    for field, inverted_index in inverted_indices.items():\n",
    "        vocabulary = vocabularies[field]\n",
    "        updated_inverted_index = updated_inverted_indices[field]\n",
    "\n",
    "        # Calculate TF-IDF scores for query terms in this field\n",
    "        query_tf_idf_scores = []\n",
    "        for token in processed_query:\n",
    "            if token in vocabulary:\n",
    "                term_id = vocabulary[token]\n",
    "                query_tf_idf_scores.append((term_id, functions.tf_idf(term_id, inverted_index, {0: processed_query}, vocabulary, n_docs)[0]))\n",
    "\n",
    "        query_tf_idf_scores.sort(key=lambda x: x[0])\n",
    "        query_norm = np.linalg.norm([score for _, score in query_tf_idf_scores])\n",
    "\n",
    "        # Compute cosine similarity for each document in this field\n",
    "        doc_norms = {\n",
    "            doc_id: np.linalg.norm([score for _, score in updated_inverted_index[doc_id]])\n",
    "            for doc_id in updated_inverted_index\n",
    "        }\n",
    "\n",
    "        for doc_id, doc_tf_idf_scores in updated_inverted_index.items():\n",
    "            # Calculate intersection of query and document TF-IDF scores\n",
    "            query_intersection, doc_intersection = functions.query_doc_intersection_enanched(query_tf_idf_scores, doc_tf_idf_scores)\n",
    "            dot_product = np.dot([score for _, score in query_intersection], [score for _, score in doc_intersection])\n",
    "\n",
    "            # Calculate and aggregate cosine similarity\n",
    "            cosine_scores[doc_id] += weights[field] * (dot_product / (query_norm * doc_norms.get(doc_id, 1e-10)))\n",
    "\n",
    "    return cosine_scores\n",
    "\n",
    "# Define weights for each field\n",
    "weights = {\"restaurantName\": 0.4, \"city\": 0.3, \"cuisineType\": 0.3}\n",
    "\n",
    "# Query processing function\n",
    "def search(query, weights):\n",
    "    inverted_indices = {\n",
    "        \"restaurantName\": inverted_index_restaurantName,\n",
    "        \"city\": inverted_index_city,\n",
    "        \"cuisineType\": inverted_index_cuisineType\n",
    "    }\n",
    "    vocabularies = {\n",
    "        \"restaurantName\": vocab_restaurantName,\n",
    "        \"city\": vocab_city,\n",
    "        \"cuisineType\": vocab_cuisineType\n",
    "    }\n",
    "    updated_inverted_indices = {\n",
    "        \"restaurantName\": updated_inverted_index_restaurantName,\n",
    "        \"city\": updated_inverted_index_city,\n",
    "        \"cuisineType\": updated_inverted_index_cuisineType\n",
    "    }\n",
    "    \n",
    "    # Aggregate similarity scores across specified fields\n",
    "    cosine_scores = aggregate_similarity(query, inverted_indices, vocabularies, updated_inverted_indices, n_docs, weights)\n",
    "    \n",
    "    # Sort results by similarity score\n",
    "    ranked_docs = sorted(cosine_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    return ranked_docs[:5]  # Return top 5 results\n",
    "\n",
    "# Example query\n",
    "query = \"pizza New York Italian\"\n",
    "top_results = search(query, weights)\n",
    "print(top_results)\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T19:42:15.307089Z",
     "start_time": "2024-11-11T19:42:15.303184Z"
    }
   },
   "source": [
    "import json\n",
    "def createIndex(df, column):\n",
    "    # Convert all unique words to lowercase and apply stemming\n",
    "    stemmer = PorterStemmer()\n",
    "    df[column] = df[column].fillna('')\n",
    "    all_words = pd.Series(\" \".join(df[column].str.lower()).split()).unique()\n",
    "    all_words_stemmed = [stemmer.stem(word) for word in all_words]\n",
    "    \n",
    "    # Initialize the dictionary for stemmed words\n",
    "    word_to_restaurants = {word: [] for word in all_words_stemmed}\n",
    "    \n",
    "    # Split each row's text, stem each word, and update the index\n",
    "    for i, row in df.iterrows():\n",
    "        words = row[column].lower().split()\n",
    "        for word in words:\n",
    "            stemmed_word = stemmer.stem(word)\n",
    "            word_to_restaurants[stemmed_word].append(row['restaurantName'])\n",
    "    \n",
    "    # Save to JSON\n",
    "    path = f'C:/Users/xavie/Documents/ADM_HW3/{column}_index.json'\n",
    "    with open(path, 'w') as jsonfile:\n",
    "        json.dump(word_to_restaurants, jsonfile)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T19:42:17.272565Z",
     "start_time": "2024-11-11T19:42:17.189229Z"
    }
   },
   "source": [
    "restaurnt_index = createIndex(df, 'restaurantName')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T19:44:43.636052Z",
     "start_time": "2024-11-11T19:44:43.574785Z"
    }
   },
   "source": [
    "city_index = createIndex(df, 'city')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T19:44:59.201932Z",
     "start_time": "2024-11-11T19:44:59.115810Z"
    }
   },
   "source": [
    "cuisinType_index = createIndex(df, 'cuisineType')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T20:12:47.933989Z",
     "start_time": "2024-11-11T20:12:45.672277Z"
    }
   },
   "source": [
    "# Initialize inverted indexes for each field\n",
    "inverted_index_name = defaultdict(list)\n",
    "inverted_index_city = defaultdict(list)\n",
    "inverted_index_cuisine = defaultdict(list)\n",
    "\n",
    "# Preprocessed documents and vocabulary for each field\n",
    "preprocessed_docs_name = defaultdict(list)\n",
    "preprocessed_docs_city = defaultdict(list)\n",
    "preprocessed_docs_cuisine = defaultdict(list)\n",
    "\n",
    "vocabulary_dict_name = {}\n",
    "vocabulary_dict_city = {}\n",
    "vocabulary_dict_cuisine = {}\n",
    "\n",
    "# Total number of documents\n",
    "n = len(df)\n",
    "\n",
    "# Preprocess each field, create inverted index, and calculate TF-IDF\n",
    "for doc_id, row in df.iterrows():\n",
    "\n",
    "    # Restaurant name field\n",
    "    preprocessed_docs_name[doc_id] = functions.preprocessing(row['restaurantName'])\n",
    "    tokens_name = set(preprocessed_docs_name[doc_id])\n",
    "    for token in tokens_name:\n",
    "        # Update vocabulary and get term_id\n",
    "        term_id = vocabulary_dict_name.setdefault(token, len(vocabulary_dict_name))\n",
    "        # Calculate TF-IDF\n",
    "        tf = preprocessed_docs_name[doc_id].count(token)\n",
    "        df_name = len(inverted_index_name[term_id]) if term_id in inverted_index_name else 0\n",
    "        idf = np.log10(n / (df_name + 1))  # Add 1 to avoid division by zero\n",
    "        tf_idf_score = tf * idf\n",
    "        # Append (doc_id, tf_idf_score) to inverted index\n",
    "        inverted_index_name[term_id].append((doc_id, tf_idf_score))\n",
    "\n",
    "    # City field\n",
    "    preprocessed_docs_city[doc_id] = functions.preprocessing(row['city'])\n",
    "    tokens_city = set(preprocessed_docs_city[doc_id])\n",
    "    for token in tokens_city:\n",
    "        term_id = vocabulary_dict_city.setdefault(token, len(vocabulary_dict_city))\n",
    "        tf = preprocessed_docs_city[doc_id].count(token)\n",
    "        df_city = len(inverted_index_city[term_id]) if term_id in inverted_index_city else 0\n",
    "        idf = np.log10(n / (df_city + 1))\n",
    "        tf_idf_score = tf * idf\n",
    "        inverted_index_city[term_id].append((doc_id, tf_idf_score))\n",
    "\n",
    "    # Cuisine type field\n",
    "    preprocessed_docs_cuisine[doc_id] = functions.preprocessing(row['cuisineType'])\n",
    "    tokens_cuisine = set(preprocessed_docs_cuisine[doc_id])\n",
    "    for token in tokens_cuisine:\n",
    "        term_id = vocabulary_dict_cuisine.setdefault(token, len(vocabulary_dict_cuisine))\n",
    "        tf = preprocessed_docs_cuisine[doc_id].count(token)\n",
    "        df_cuisine = len(inverted_index_cuisine[term_id]) if term_id in inverted_index_cuisine else 0\n",
    "        idf = np.log10(n / (df_cuisine + 1))\n",
    "        tf_idf_score = tf * idf\n",
    "        inverted_index_cuisine[term_id].append((doc_id, tf_idf_score))\n",
    "\n",
    "# Save inverted indexes to files if needed\n",
    "with open(\"inverted_index_restaurantName.pkl\", \"wb\") as file:\n",
    "    pickle.dump(inverted_index_name, file)\n",
    "# Repeat for other fields...\n",
    "with open(\"inverted_index_city.pkl\", \"wb\") as file:\n",
    "    pickle.dump(inverted_index_city, file)\n",
    "with open(\"inverted_index_cuisineType.pkl\", \"wb\") as file:\n",
    "    pickle.dump(inverted_index_cuisine, file)\n",
    "    \n",
    "# Esempio per calcolare doc_tf_idf_scores per 'restaurantName'\n",
    "doc_tf_idf_scores_name = defaultdict(list)\n",
    "for term_id, docs_scores in inverted_index_name.items():  # usa l'indice invertito specifico per 'restaurantName'\n",
    "    for doc_id, tf_idf_score in docs_scores:\n",
    "        if tf_idf_score != 0:\n",
    "            doc_tf_idf_scores_name[doc_id].append((term_id, tf_idf_score))\n",
    "    doc_tf_idf_scores_name[doc_id].sort(key=lambda x: x[0])  # ordina per term_id\n",
    "\n",
    "# Ripeti per 'city' e 'cuisineType'\n",
    "doc_tf_idf_scores_city = defaultdict(list)\n",
    "for term_id, docs_scores in inverted_index_city.items():\n",
    "    for doc_id, tf_idf_score in docs_scores:\n",
    "        if tf_idf_score != 0:\n",
    "            doc_tf_idf_scores_city[doc_id].append((term_id, tf_idf_score))\n",
    "    doc_tf_idf_scores_city[doc_id].sort(key=lambda x: x[0])\n",
    "\n",
    "doc_tf_idf_scores_cuisine = defaultdict(list)\n",
    "for term_id, docs_scores in inverted_index_cuisine.items():\n",
    "    for doc_id, tf_idf_score in docs_scores:\n",
    "        if tf_idf_score != 0:\n",
    "            doc_tf_idf_scores_cuisine[doc_id].append((term_id, tf_idf_score))\n",
    "    doc_tf_idf_scores_cuisine[doc_id].sort(key=lambda x: x[0])"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T20:12:51.005398Z",
     "start_time": "2024-11-11T20:12:50.958351Z"
    }
   },
   "source": [
    "doc_tf_idf_scores_name"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T20:16:33.311730Z",
     "start_time": "2024-11-11T20:16:33.306231Z"
    }
   },
   "source": [
    "def top_k_restaurants_enanched(query, k=5):\n",
    "    '''\n",
    "    Find the top k restaurants matching the query by aggregating similarity scores across fields.\n",
    "    '''\n",
    "    # Process the query for each field\n",
    "    query_tokens_name = list(functions.preprocessing(query))\n",
    "    query_tokens_city = list(functions.preprocessing(query))\n",
    "    query_tokens_cuisine = list(functions.preprocessing(query))\n",
    "\n",
    "    # Initialize dictionaries to store cosine similarities for each field\n",
    "    cosine_similarities_name = calculate_cosine_similarity_enanched(query_tokens_name, inverted_index_name, vocabulary_dict_name, doc_tf_idf_scores_name)\n",
    "    cosine_similarities_city = calculate_cosine_similarity_enanched(query_tokens_city, inverted_index_city, vocabulary_dict_city, doc_tf_idf_scores_city)\n",
    "    cosine_similarities_cuisine = calculate_cosine_similarity_enanched(query_tokens_cuisine, inverted_index_cuisine, vocabulary_dict_cuisine, doc_tf_idf_scores_cuisine)\n",
    "\n",
    "    # Aggregate scores from all fields\n",
    "    aggregated_scores = defaultdict(float)\n",
    "    for doc_id in cosine_similarities_name:\n",
    "        aggregated_scores[doc_id] += cosine_similarities_name.get(doc_id, 0)\n",
    "    for doc_id in cosine_similarities_city:\n",
    "        aggregated_scores[doc_id] += cosine_similarities_city.get(doc_id, 0)\n",
    "    for doc_id in cosine_similarities_cuisine:\n",
    "        aggregated_scores[doc_id] += cosine_similarities_cuisine.get(doc_id, 0)\n",
    "\n",
    "    # Sort aggregated scores in descending order\n",
    "    sorted_docs = sorted(aggregated_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Get top-k results\n",
    "    top_k = sorted_docs[:k]\n",
    "    top_k_ids = [doc_id for doc_id, _ in top_k]\n",
    "    top_k_scores = [score for _, score in top_k]\n",
    "\n",
    "    # Prepare final DataFrame with restaurant information and similarity scores\n",
    "    results_df = df.loc[top_k_ids][['restaurantName', 'address', 'cuisineType', 'priceRange', 'website']]\n",
    "    results_df['Similarity Score'] = top_k_scores\n",
    "\n",
    "    return results_df\n",
    "\n",
    "def calculate_cosine_similarity_enanched(query_tokens, inverted_index, vocabulary_dict, doc_tf_idf_scores):\n",
    "    '''\n",
    "    Helper function to calculate cosine similarity for a single field.\n",
    "    '''\n",
    "    query_tf_idf = []\n",
    "    n = len(doc_tf_idf_scores)  # total number of documents\n",
    "\n",
    "    # Compute TF-IDF for query terms\n",
    "    for term in query_tokens:\n",
    "        term_id = vocabulary_dict.get(term)\n",
    "        if term_id is None:\n",
    "            continue\n",
    "        n_term = len(inverted_index[term_id])\n",
    "        IDF = np.log10(n / n_term) if n_term else 0\n",
    "        TF = query_tokens.count(term)\n",
    "        query_tf_idf.append((term_id, TF * IDF))\n",
    "\n",
    "    # Normalize query vector\n",
    "    query_norm = np.linalg.norm([score for _, score in query_tf_idf])\n",
    "\n",
    "    # Calculate cosine similarity\n",
    "    cosine_similarity = defaultdict(float)\n",
    "    for doc_id in inverted_index[term_id]:\n",
    "        _, doc_scores = zip(*doc_tf_idf_scores[doc_id])\n",
    "        doc_norm = np.linalg.norm(doc_scores)\n",
    "        intersection_scores = [score for term_id, score in query_tf_idf if term_id in doc_tf_idf_scores[doc_id]]\n",
    "        cosine_similarity[doc_id] = np.dot(intersection_scores, doc_scores) / (query_norm * doc_norm) if doc_norm else 0\n",
    "    \n",
    "    return cosine_similarity\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T20:26:00.226141Z",
     "start_time": "2024-11-11T20:26:00.220363Z"
    }
   },
   "source": [
    "def top_k_restaurants_enanched(query, k=5, price_range=None, regions=None, credit_cards=None, facilities=None):\n",
    "    '''\n",
    "    Find the top k restaurants matching the query by aggregating similarity scores across fields.\n",
    "    Applies additional filters for price range, region, accepted credit cards, and facilities.\n",
    "    '''\n",
    "    # Process the query for each field\n",
    "    query_tokens_name = list(functions.preprocessing(query))\n",
    "    query_tokens_city = list(functions.preprocessing(query))\n",
    "    query_tokens_cuisine = list(functions.preprocessing(query))\n",
    "\n",
    "    # Initialize dictionaries to store cosine similarities for each field\n",
    "    cosine_similarities_name = calculate_cosine_similarity_enanched(query_tokens_name, inverted_index_name, vocabulary_dict_name, doc_tf_idf_scores_name)\n",
    "    cosine_similarities_city = calculate_cosine_similarity_enanched(query_tokens_city, inverted_index_city, vocabulary_dict_city, doc_tf_idf_scores_city)\n",
    "    cosine_similarities_cuisine = calculate_cosine_similarity_enanched(query_tokens_cuisine, inverted_index_cuisine, vocabulary_dict_cuisine, doc_tf_idf_scores_cuisine)\n",
    "\n",
    "    # Aggregate scores from all fields\n",
    "    aggregated_scores = defaultdict(float)\n",
    "    for doc_id in cosine_similarities_name:\n",
    "        aggregated_scores[doc_id] += cosine_similarities_name.get(doc_id, 0)\n",
    "    for doc_id in cosine_similarities_city:\n",
    "        aggregated_scores[doc_id] += cosine_similarities_city.get(doc_id, 0)\n",
    "    for doc_id in cosine_similarities_cuisine:\n",
    "        aggregated_scores[doc_id] += cosine_similarities_cuisine.get(doc_id, 0)\n",
    "\n",
    "    # Sort aggregated scores in descending order\n",
    "    sorted_docs = sorted(aggregated_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Get top-k results\n",
    "    top_k = sorted_docs[:k]\n",
    "    top_k_ids = [doc_id for doc_id, _ in top_k]\n",
    "    top_k_scores = [score for _, score in top_k]\n",
    "\n",
    "    # Prepare final DataFrame with restaurant information and similarity scores\n",
    "    results_df = df.loc[top_k_ids][['restaurantName', 'address', 'description', 'website', 'priceRange', 'region', 'acceptedCreditCards', 'servicesFacilities']]\n",
    "    results_df['Similarity Score'] = top_k_scores\n",
    "\n",
    "    # Apply price range filter if provided\n",
    "    if price_range:\n",
    "        results_df = results_df[results_df['priceRange'].isin(price_range)]\n",
    "\n",
    "    # Apply region filter if provided\n",
    "    if regions:\n",
    "        results_df = results_df[results_df['region'].isin(regions)]\n",
    "\n",
    "    # Apply accepted credit cards filter if provided\n",
    "    if credit_cards:\n",
    "        results_df = results_df[results_df['acceptedCreditCards'].apply(lambda x: any(card in x for card in credit_cards))]\n",
    "\n",
    "    # Apply services and facilities filter if provided\n",
    "    if facilities:\n",
    "        results_df = results_df[results_df['servicesFacilities'].apply(lambda x: all(facility in x for facility in facilities))]\n",
    "\n",
    "    return results_df\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T20:26:02.154488Z",
     "start_time": "2024-11-11T20:26:02.148829Z"
    }
   },
   "source": [
    "def calculate_cosine_similarity_enanched(query_tokens, inverted_index, vocabulary_dict, doc_tf_idf_scores):\n",
    "    '''\n",
    "    Helper function to calculate cosine similarity for a single field.\n",
    "    '''\n",
    "    query_tf_idf = []\n",
    "    n = len(doc_tf_idf_scores)  # total number of documents\n",
    "\n",
    "    # Compute TF-IDF for query terms\n",
    "    for term in query_tokens:\n",
    "        term_id = vocabulary_dict.get(term)\n",
    "        if term_id is None:\n",
    "            continue\n",
    "        n_term = len(inverted_index[term_id])\n",
    "        IDF = np.log10(n / n_term) if n_term else 0\n",
    "        TF = query_tokens.count(term)\n",
    "        query_tf_idf.append((term_id, TF * IDF))\n",
    "\n",
    "    # Normalize query vector\n",
    "    query_norm = np.linalg.norm([score for _, score in query_tf_idf])\n",
    "\n",
    "    # Calculate cosine similarity\n",
    "    cosine_similarity = defaultdict(float)\n",
    "    for term_id, query_score in query_tf_idf:\n",
    "        if term_id not in inverted_index:\n",
    "            continue  # Skip terms not in the index\n",
    "        \n",
    "        # Process each document containing this term\n",
    "        for doc_id, doc_score in inverted_index[term_id]:\n",
    "            if doc_id not in doc_tf_idf_scores or not doc_tf_idf_scores[doc_id]:\n",
    "                continue  # Skip if doc_id is missing or empty in doc_tf_idf_scores\n",
    "            \n",
    "            # Retrieve document scores and normalize\n",
    "            _, doc_scores = zip(*doc_tf_idf_scores[doc_id])\n",
    "            doc_norm = np.linalg.norm(doc_scores)\n",
    "            if doc_norm == 0:\n",
    "                continue  # Avoid division by zero\n",
    "            \n",
    "            # Calculate cosine similarity for current document\n",
    "            cosine_similarity[doc_id] += (query_score * doc_score) / (query_norm * doc_norm) if query_norm else 0\n",
    "            cosine_similarity[doc_id] = cosine_similarity[doc_id] / 3\n",
    "            \n",
    "    return cosine_similarity\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "top_k_restaurants_enanched(\n",
    "    'Filippino Lipari Seafood, Sicilian',\n",
    "    k=5,\n",
    "    price_range=['€', '€€€'],\n",
    "    regions=['Sicilia', 'Campania'],\n",
    "    credit_cards=['Visa', 'Amex'],\n",
    "    facilities=['Wi-Fi', 'Terrace']\n",
    ")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T20:17:57.176211Z",
     "start_time": "2024-11-11T20:17:57.168286Z"
    }
   },
   "source": [
    "top_k_restaurants_enanched('Filippino Lipari Seafood, Sicilian')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T20:26:12.816642Z",
     "start_time": "2024-11-11T20:26:12.810349Z"
    }
   },
   "source": [
    "df.head()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-13T08:27:54.337823Z",
     "start_time": "2024-11-13T08:27:54.324815Z"
    }
   },
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "# Dati simulati\n",
    "cuisine_types = [\"Italian\", \"Japanese\", \"Mexican\", \"Indian\"]\n",
    "facilities = [\"WiFi\", \"Parking\", \"Outdoor Seating\", \"Pet Friendly\"]\n",
    "price_ranges = [\"$\", \"$$\", \"$$$\", \"$$$$\"]\n",
    "\n",
    "# Creazione dei widget\n",
    "search_input = widgets.Text(placeholder=\"Type to search...\", description=\"Description:\")\n",
    "cuisine_dropdown = widgets.Dropdown(\n",
    "    options=[\"All\"] + cuisine_types,\n",
    "    value=\"All\",\n",
    "    description=\"Cuisine Type:\"\n",
    ")\n",
    "facilities_checkboxes = [widgets.Checkbox(value=False, description=facility) for facility in facilities]\n",
    "price_dropdown = widgets.Dropdown(\n",
    "    options=[\"All\"] + price_ranges,\n",
    "    value=\"All\",\n",
    "    description=\"Price Range:\"\n",
    ")\n",
    "num_results_slider = widgets.IntSlider(value=5, min=1, max=50, step=1, description=\"Results:\")\n",
    "\n",
    "search_button = widgets.Button(description=\"Search\", button_style=\"success\")\n",
    "clear_button = widgets.Button(description=\"Clear\", button_style=\"danger\")\n",
    "\n",
    "# Funzioni di ricerca e di reset\n",
    "def on_search_clicked(b):\n",
    "    search_params = {\n",
    "        \"description\": search_input.value,\n",
    "        \"cuisine_type\": cuisine_dropdown.value,\n",
    "        \"facilities_services\": [cb.description for cb in facilities_checkboxes if cb.value],\n",
    "        \"price_range\": price_dropdown.value,\n",
    "        \"num_results\": num_results_slider.value\n",
    "    }\n",
    "    clear_output()\n",
    "    display_widgets()\n",
    "    print(\"Search Parameters:\", search_params)\n",
    "\n",
    "def on_clear_clicked(b):\n",
    "    search_input.value = \"\"\n",
    "    cuisine_dropdown.value = \"All\"\n",
    "    for cb in facilities_checkboxes:\n",
    "        cb.value = False\n",
    "    price_dropdown.value = \"All\"\n",
    "    num_results_slider.value = 5\n",
    "    clear_output()\n",
    "    display_widgets()\n",
    "\n",
    "# Collegamento dei pulsanti con le funzioni\n",
    "search_button.on_click(on_search_clicked)\n",
    "clear_button.on_click(on_clear_clicked)\n",
    "\n",
    "# Funzione per visualizzare tutti i widget\n",
    "def display_widgets():\n",
    "    display(\n",
    "        widgets.VBox([\n",
    "            search_input,\n",
    "            cuisine_dropdown,\n",
    "            widgets.VBox(facilities_checkboxes),\n",
    "            price_dropdown,\n",
    "            num_results_slider,\n",
    "            widgets.HBox([search_button, clear_button])\n",
    "        ])\n",
    "    )\n",
    "\n",
    "# Mostrare l'interfaccia\n",
    "display_widgets()\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-13T09:02:41.492769Z",
     "start_time": "2024-11-13T09:02:40.438664Z"
    }
   },
   "source": [
    "import dash\n",
    "from dash import dcc, html\n",
    "from dash.dependencies import Input, Output, State\n",
    "import plotly.express as px\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Carica i dati dei ristoranti e delle fasce di prezzo\n",
    "restaurants_df = pd.read_csv('geocode.tsv', sep=\"\\t\", usecols=['restaurantName', 'region', 'latitude', 'longitude'])\n",
    "priceRangeDF = pd.read_csv('restaurants_data.tsv', sep=\"\\t\", usecols=['restaurantName', 'priceRange'])\n",
    "restaurants_df = restaurants_df.merge(priceRangeDF, on='restaurantName', how='right')\n",
    "\n",
    "# Carica il file GeoJSON delle regioni italiane\n",
    "gdf = gpd.read_file(\"./GeoJson/limits_IT_regions.geojson\")\n",
    "if gdf.crs != \"EPSG:4326\":\n",
    "    gdf = gdf.to_crs(\"EPSG:4326\")\n",
    "\n",
    "# Funzione per eseguire la ricerca personalizzata dei ristoranti (simulazione)\n",
    "def custom_search_restaurants(region_name, price_range=None):\n",
    "    # Filtro per regione e, se specificato, per fascia di prezzo\n",
    "    filtered_df = restaurants_df[restaurants_df['region'] == (\" \" + region_name)]\n",
    "    if price_range:\n",
    "        filtered_df = filtered_df[filtered_df['priceRange'] == price_range]\n",
    "    return filtered_df\n",
    "\n",
    "# Crea l'app Dash\n",
    "app = dash.Dash(__name__)\n",
    "\n",
    "app.layout = html.Div([\n",
    "    # Mappa Italia e selezione checkbox\n",
    "    html.Div([\n",
    "        dcc.Graph(id='italy-map', clickData=None, style={'width': '50vw', 'height': '100vh'}),\n",
    "        dcc.Graph(id='region-map', style={'width': '50vw', 'height': '100vh'})\n",
    "    ], style={'display': 'flex', 'flex-direction': 'row'}),\n",
    "\n",
    "    # Checkbox e pulsante per la visualizzazione dei ristoranti\n",
    "    html.Div([\n",
    "        dcc.Checklist(\n",
    "            id='show-restaurants',\n",
    "            options=[{'label': 'Mostra Ristoranti', 'value': 'show'}],\n",
    "            value=[],\n",
    "            labelStyle={'display': 'inline-block'}\n",
    "        ),\n",
    "        html.Button('Cerca Ristoranti', id='search-restaurants-btn', n_clicks=0),\n",
    "    ], style={'textAlign': 'center', 'padding': '10px'})\n",
    "])\n",
    "\n",
    "# Callback per la mappa dell'Italia\n",
    "@app.callback(\n",
    "    Output('italy-map', 'figure'),\n",
    "    Input('italy-map', 'clickData')\n",
    ")\n",
    "def update_italy_map(clickData):\n",
    "    selected_region = None\n",
    "    if clickData:\n",
    "        selected_region = clickData['points'][0]['location']\n",
    "    \n",
    "    fig = px.choropleth_mapbox(\n",
    "        geojson=json.loads(gdf.to_json()),\n",
    "        locations=gdf['reg_name'],\n",
    "        featureidkey=\"properties.reg_name\",\n",
    "        color_discrete_sequence=['grey'],\n",
    "        opacity=0.2,\n",
    "        mapbox_style=\"carto-positron\",\n",
    "        zoom=4.5,\n",
    "        center={\"lat\": 41.8719, \"lon\": 12.5674},\n",
    "        title=\"Mappa delle Regioni Italiane\"\n",
    "    )\n",
    "    \n",
    "    if selected_region:\n",
    "        fig.update_traces(marker_line_color=\"red\", selector=dict(location=selected_region))\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# Callback per la mappa della regione selezionata e la visualizzazione dei ristoranti\n",
    "@app.callback(\n",
    "    Output('region-map', 'figure'),\n",
    "    [Input('italy-map', 'clickData'),\n",
    "     Input('show-restaurants', 'value'),\n",
    "     Input('search-restaurants-btn', 'n_clicks')],\n",
    "    [State('italy-map', 'clickData')]\n",
    ")\n",
    "def display_selected_region(clickData, show_restaurants, n_clicks, clickData_state):\n",
    "    # Determina se mostrare tutti i ristoranti o filtrare i risultati di ricerca\n",
    "    if not clickData:\n",
    "        return {}\n",
    "\n",
    "    selected_region = clickData['points'][0]['location']\n",
    "    region_gdf = gdf[gdf['reg_name'] == selected_region]\n",
    "    region_gdf_proj = region_gdf.to_crs(epsg=32632)\n",
    "    centroid_proj = region_gdf_proj.geometry.centroid.iloc[0]\n",
    "    centroid = gpd.GeoSeries([centroid_proj], crs=\"EPSG:32632\").to_crs(\"EPSG:4326\").iloc[0]\n",
    "    center_lat, center_lon = centroid.y, centroid.x\n",
    "\n",
    "    # Usa custom_search_restaurants solo se il pulsante \"Cerca Ristoranti\" è stato cliccato\n",
    "    if n_clicks > 0:\n",
    "        filtered_restaurants = custom_search_restaurants(selected_region)\n",
    "    else:\n",
    "        filtered_restaurants = restaurants_df[restaurants_df['region'] == (\" \" + selected_region)]\n",
    "\n",
    "    fig = px.choropleth_mapbox(\n",
    "        geojson=json.loads(region_gdf.to_json()),\n",
    "        locations=[selected_region],\n",
    "        featureidkey=\"properties.reg_name\",\n",
    "        mapbox_style=\"carto-positron\",\n",
    "        color_discrete_sequence=['red'],\n",
    "        opacity=0.1,\n",
    "        zoom=6,\n",
    "        center={\"lat\": center_lat, \"lon\": center_lon},\n",
    "        title=f\"Mappa di {selected_region} con Ristoranti\"\n",
    "    )\n",
    "\n",
    "    if 'show' in show_restaurants:\n",
    "        for price, color in zip([\"€\", \"€€\", \"€€€\", \"€€€€\"], [\"blue\", \"green\", \"purple\", \"brown\"]):\n",
    "            price_restaurants = filtered_restaurants[filtered_restaurants['priceRange'] == price]\n",
    "            fig.add_scattermapbox(\n",
    "                lat=price_restaurants['latitude'].tolist(),\n",
    "                lon=price_restaurants['longitude'].tolist(),\n",
    "                mode='markers',\n",
    "                marker=dict(size=10, color=color, opacity=0.8),\n",
    "                text=price_restaurants['restaurantName'],\n",
    "                name=price,\n",
    "                hovertemplate=(\n",
    "                    \"<b>Nome Ristorante:</b> %{text}<br>\"\n",
    "                    \"<b>Latitudine:</b> %{lat}<br>\"\n",
    "                    \"<b>Longitudine:</b> %{lon}<br>\"\n",
    "                )\n",
    "            )\n",
    "\n",
    "    fig.update_layout(\n",
    "        mapbox=dict(\n",
    "            layers=[\n",
    "                {\n",
    "                    'source': json.loads(region_gdf.to_json()), \n",
    "                    'type': \"line\",\n",
    "                    'color': \"black\",\n",
    "                    'line': {'width': 0.5}\n",
    "                }\n",
    "            ]\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# Avvia l'app Dash\n",
    "if __name__ == '__main__':\n",
    "    app.run_server(jupyter_mode = 'external', debug=True)\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T13:57:39.764390Z",
     "start_time": "2024-11-14T13:57:39.753683Z"
    }
   },
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output, HTML\n",
    "import pandas as pd\n",
    "from itertools import chain\n",
    "\n",
    "class RestaurantSearchInterface:\n",
    "    def __init__(self, df, vocabulary_df, inverted_index):\n",
    "        \"\"\"\n",
    "        Initialize the search interface with the enhanced search engine.\n",
    "        \"\"\"\n",
    "        self.df = df\n",
    "        self.vocabulary_df = vocabulary_df\n",
    "        self.inverted_index = inverted_index\n",
    "        \n",
    "        self.cuisine_types = ['All Cuisines'] + sorted(df['cuisineType'].dropna().unique().tolist())\n",
    "        self.facilities = sorted(list(set(chain(*df['facilitiesServices'].apply(eval)))))\n",
    "        self.price_ranges = ['All Prices'] + sorted(df['priceRange'].dropna().unique().tolist())\n",
    "        \n",
    "        # Create widgets\n",
    "        self.create_widgets()\n",
    "        \n",
    "    def create_widgets(self):\n",
    "        # Search text input\n",
    "        self.search_text = widgets.Text(\n",
    "            description='Search:',\n",
    "            placeholder='Enter keywords (e.g., Greek, pasta...)',\n",
    "            layout=widgets.Layout(width='70%')\n",
    "        )\n",
    "        \n",
    "        # Number of results slider\n",
    "        self.results_select = widgets.IntSlider(\n",
    "            min=1,\n",
    "            max=20,\n",
    "            step=1,\n",
    "            value=5,\n",
    "            description='Show top:',\n",
    "            style={'description_width': 'initial'},\n",
    "            layout=widgets.Layout(width='70%')\n",
    "        )\n",
    "\n",
    "        # Cuisine type dropdown\n",
    "        self.cuisine_select = widgets.Dropdown(\n",
    "            options=self.cuisine_types,\n",
    "            description='Cuisine:',\n",
    "            value='All Cuisines',\n",
    "            layout=widgets.Layout(width='70%')\n",
    "        )\n",
    "        \n",
    "        # Price range dropdown\n",
    "        self.price_select = widgets.Dropdown(\n",
    "            options=self.price_ranges,\n",
    "            description='Price:',\n",
    "            value='All Prices',\n",
    "            layout=widgets.Layout(width='70%')\n",
    "        )\n",
    "        \n",
    "        # Facilities checkboxes\n",
    "        self.facilities_boxes = [\n",
    "            widgets.Checkbox(\n",
    "                value=False,\n",
    "                description=facility,\n",
    "                layout=widgets.Layout(width='auto')\n",
    "            ) for facility in self.facilities\n",
    "        ]\n",
    "        \n",
    "        # Facilities container\n",
    "        self.facilities_box = widgets.VBox([\n",
    "            widgets.HTML(\"<h4 style='margin:10px 0;'>Select Facilities:</h4>\"),\n",
    "            widgets.Box(self.facilities_boxes, layout=widgets.Layout(display='flex', flex_wrap='wrap'))\n",
    "        ])\n",
    "        \n",
    "        # Search and clear buttons\n",
    "        self.search_button = widgets.Button(\n",
    "            description='🔍 Search',\n",
    "            button_style='success',\n",
    "            layout=widgets.Layout(width='30%', margin='10px 5px')\n",
    "        )\n",
    "        self.clear_button = widgets.Button(\n",
    "            description='✖ Clear',\n",
    "            button_style='danger',\n",
    "            layout=widgets.Layout(width='30%', margin='10px 5px')\n",
    "        )\n",
    "        \n",
    "        # Output area\n",
    "        self.output = widgets.Output()\n",
    "        \n",
    "        # Button actions\n",
    "        self.search_button.on_click(self.handle_search)\n",
    "        self.clear_button.on_click(self.handle_clear)\n",
    "\n",
    "    def format_results_as_table(self, results):\n",
    "        \"\"\"Format search results as an HTML table with CSS styling.\"\"\"\n",
    "        table_style = \"\"\"\n",
    "        <style>\n",
    "        .search-results { width: 100%; border-collapse: collapse; margin: 20px 0; font-size: 15px; }\n",
    "        .search-results th, .search-results td { padding: 12px; text-align: left; border: 1px solid #ddd; }\n",
    "        .search-results th { background-color: #4CAF50; color: white; }\n",
    "        .search-results tr:nth-child(even) { background-color: #f2f2f2; }\n",
    "        .search-results tr:hover { background-color: #ddd; }\n",
    "        </style>\n",
    "        \"\"\"\n",
    "        \n",
    "        html = table_style + '<table class=\"search-results\">'\n",
    "        headers = ['Name', 'Address', 'Description', 'Website', 'Score']\n",
    "        html += '<tr>' + ''.join([f'<th>{h}</th>' for h in headers]) + '</tr>'\n",
    "        for _, row in results.iterrows():\n",
    "            html += '<tr>'\n",
    "            html += f'<td>{row[\"restaurantName\"]}</td>'\n",
    "            html += f'<td>{row[\"address\"]}</td>'\n",
    "            desc = row['description'][:150] + '...' if len(row['description']) > 150 else row['description']\n",
    "            html += f'<td>{desc}</td>'\n",
    "            html += f'<td>{row[\"website\"]}</td>'\n",
    "            html += f'<td>{row[\"customScore\"]:.3f}</td>'\n",
    "            html += '</tr>'\n",
    "            \n",
    "        html += '</table>'\n",
    "        return html\n",
    "\n",
    "    def handle_search(self, button):\n",
    "        \"\"\"Handle the search button click.\"\"\"\n",
    "        with self.output:\n",
    "            clear_output()\n",
    "            \n",
    "            #query = self.search_text.value.strip()\n",
    "            #if not query:\n",
    "            #    display(HTML(\"<p style='color:red;'>Please enter a search query.</p>\"))\n",
    "            #    return\n",
    "                \n",
    "            #cuisine = None if self.cuisine_select.value == 'All Cuisines' else self.cuisine_select.value\n",
    "            #price_range = None if self.price_select.value == 'All Prices' else self.price_select.value\n",
    "            \n",
    "            #facilities = [f.description for f in self.facilities_boxes if f.value]\n",
    "            #facilities = facilities if facilities else None\n",
    "            \n",
    "            #k = self.results_select.value\n",
    "            \n",
    "            try:\n",
    "                # Raccolta dei valori inseriti dall'utente\n",
    "                query = {\n",
    "                    'description': self.search_text.value.strip(),\n",
    "                    'cuisineType': None if self.cuisine_select.value == 'All Cuisines' else self.cuisine_select.value,\n",
    "                    'facilitiesServices': [f.description for f in self.facilities_boxes if f.value],\n",
    "                    'priceRange': None if self.price_select.value == 'All Prices' else self.price_select.value,\n",
    "                    'num_results': self.results_select.value\n",
    "                }\n",
    "\n",
    "                # Chiamata alla funzione di ricerca\n",
    "                results = functions.find_top_custom_restaurants(\n",
    "                    query,\n",
    "                    self.vocabulary_df,\n",
    "                    self.inverted_index,\n",
    "                    self.df\n",
    "                )\n",
    "                if results.empty:\n",
    "                    display(HTML(\"<p style='color:orange;'>No results found.</p>\"))\n",
    "                else:\n",
    "                    display(HTML(f\"<p style='color:green;'>Found {len(results)} results:</p>\"))\n",
    "                    display(HTML(self.format_results_as_table(results)))\n",
    "                    \n",
    "            except Exception as e:\n",
    "                display(HTML(f\"<p style='color:red;'>An error occurred: {str(e)}</p>\"))\n",
    "    \n",
    "    def handle_clear(self, button):\n",
    "        \"\"\"Clear all fields and reset the output area.\"\"\"\n",
    "        self.search_text.value = ''\n",
    "        self.cuisine_select.value = 'All Cuisines'\n",
    "        self.price_select.value = 'All Prices'\n",
    "        for checkbox in self.facilities_boxes:\n",
    "            checkbox.value = False\n",
    "        self.results_select.value = 5\n",
    "        with self.output:\n",
    "            clear_output()\n",
    "    \n",
    "    def display_interface(self):\n",
    "        \"\"\"Display the complete search interface.\"\"\"\n",
    "        search_box = widgets.VBox([\n",
    "            widgets.HTML(\"<h2 style='text-align:center; color:#4CAF50;'>Restaurant Search</h2>\"),\n",
    "            widgets.HBox([self.search_text, self.results_select]),\n",
    "            self.cuisine_select,\n",
    "            self.price_select,\n",
    "            self.facilities_box,\n",
    "            widgets.HBox([self.search_button, self.clear_button]),\n",
    "            self.output\n",
    "        ])\n",
    "        \n",
    "        display(search_box)\n"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T13:57:41.513360Z",
     "start_time": "2024-11-14T13:57:41.481770Z"
    }
   },
   "source": [
    "search_ui = RestaurantSearchInterface(df, vocabulary_df, inverted_index)\n",
    "search_ui.display_interface()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VBox(children=(HTML(value=\"<h2 style='text-align:center; color:#4CAF50;'>Restaurant Search</h2>\"), HBox(childr…"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a127f9facbb848ad9cabac8825141413"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Algorithmic Question (AQ)"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## PseudoCode"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The intuition is that, starting from the origin (0, 0) in the first quadrant where all packages are located, the first package is always reachable. Given that we can only move up or right, we can only reach packages that are above or to the right of the current one. Therefore, for each package reached, we need to check the next one: if it is below or to the left, we can print \"NO\" because it’s unreachable. Otherwise, we proceed, but to ensure the lexicographically smallest path, we need to sort all packages in ascending order by their coordinates."
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "for each test case (t): read n\n",
    "\n",
    "packages = []\n",
    "\n",
    "for i = 1 to n: O(n) read x[i], y[i] append (x[i], y[i]) to packages\n",
    "\n",
    "sort packages by x, then by y O(n Log n)\n",
    "\n",
    "x_current, y_current = 0, 0 path = '' possible = True\n",
    "\n",
    "for x[i], y[i] in packages: O(n) if x[i] < x_current or y[i] < y_current: possible = False break num_right_moves = x[i] - x_current num_up_moves = y[i] - y_current\n",
    "\n",
    "path += \"R\" * num_right_moves path += \"U\" * num_up_moves\n",
    "\n",
    "x_current = x[i] y_current = y[i]\n",
    "\n",
    "if possible: print(\"YES\") print(path) else: print(\"NO\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
