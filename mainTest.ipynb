{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4E4cWhSzcIK9"
   },
   "source": [
    "# ADM-HW3: GROUP #14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Xavier Del Giudice, Alessio Iacono, Geraldine Maurer\n",
    "\n",
    "\n",
    "| STUDENT |   ID    |                 E-mail                  |\n",
    "| :-: |:-------:|:---------------------------------------:|\n",
    "| Xavier Del Giudice | 1967219 | delgiudice.1967219@studenti.uniroma1.it |\n",
    "| Alessio Iacono | 1870276 |   iacono.1870276@studenti.uniroma1.it   |\n",
    "| Geraldine Maurer | 1996887 |           gmaurer0@gmail.com            |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-15T15:00:34.704498Z",
     "start_time": "2024-11-15T15:00:33.135980Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "illQRCTCZg4v",
    "outputId": "45f1c85d-efd3-40f6-eebf-364c9b9493de"
   },
   "outputs": [],
   "source": [
    "%pip install unidecode geopy plotly dash aiofiles aiohttp nltk ipywidgets requests bs4 pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-16T16:24:13.434550Z",
     "start_time": "2024-11-16T16:24:12.356275Z"
    }
   },
   "outputs": [],
   "source": [
    "import heapq\n",
    "import nltk\n",
    "import os\n",
    "import re\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from unidecode import unidecode\n",
    "import string\n",
    "import unicodedata\n",
    "from IPython.display import display, clear_output\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import pickle\n",
    "import ipywidgets\n",
    "import ipywidgets as ipw\n",
    "from itertools import chain\n",
    "from functions import utils, engine, crawler, parser\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H4za-YIOXRhy"
   },
   "source": [
    "# 1. Data Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Get the list of Michelin restaurants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jWjzIJ4hUMUV",
    "outputId": "ddbcd81e-01c5-4aee-b499-4a398b4f1dea"
   },
   "outputs": [],
   "source": [
    "# Initial url of the Michelin guide where to start scraping\n",
    "base_url = 'https://guide.michelin.com/en/it/restaurants/page/'\n",
    "# Pathname of .txt file where URLs will be stored\n",
    "txt_out_pathname = 'michelin_restaurant_urls.txt'\n",
    "\n",
    "# Start txt crawling\n",
    "crawler.crawl_restaurant_links(base_url, txt_out_pathname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Crawl Michelin restaurant pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pathname of .txt file where URLs are stored\n",
    "file_path = 'michelin_restaurant_urls.txt'\n",
    "# Pathname of directory where HTML pages will be stored\n",
    "output_dir = 'downloads'\n",
    "\n",
    "async def main():\n",
    "    # Load URLs from a file\n",
    "    urls = await crawler.load_urls(file_path)\n",
    "    # Download all URLs, organizing them into folders\n",
    "    await crawler.download_all(urls, output_dir)\n",
    "\n",
    "await main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Parse downloaded pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory containing the downloaded HTML files\n",
    "output_dir = 'downloads'\n",
    "# Pathname of .tsv where final dataset will be stored\n",
    "tsv_pathname = 'restaurants_data.tsv'\n",
    "\n",
    "# Create a pandas DataFrame from data scraped from HTML pages and then save it to .tsv file\n",
    "df = pd.DataFrame(utils.iterate_folders(output_dir))\n",
    "df.to_csv(tsv_pathname, sep='\\t', index=False)\n",
    "\n",
    "print(f\"Data saved to {tsv_pathname}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert NaN values in the dataset to empty strings (as required)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read dataset from .tsv and convert NaN values to empty string\n",
    "df = pd.read_csv('restaurants_data.tsv', sep='\\t')\n",
    "df = df.fillna(\"\")\n",
    "\n",
    "# Update .tsv file\n",
    "df.to_csv('restaurants_data.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q1i9zzfhXXhb"
   },
   "source": [
    "# 2. Search Engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "utldng-rXa_9"
   },
   "source": [
    "## 2.0 Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We collected all the useful defined functions that we used to run the Engine, in the specified file: ```engine.py```.\n",
    "You can find it in the folder ````functions````... TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is to preprocess the restaurant descriptions. For this, we use the custom-made function ```preprocessing```, and save all pre-processed documents in a list of documents ```preprocessed_docs```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-16T16:24:33.349232Z",
     "start_time": "2024-11-16T16:24:33.329366Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('restaurants_data.tsv', sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-16T16:24:34.013233Z",
     "start_time": "2024-11-16T16:24:34.005865Z"
    }
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-16T16:04:59.752813Z",
     "start_time": "2024-11-16T16:04:57.696135Z"
    }
   },
   "outputs": [],
   "source": [
    "preprocessed_docs = defaultdict(list) # initialize defaultdict to store preprocessed docs\n",
    "for doc_id, doc in enumerate(df.description):\n",
    "  preprocessed_docs[doc_id] = engine.preprocessing(doc) # preprocess doc at position doc_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-16T14:55:36.911626Z",
     "start_time": "2024-11-16T14:55:36.907693Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rRWQ7HxDX1oY",
    "outputId": "1a78081f-abe8-4cf5-f25d-c9b19976a6f9"
   },
   "outputs": [],
   "source": [
    "# Test description\n",
    "text = '''After many years' experience in Michelin-starred restaurants, Luigi Tramontano and his wife Nicoletta\n",
    "have opened their first restaurant in the chef's native Gargnano. Previously a pasta factory, the building has been converted\n",
    "into an elegant, contemporary-style restaurant which has nonetheless retained its charming high ceilings.\n",
    "The cuisine is inspired by regional traditions which are reinterpreted to create gourmet dishes,\n",
    "all prepared with respect for the ingredients used and a strong focus on local produce.'''\n",
    "\n",
    "# Test preprocessing on test description\n",
    "print(engine.preprocessing(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DO0y6xQyfcyJ"
   },
   "source": [
    "## 2.1 Conjunctive Query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "faZun-BPfgJm"
   },
   "source": [
    "### 2.1.1 Create your Index!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following code cells, we preprocess all restaurant descriptions and 1. save unique tokens in a DataFrame ```vocabulary_df``` that maps terms to unique integer IDs, then 2. compute the inverted index for the documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-16T16:05:56.679662Z",
     "start_time": "2024-11-16T16:05:56.454933Z"
    },
    "id": "jCv8kfkcfnKl"
   },
   "outputs": [],
   "source": [
    "# 1. Vocabulary File\n",
    "\n",
    "# Retrieve the restaurants DataFrame\n",
    "df = pd.read_csv('restaurants_data.tsv', sep='\\t')\n",
    "\n",
    "doc_tokens = [] # initialize list to store all tokens\n",
    "\n",
    "# Find unique tokens\n",
    "for doc in preprocessed_docs.values():\n",
    "  doc_tokens.extend(doc)\n",
    "  doc_tokens = list(set(doc_tokens)) # remove duplicates\n",
    "\n",
    "vocabulary_dict = {term: i for i,term in enumerate(doc_tokens)} # dictionary of all vocabulary terms\n",
    "vocabulary_df = pd.DataFrame({'term': vocabulary_dict.keys(), 'term_id': vocabulary_dict.values()}) # dataframe that maps terms to IDs\n",
    "\n",
    "vocabulary_df.to_csv('vocabulary.csv', index=False) # save vocabulary dataframe in a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-16T16:05:57.821361Z",
     "start_time": "2024-11-16T16:05:57.760443Z"
    },
    "id": "QI3YYNZMhpC_"
   },
   "outputs": [],
   "source": [
    "# 2. Inverted Index\n",
    "\n",
    "inverted_index = defaultdict(list) # initialize inverted_index dictionary\n",
    "\n",
    "# Compute the inverted_index\n",
    "for doc_id, row in enumerate(df.description):\n",
    "  tokens = set(preprocessed_docs[doc_id]) # preprocessed description\n",
    "  for token in tokens: # eliminate duplicates\n",
    "    # Look up the term_id of the current term/token\n",
    "    term_id = vocabulary_dict[token]\n",
    "    # If the doc_id is not in the term_id's list in inverted_index, add it\n",
    "    if doc_id not in inverted_index[term_id]:\n",
    "      inverted_index[term_id].append(doc_id)\n",
    "\n",
    "# Save the inverted_index dictionary to a file\n",
    "with open(\"inverted_index.pkl\", \"wb\") as file:\n",
    "    pickle.dump(inverted_index, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we allow the user to input a query. After clicking on search, the first search engine will be triggered to retrieve all restaurants that contain in their description the same terms as the query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-16T14:55:41.259316Z",
     "start_time": "2024-11-16T14:55:41.245289Z"
    },
    "id": "mstIv_0qlqXw"
   },
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "# re-load inverted index in case it was modified somewhere\n",
    "with open('inverted_index.pkl', 'rb') as file:\n",
    "    inverted_index = pickle.load(file)\n",
    "\n",
    "# Text input field for query\n",
    "text_input = widgets.Text(\n",
    "    value='',\n",
    "    placeholder='Type your query',\n",
    "    description='Query:',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "# Search button\n",
    "search_button = widgets.Button(\n",
    "    description='Search',\n",
    "    disabled=False,\n",
    "    button_style='primary'\n",
    ")\n",
    "\n",
    "output = widgets.Output()\n",
    "\n",
    "# Define a function to handle button press\n",
    "def on_search_button_clicked(b):\n",
    "    with output:\n",
    "        output.clear_output()  # clear previous output if there are any\n",
    "        query = text_input.value\n",
    "        if query.strip():  # Check if there's an input\n",
    "            display(engine.find_restaurants(query, vocabulary_df, inverted_index, df)) # display query results\n",
    "        else:\n",
    "            print(\"Please enter something to search for.\")\n",
    "\n",
    "# Link the function to the button\n",
    "search_button.on_click(on_search_button_clicked)\n",
    "\n",
    "# Display the widgets\n",
    "display(text_input, search_button, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-16T13:50:41.687560Z",
     "start_time": "2024-11-16T13:50:41.669920Z"
    }
   },
   "outputs": [],
   "source": [
    "# with query: \"modern seasonal cuisine\" we obtained this result\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "92JOh6oFyPuz"
   },
   "source": [
    "## 2.2 Ranked Search Engine with TF-IDF and Cosine Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uXxrWEbzyVV2"
   },
   "source": [
    "### 2.2.1 Inverted Index with TF-IDF Scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following exercise, we will first compute the inverted index with TF-IDF scores using the custom-made function ```tf_idf``` and save the ```updated_inverted_index``` in a pickle file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-16T15:30:00.026134Z",
     "start_time": "2024-11-16T15:29:59.798728Z"
    },
    "collapsed": true,
    "id": "KNv23rrBWtxx"
   },
   "outputs": [],
   "source": [
    "# Preliminary steps\n",
    "n = len(preprocessed_docs)\n",
    "updated_inverted_index = defaultdict(list) # initialize default dictionary to store the inverted_index values with TF-IDF scores\n",
    "inverted_index_copy = inverted_index.copy() # Create a copy of the inverted_index to iterate over\n",
    "\n",
    "# Compute updated_inverted_index\n",
    "for term_id, docs in inverted_index_copy.items():\n",
    "  tf_idf_scores = engine.tf_idf(int(term_id), inverted_index, preprocessed_docs, vocabulary_df, n)\n",
    "  updated_inverted_index[term_id] = list(zip(docs, tf_idf_scores))\n",
    "\n",
    "with open('updated_inverted_index.pkl', 'wb') as file:\n",
    "    pickle.dump(updated_inverted_index, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we retrieve from ```updated_inverted_index``` the TF-IDF scores related to documents, and memorize only the tuples (term, tf-idf) where tf-idf != 0 for each document in a pickle file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-16T15:30:01.624953Z",
     "start_time": "2024-11-16T15:30:01.502794Z"
    },
    "collapsed": true,
    "id": "rLbjRaqLS9bj"
   },
   "outputs": [],
   "source": [
    "# Compute the TF-IDF vectors of all documents and store them in a pickle file\n",
    "doc_tf_idf_scores = defaultdict(list) # initialize dictionary to store non-zero TF-IDF scores for each document\n",
    "\n",
    "for term_id, docs_scores in updated_inverted_index.items():\n",
    "  for doc_id, tf_idf_score in docs_scores:\n",
    "    if tf_idf_score != 0:\n",
    "      doc_tf_idf_scores[doc_id].append((term_id,tf_idf_score))\n",
    "  doc_tf_idf_scores[doc_id].sort(key=lambda x: x[0]) # sort the terms\n",
    "\n",
    "with open('doc_tf_idf_scores.pkl', 'wb') as file:\n",
    "    pickle.dump(doc_tf_idf_scores, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we enable the user to input a text query, and return the top-k ranked restaurants by cosine similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-16T14:56:06.669413Z",
     "start_time": "2024-11-16T14:56:06.658876Z"
    },
    "id": "LXzqp1nkQ661"
   },
   "outputs": [],
   "source": [
    "# re-load inverted index in case it was modified somewhere\n",
    "with open('inverted_index.pkl', 'rb') as file:\n",
    "    inverted_index = pickle.load(file)\n",
    "\n",
    "# Text input field for query\n",
    "text_input = widgets.Text(\n",
    "    value='',\n",
    "    placeholder='Type your query',\n",
    "    description='Query:',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "# Search button\n",
    "search_button = widgets.Button(\n",
    "    description='Search',\n",
    "    disabled=False,\n",
    "    button_style='primary'\n",
    ")\n",
    "\n",
    "output = widgets.Output()\n",
    "\n",
    "# Define a function to handle button press\n",
    "def on_search_button_clicked(b):\n",
    "    with output:\n",
    "        output.clear_output()  # clear previous output if there are any\n",
    "        query = text_input.value\n",
    "        if query.strip():  # Check if there's an input\n",
    "            k = 10\n",
    "            display(engine.top_k_restaurants(query, inverted_index, vocabulary_dict, doc_tf_idf_scores, df, n, k)) # display query results\n",
    "        else:\n",
    "            print(\"Please enter something to search for.\")\n",
    "\n",
    "# Link the function to the button\n",
    "search_button.on_click(on_search_button_clicked)\n",
    "\n",
    "# Display the widgets\n",
    "display(text_input, search_button, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-16T13:56:49.258667Z",
     "start_time": "2024-11-16T13:56:49.241126Z"
    }
   },
   "outputs": [],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Define a New Score!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A user interface(UI) is used to consider the user's additive information, which allows the user to enter the fields they prefer to find the restaurant.\n",
    "We will use this additional information to predicate some of the rows in our dataset.\n",
    "Since all restaurants are filtered by text initially, we want to give lower weight to the similarity between the description and the input query.  \n",
    "Rather we want to give higher weight to user input details, which are the key to finding restaurants to which a user can bring interest.\n",
    "Specifically we prefer to give higher weight to the type of cuisine, if I were to search for a restaurant and I have a particular desire to eat that cuisine I would want those as the pirmiest search results. Sucessively we give slightly less weight to the services available and finally the least weight to the price, speaking of Michelin restaurants the price is not an issue\n",
    "We can also find this behavior in very popular search engines, for example amazon search, prefers user-selected filters over the user's even detailed content in the search bar.\n",
    "\n",
    "The results in the end turn out to be better, more accurate. We also have to consider that in the previous Engine based on the cosine similarity we are just considering the score based on the similarity between the input query and the description which is way larger than a possible query. Instead now we are building our own custom score where we give more importance to the details, infact we havebigger score for the ones that perfectly fit thee search. We are basically considernig more fileds so its obvious that the results are more accurated. But there is also to note that at the computational level this type of search is less performant since we have to initially load all the restaurants that respect the query input and then create a new score based on matching the user input and finally sort to select only the first k."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-16T13:57:10.317432Z",
     "start_time": "2024-11-16T13:57:10.310561Z"
    }
   },
   "outputs": [],
   "source": [
    "from functions.search_restaurant_ui import SearchRestaurantUI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-16T13:57:11.800861Z",
     "start_time": "2024-11-16T13:57:11.765905Z"
    }
   },
   "outputs": [],
   "source": [
    "search_ui = SearchRestaurantUI(df, vocabulary_df, inverted_index)\n",
    "search_ui.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the previous points, we can not visualize the UI just created. To let you understand what we created we are going to use an image of it.\n",
    "But if you would like to use it, you can download the code and run it in local.\n",
    "In the next cell you will see the output generated by the parameters:  \n",
    "\n",
    "**Description searched** : \"modern seasonal cuisine\"  \n",
    "\n",
    "**Cuisine Type** : \"Italian Contemporary, Creative\"  \n",
    "\n",
    "**Facilities & Services** : \"Air Conditioning, Car Park, Interesting Wine List\"  \n",
    "\n",
    "**Price Range** : \"€€€\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-16T14:10:53.954113Z",
     "start_time": "2024-11-16T14:10:53.947675Z"
    }
   },
   "outputs": [],
   "source": [
    "search_ui.output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Visualizing the Most Relevant Restaurants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Geocode Locations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In 4.1 we use geopy to get the coordinates of the restaurants and save them in the .tsv file. \n",
    "\n",
    "If some data of these restaurants is not found using geopy, their name, postal code and country are saved in a second file \"noDataRest.tsv\" to be used in any (possible) subsequent processing to recover the missing data of these restaurants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T16:32:31.472419Z",
     "start_time": "2024-11-14T16:32:00.942978Z"
    }
   },
   "outputs": [],
   "source": [
    "# Directory where .html files are stored\n",
    "output_dir = 'downloads'\n",
    "# Filename of tsv where geodata (region, latitude and longitude) of each restaurant will be saved\n",
    "tsv_filename = 'geodata.tsv'\n",
    "\n",
    "# Create a pandas DataFrame from scraped geodata\n",
    "df = pd.DataFrame(utils.iterate_geo_folders(output_dir))\n",
    "\n",
    "# Translation of italian region from english to italian name (needed for map)\n",
    "df['region'] = utils.translateRegions(df['region'])\n",
    "\n",
    "# Save the data to a CSV file\n",
    "df.to_csv(tsv_filename, sep='\\t', index=False)\n",
    "print(f\"Data saved to {tsv_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To merge the information about the restaurants and their geo-localition info we need to merge the two different table: ```restaurants_data.tsv``` and ```geodata.tsv```. </br>\n",
    "To do this we use pandas command: ```merge```, but first, to avoid duplicates and bias we defined an attribute of join. </br>\n",
    "It need to be unique for each row of the two dataset. So we defined *restaurantId* that is an autoincrement value for each row of the dataset (primarey key).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-16T16:24:40.870431Z",
     "start_time": "2024-11-16T16:24:40.862922Z"
    }
   },
   "outputs": [],
   "source": [
    "df['restaurantId'] = range(1, len(df) + 1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-16T16:24:42.106519Z",
     "start_time": "2024-11-16T16:24:42.102811Z"
    }
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We repeat the creation of the *restaurantId* column for the ```geodata.tsv```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-16T16:24:44.024180Z",
     "start_time": "2024-11-16T16:24:44.017284Z"
    }
   },
   "outputs": [],
   "source": [
    "df_geo = pd.read_csv(\"geodata.tsv\", sep='\\t')\n",
    "df_geo['restaurantId'] = range(1, len(df) + 1)\n",
    "df_geo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-16T16:24:45.847368Z",
     "start_time": "2024-11-16T16:24:45.844154Z"
    }
   },
   "outputs": [],
   "source": [
    "df_geo.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can merge this two table, on the specified attribute (*restaurantId*), obtaining a new pandas DataFrame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-16T16:24:47.292515Z",
     "start_time": "2024-11-16T16:24:47.288052Z"
    }
   },
   "outputs": [],
   "source": [
    "df_final = pd.merge(df, df_geo, on='restaurantId')\n",
    "print(df_final.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-16T16:24:48.553947Z",
     "start_time": "2024-11-16T16:24:48.547296Z"
    }
   },
   "outputs": [],
   "source": [
    "df_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from the output above the column restaurantName seems to be not unique, that's way we didn't use this column as attribute of join.\n",
    "This is probably caused by the data gathering process, in which is possibile that some character differs from the two tables.\n",
    "So, we decided to check how many rows differs in the relative column, then we drop one of the two and we keep it as \"restaurantName\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-16T16:24:50.343239Z",
     "start_time": "2024-11-16T16:24:50.339828Z"
    }
   },
   "outputs": [],
   "source": [
    "df_final = df_final.rename(columns={'restaurantName_x': 'restaurantName'})\n",
    "\n",
    "# Drop column 'restaurantName_y'\n",
    "df_final = df_final.drop(columns=['restaurantName_y'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can see how is our ```df_final``` composed. We have all the information about the restaurant and we also added the information about its region and latidute and longitude.\n",
    "This allow us to represent the restaurant and all its information as point in our map plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-16T16:24:51.736397Z",
     "start_time": "2024-11-16T16:24:51.729354Z"
    }
   },
   "outputs": [],
   "source": [
    "df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-16T16:24:53.401080Z",
     "start_time": "2024-11-16T16:24:53.398281Z"
    }
   },
   "outputs": [],
   "source": [
    "df_final.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Map Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dash used instead of plain Plotly to make the map interactive and to be able to select regions with a simple click instead of using a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-16T10:37:23.550015Z",
     "start_time": "2024-11-16T10:37:22.979196Z"
    }
   },
   "outputs": [],
   "source": [
    "import dash\n",
    "from dash import dcc, html\n",
    "from dash.dependencies import Input, Output\n",
    "import plotly.express as px\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# DEBUG\n",
    "print(df_final.shape)\n",
    "\n",
    "# Load GeoJSON file of Italian regions in a GeoDataFrame\n",
    "gdf = gpd.read_file(\"./GeoJson/limits_IT_regions.geojson\")\n",
    "\n",
    "# Check CRS and convert it if needed (important to calculate centroid of each region to display it centered)\n",
    "if gdf.crs != \"EPSG:4326\":\n",
    "    gdf = gdf.to_crs(\"EPSG:4326\")\n",
    "\n",
    "# Extract region names from the GeoDataFrame\n",
    "region_names = gdf['reg_name'].tolist()\n",
    "\n",
    "# Create Dash app (Dash provides an easy-to-use API for creating web apps using Python)\n",
    "app = dash.Dash(__name__)\n",
    "\n",
    "# Layout of the app with checkbox for filtering top_k_result.tsv\n",
    "app.layout = html.Div([\n",
    "    html.Div([\n",
    "        # Add checkbox to filter top_k_result.tsv\n",
    "        dcc.Checklist(\n",
    "            id='show-top-k',\n",
    "            options=[{'label': 'Show Top-K Restaurants Only', 'value': 'top_k'}],\n",
    "            value=[],\n",
    "            inline=True\n",
    "        ),\n",
    "    ]),\n",
    "    \n",
    "    # Create 2 maps, one of Italy with selectable region and one for the selected region where we display restaurants\n",
    "    html.Div([\n",
    "        dcc.Graph(id='italy-map', clickData=None, style={'width': '50vw', 'height': '100vh'}),\n",
    "        dcc.Graph(id='region-map', style={'width': '50vw', 'height': '100vh'})\n",
    "    ], style={'display': 'flex', 'flex-direction': 'row'})\n",
    "])\n",
    "\n",
    "# Global variable to store filtered restaurants (default is all restaurants)\n",
    "filtered_restaurants = df_final\n",
    "\n",
    "@app.callback(\n",
    "    [Output('italy-map', 'figure'),\n",
    "     Output('region-map', 'figure')],\n",
    "    [Input('italy-map', 'clickData'),\n",
    "     Input('show-top-k', 'value')]\n",
    ")\n",
    "def update_maps(clickData, show_top_k):\n",
    "    global filtered_restaurants\n",
    "    \n",
    "    # Se la checkbox \"Top-K\" è selezionata, filtra i ristoranti dal file top_k_result.tsv\n",
    "    if 'top_k' in show_top_k:\n",
    "        top_k_df = pd.read_csv('top_k_result.tsv', sep='\\t')\n",
    "        filtered_restaurants = df_final[df_final['restaurantName'].isin(top_k_df['restaurantName'])]\n",
    "    else:\n",
    "        filtered_restaurants = df_final\n",
    "\n",
    "    # Variabile per gestire se una regione è selezionata\n",
    "    selected_region = None\n",
    "    if clickData:\n",
    "        selected_region = clickData['points'][0]['location']\n",
    "\n",
    "    # Configurazione della mappa dell'Italia\n",
    "    italy_map = px.choropleth_mapbox(\n",
    "        geojson=json.loads(gdf.to_json()),\n",
    "        locations=gdf['reg_name'],\n",
    "        featureidkey=\"properties.reg_name\",\n",
    "        color_continuous_scale=['grey'],\n",
    "        opacity=0.2,\n",
    "        mapbox_style=\"carto-positron\",\n",
    "        zoom=4.5,\n",
    "        center={\"lat\": 41.8719, \"lon\": 12.5674},\n",
    "        title=\"Map of the Italian Regions\"\n",
    "    )\n",
    "    \n",
    "    # Se la checkbox \"Top-K\" è selezionata e una regione è selezionata, mostra i marker\n",
    "    if 'top_k' in show_top_k and selected_region:\n",
    "        for price_range, color in [('€', 'blue'), ('€€', 'green'), ('€€€', 'purple'), ('€€€€', 'brown')]:\n",
    "            price_restaurants = filtered_restaurants[filtered_restaurants['priceRange'] == price_range]\n",
    "            italy_map.add_scattermapbox(\n",
    "                lat=price_restaurants['latitude'].tolist(),\n",
    "                lon=price_restaurants['longitude'].tolist(),\n",
    "                mode='markers',\n",
    "                marker=dict(size=10, color=color, opacity=0.8),\n",
    "                text=price_restaurants['restaurantName'],\n",
    "                name=price_range,\n",
    "                hovertemplate=(\n",
    "                    \"<b>Restaurant Name:</b> %{text}<br>\" +\n",
    "                    \"<b>Latitude:</b> %{lat}<br>\" +\n",
    "                    \"<b>Longitude:</b> %{lon}<br>\"\n",
    "                )\n",
    "            )\n",
    "    \n",
    "    if selected_region:\n",
    "        italy_map.update_traces(marker_line_color=\"red\", selector=dict(location=selected_region))\n",
    "    \n",
    "    # Configurazione della mappa della regione selezionata (se presente)\n",
    "    if selected_region:\n",
    "        region_gdf = gdf[gdf['reg_name'] == selected_region]\n",
    "        region_gdf_proj = region_gdf.to_crs(epsg=32632)\n",
    "        centroid_proj = region_gdf_proj.geometry.centroid.iloc[0]\n",
    "        centroid = gpd.GeoSeries([centroid_proj], crs=\"EPSG:32632\").to_crs(\"EPSG:4326\").iloc[0]\n",
    "        center_lat, center_lon = centroid.y, centroid.x\n",
    "\n",
    "        filtered_restaurants_region = filtered_restaurants[filtered_restaurants['region'] == selected_region]\n",
    "\n",
    "        region_map = px.choropleth_mapbox(\n",
    "            geojson=json.loads(region_gdf.to_json()),\n",
    "            locations=[selected_region],\n",
    "            featureidkey=\"properties.reg_name\",\n",
    "            mapbox_style=\"carto-positron\",\n",
    "            color_discrete_sequence=['red'],\n",
    "            opacity=0.1,\n",
    "            zoom=6,\n",
    "            center={\"lat\": center_lat, \"lon\": center_lon},\n",
    "            title=f\"Map of {selected_region} with Restaurants\"\n",
    "        )\n",
    "        \n",
    "        # Aggiungi marker per i ristoranti nella regione selezionata\n",
    "        for price_range, color in [('€', 'blue'), ('€€', 'green'), ('€€€', 'purple'), ('€€€€', 'brown')]:\n",
    "            price_restaurants = filtered_restaurants_region[filtered_restaurants_region['priceRange'] == price_range]\n",
    "            region_map.add_scattermapbox(\n",
    "                lat=price_restaurants['latitude'].tolist(),\n",
    "                lon=price_restaurants['longitude'].tolist(),\n",
    "                mode='markers',\n",
    "                marker=dict(size=10, color=color, opacity=0.8),\n",
    "                text=price_restaurants['restaurantName'],\n",
    "                name=price_range,\n",
    "                hovertemplate=(\n",
    "                    \"<b>Restaurant Name:</b> %{text}<br>\" +\n",
    "                    \"<b>Latitude:</b> %{lat}<br>\" +\n",
    "                    \"<b>Longitude:</b> %{lon}<br>\"\n",
    "                )\n",
    "            )\n",
    "    else:\n",
    "        # Se nessuna regione è selezionata, restituisci una mappa vuota\n",
    "        region_map = {}\n",
    "\n",
    "    return italy_map, region_map\n",
    "\n",
    "# Start Dash App\n",
    "if __name__ == '__main__':\n",
    "    app.run_server(jupyter_mode = 'external', debug=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. BONUS: Advanced Search Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T19:28:52.441987Z",
     "start_time": "2024-11-11T19:28:47.892908Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_weighted_similarity(df, queries, fields):\n",
    "    '''\n",
    "    Compute the cosine similarity score weighted basing on the non empty fields\n",
    "    '''\n",
    "    # Determina i campi attivi e i pesi\n",
    "    active_fields = [field for field in fields if queries[field].strip()]\n",
    "    \n",
    "    if not active_fields:\n",
    "        return np.zeros(len(df))\n",
    "    \n",
    "    # Compute the weight structure basing on the active text fields\n",
    "    if len(active_fields) == 1:\n",
    "        weights = {field: 1.0 if field == active_fields[0] else 0.0 for field in fields}\n",
    "    elif len(active_fields) == 2 and \"restaurantName\" in active_fields:\n",
    "        weights = {\n",
    "            \"restaurantName\": 0.7,\n",
    "            \"city\": 0.3 if \"city\" in active_fields else 0.0,\n",
    "            \"cuisineType\": 0.3 if \"cuisineType\" in active_fields else 0.0\n",
    "        }\n",
    "    elif len(active_fields) == 2 and \"restaurantName\" not in active_fields:\n",
    "        weights = {\n",
    "            \"restaurantName\": 0.0,\n",
    "            \"city\": 0.7,\n",
    "            \"cuisineType\": 0.3\n",
    "        }\n",
    "    elif len(active_fields) == 3:\n",
    "        weights = {\n",
    "            \"restaurantName\": 0.5,\n",
    "            \"city\": 0.3,\n",
    "            \"cuisineType\": 0.2\n",
    "        }\n",
    "    else:\n",
    "        weights = {}\n",
    "    \n",
    "    # Compute the cosine similarity for each text with value\n",
    "    field_similarities = defaultdict(lambda: np.zeros(len(df)))\n",
    "    for field in active_fields:\n",
    "        similarity_scores = engine.top_k_cosine_similarity(df[field], queries[field], k = 100) # RIMUOVERE K (ANCHE DALLA DESCRIZIONE)\n",
    "        for doc_id, score in similarity_scores:\n",
    "            field_similarities[field][doc_id] = score * weights[field]\n",
    "    \n",
    "    # Aggregate the scores\n",
    "    total_score = np.zeros(len(df))\n",
    "    for field in active_fields:\n",
    "        total_score += field_similarities[field]\n",
    "    \n",
    "    return total_score / len(active_fields)\n",
    "\n",
    "\n",
    "def get_price_range_value(price_str):\n",
    "    '''\n",
    "    Convert the € string in the number of correspondent elements\n",
    "    '''\n",
    "    return len(price_str.strip())\n",
    "\n",
    "def search_restaurants(restaurant_name_widget, city_widget, cuisine_type_widget, \n",
    "                      price_range_widget, region_checkboxes,\n",
    "                      credit_card_checkboxes, facility_checkboxes, output):\n",
    "    with output:\n",
    "        clear_output()\n",
    "        \n",
    "        try:\n",
    "            # Raccolta input testuali\n",
    "            queries = {\n",
    "                \"restaurantName\": restaurant_name_widget.value.strip().lower(),\n",
    "                \"city\": city_widget.value.strip().lower(),\n",
    "                \"cuisineType\": cuisine_type_widget.value.strip().lower()\n",
    "            }\n",
    "            print(\"Query raccolte:\", queries)  # Debugging\n",
    "\n",
    "            # Calcola similarity score pesata\n",
    "            similarity_scores = get_weighted_similarity(\n",
    "                df_final,\n",
    "                queries,\n",
    "                [\"restaurantName\", \"city\", \"cuisineType\"]\n",
    "            )\n",
    "            print(\"Punteggi di similarità calcolati:\", similarity_scores)  # Debugging\n",
    "            \n",
    "            # Crea un DataFrame temporaneo con gli scores\n",
    "            results = df_final.copy()\n",
    "            results['similarity_score'] = similarity_scores\n",
    "            \n",
    "            # Applica threshold per la similarity\n",
    "            if any(queries.values()):\n",
    "                results = results[results['similarity_score'] > 0.0]\n",
    "            print(\"Risultati dopo filtro similarity > 0:\", results.shape)  # Debugging\n",
    "            \n",
    "            # Applica filtri (aggiungi stampa per ogni filtro applicato)\n",
    "            selected_price_range = price_range_widget.value\n",
    "            selected_regions = [rc.description for rc in region_checkboxes if rc.value]\n",
    "            selected_credit_cards = [ccc.description for ccc in credit_card_checkboxes if ccc.value]\n",
    "            selected_facilities = [fc.description for fc in facility_checkboxes if fc.value]\n",
    "\n",
    "            # Filtra per intervallo di prezzo\n",
    "            if selected_price_range:\n",
    "                results = results[\n",
    "                    results[\"priceRange\"].apply(get_price_range_value).between(\n",
    "                        selected_price_range[0], \n",
    "                        selected_price_range[1]\n",
    "                    )\n",
    "                ]\n",
    "            print(\"Risultati dopo filtro prezzo:\", results.shape)  # Debugging\n",
    "\n",
    "            if selected_regions:\n",
    "                results = results[results[\"region\"].isin(selected_regions)]\n",
    "            print(\"Risultati dopo filtro regione:\", results.shape)  # Debugging\n",
    "\n",
    "            if selected_credit_cards:\n",
    "                results = results[\n",
    "                    results[\"creditCards\"].apply(\n",
    "                        lambda x: all(card in eval(x) for card in selected_credit_cards)\n",
    "                    )\n",
    "                ]\n",
    "            print(\"Risultati dopo filtro carte di credito:\", results.shape)  # Debugging\n",
    "\n",
    "            if selected_facilities:\n",
    "                results = results[\n",
    "                    results[\"facilitiesServices\"].apply(\n",
    "                        lambda x: all(service in eval(x) for service in selected_facilities)\n",
    "                    )\n",
    "                ]\n",
    "            print(\"Risultati dopo filtro servizi e strutture:\", results.shape)  # Debugging\n",
    "\n",
    "            # Ordina per similarity score\n",
    "            if any(queries.values()):\n",
    "                results = results.sort_values('similarity_score', ascending=False)\n",
    "\n",
    "            # Mostra i risultati\n",
    "            if not results.empty:\n",
    "                display(results[[\"restaurantName\", \"address\", \"cuisineType\", \"priceRange\", \"website\"]])\n",
    "            else:\n",
    "                print(\"Nessun risultato trovato.\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Errore: {e}\")\n",
    "\n",
    "\n",
    "# Collect all the possible values for Credit Cards, Services and facilities, regions\n",
    "unique_credit_cards = sorted(list(set(chain(*df_final['creditCards'].apply(eval)))))\n",
    "unique_services_facilities = sorted(list(set(chain(*df_final['facilitiesServices'].apply(eval)))))\n",
    "regions = sorted(pd.Series(df_final[\"region\"]).dropna().drop_duplicates().tolist())\n",
    "\n",
    "# Widget input\n",
    "restaurant_name = ipw.Text(placeholder=\"Type restaurant name\", description=\"Restaurant:\")\n",
    "city = ipw.Text(placeholder=\"Type city\", description=\"City:\")\n",
    "cuisine_type = ipw.Text(placeholder=\"Type cuisine\", description=\"Cuisine:\")\n",
    "price_range = ipw.IntRangeSlider(\n",
    "    value=[1, 4],\n",
    "    min=1,\n",
    "    max=4,\n",
    "    step=1,\n",
    "    description=\"Price Range:\",\n",
    ")\n",
    "\n",
    "# Checkbox for regions, CreditCards, Facilities & Services\n",
    "region_checkboxes = [ipw.Checkbox(value=False, description=option) for option in regions]\n",
    "region_box = ipw.VBox(region_checkboxes)\n",
    "\n",
    "credit_card_checkboxes = [ipw.Checkbox(value=False, description=option) for option in unique_credit_cards]\n",
    "credit_card_box = ipw.VBox(credit_card_checkboxes)\n",
    "\n",
    "facility_checkboxes = [ipw.Checkbox(value=False, description=option) for option in unique_services_facilities]\n",
    "facility_box = ipw.VBox(facility_checkboxes)\n",
    "\n",
    "# Search button\n",
    "search_button = ipw.Button(description=\"Search\", button_style=\"success\")\n",
    "output = ipw.Output()\n",
    "\n",
    "def on_search_button_click(b):\n",
    "    search_restaurants(\n",
    "        restaurant_name, city, cuisine_type, price_range, region_checkboxes,\n",
    "        credit_card_checkboxes, facility_checkboxes, output\n",
    "    )\n",
    "search_button.on_click(on_search_button_click)\n",
    "# Widget display \n",
    "display(restaurant_name, city, cuisine_type, price_range)\n",
    "display(ipw.Label(\"Regions:\"))\n",
    "display(region_box)\n",
    "display(ipw.Label(\"Credit Cards:\"))\n",
    "display(credit_card_box)\n",
    "display(ipw.Label(\"Services and Facilities:\"))\n",
    "display(facility_box)\n",
    "display(search_button, output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bozza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "def get_weighted_similarity(df, queries, fields):\n",
    "    \"\"\"\n",
    "    Calcola la similarity score pesata basata sui campi compilati\n",
    "    \"\"\"\n",
    "    # Determina i campi attivi e i pesi\n",
    "    active_fields = [field for field in fields if queries[field].strip()]\n",
    "    \n",
    "    if not active_fields:\n",
    "        return np.zeros(len(df))\n",
    "    \n",
    "    # Calcola i pesi basati sui campi attivi\n",
    "    if len(active_fields) == 1:\n",
    "        weights = {field: 1.0 if field == active_fields[0] else 0.0 for field in fields}\n",
    "    elif len(active_fields) == 2 and \"restaurantName\" in active_fields:\n",
    "        weights = {\n",
    "            \"restaurantName\": 0.7,\n",
    "            \"city\": 0.3 if \"city\" in active_fields else 0.0,\n",
    "            \"cuisineType\": 0.3 if \"cuisineType\" in active_fields else 0.0\n",
    "        }\n",
    "    elif len(active_fields) == 2 and \"restaurantName\" not in active_fields:\n",
    "        weights = {\n",
    "            \"restaurantName\": 0.0,\n",
    "            \"city\": 0.7,\n",
    "            \"cuisineType\": 0.3\n",
    "        }\n",
    "    elif len(active_fields) == 3:\n",
    "        weights = {\n",
    "            \"restaurantName\": 0.5,\n",
    "            \"city\": 0.3,\n",
    "            \"cuisineType\": 0.2\n",
    "        }\n",
    "    else:\n",
    "        weights = {}\n",
    "    \n",
    "    # Calcola similarity per ogni campo attivo\n",
    "    field_similarities = defaultdict(lambda: np.zeros(len(df)))\n",
    "    for field in active_fields:\n",
    "        similarity_scores = engine.top_k_cosine_similarity(df[field], queries[field], k = 100)\n",
    "        for doc_id, score in similarity_scores:\n",
    "            field_similarities[field][doc_id] = score * weights[field]\n",
    "    \n",
    "    # Aggrega gli scores\n",
    "    total_score = np.zeros(len(df))\n",
    "    for field in active_fields:\n",
    "        total_score += field_similarities[field]\n",
    "    \n",
    "    return total_score / len(active_fields)\n",
    "\n",
    "\n",
    "def get_price_range_value(price_str):\n",
    "    \"\"\"Converte la stringa di € nel numero corrispondente\"\"\"\n",
    "    return len(price_str.strip())\n",
    "\n",
    "def search_restaurants(restaurant_name_widget, city_widget, cuisine_type_widget, \n",
    "                      price_range_widget, region_checkboxes,\n",
    "                      credit_card_checkboxes, facility_checkboxes, output):\n",
    "    with output:\n",
    "        clear_output()\n",
    "        print(\"Avviando ricerca...\")\n",
    "        \n",
    "        try:\n",
    "            # Raccolta input testuali\n",
    "            queries = {\n",
    "                \"restaurantName\": restaurant_name_widget.value.strip().lower(),\n",
    "                \"city\": city_widget.value.strip().lower(),\n",
    "                \"cuisineType\": cuisine_type_widget.value.strip().lower()\n",
    "            }\n",
    "            print(\"Query raccolte:\", queries)  # Debugging\n",
    "\n",
    "            # Calcola similarity score pesata\n",
    "            similarity_scores = get_weighted_similarity(\n",
    "                df_final,\n",
    "                queries,\n",
    "                [\"restaurantName\", \"city\", \"cuisineType\"]\n",
    "            )\n",
    "            print(\"Punteggi di similarità calcolati:\", similarity_scores)  # Debugging\n",
    "            \n",
    "            # Crea un DataFrame temporaneo con gli scores\n",
    "            results = df_final.copy()\n",
    "            results['similarity_score'] = similarity_scores\n",
    "            \n",
    "            # Applica threshold per la similarity\n",
    "            if any(queries.values()):\n",
    "                results = results[results['similarity_score'] > 0.0]\n",
    "            print(\"Risultati dopo filtro similarity > 0:\", results.shape)  # Debugging\n",
    "            \n",
    "            # Applica filtri (aggiungi stampa per ogni filtro applicato)\n",
    "            selected_price_range = price_range_widget.value\n",
    "            selected_regions = [rc.description for rc in region_checkboxes if rc.value]\n",
    "            selected_credit_cards = [ccc.description for ccc in credit_card_checkboxes if ccc.value]\n",
    "            selected_facilities = [fc.description for fc in facility_checkboxes if fc.value]\n",
    "\n",
    "            # Filtra per intervallo di prezzo\n",
    "            if selected_price_range:\n",
    "                results = results[\n",
    "                    results[\"priceRange\"].apply(get_price_range_value).between(\n",
    "                        selected_price_range[0], \n",
    "                        selected_price_range[1]\n",
    "                    )\n",
    "                ]\n",
    "            print(\"Risultati dopo filtro prezzo:\", results.shape)  # Debugging\n",
    "\n",
    "            if selected_regions:\n",
    "                results = results[results[\"region\"].isin(selected_regions)]\n",
    "            print(\"Risultati dopo filtro regione:\", results.shape)  # Debugging\n",
    "\n",
    "            if selected_credit_cards:\n",
    "                results = results[\n",
    "                    results[\"creditCards\"].apply(\n",
    "                        lambda x: all(card in eval(x) for card in selected_credit_cards)\n",
    "                    )\n",
    "                ]\n",
    "            print(\"Risultati dopo filtro carte di credito:\", results.shape)  # Debugging\n",
    "\n",
    "            if selected_facilities:\n",
    "                results = results[\n",
    "                    results[\"facilitiesServices\"].apply(\n",
    "                        lambda x: all(service in eval(x) for service in selected_facilities)\n",
    "                    )\n",
    "                ]\n",
    "            print(\"Risultati dopo filtro servizi e strutture:\", results.shape)  # Debugging\n",
    "\n",
    "            # Ordina per similarity score\n",
    "            if any(queries.values()):\n",
    "                results = results.sort_values('similarity_score', ascending=False)\n",
    "\n",
    "            # Mostra i risultati\n",
    "            if not results.empty:\n",
    "                display(results[[\"restaurantName\", \"address\", \"cuisineType\", \"priceRange\", \"website\"]])\n",
    "            else:\n",
    "                print(\"Nessun risultato trovato.\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Errore: {e}\")\n",
    "\n",
    "\n",
    "# Widget inizializzazione e display\n",
    "# Preparazione dei dati\n",
    "unique_credit_cards = sorted(list(set(chain(*df_final['creditCards'].apply(eval)))))\n",
    "unique_services_facilities = sorted(list(set(chain(*df_final['facilitiesServices'].apply(eval)))))\n",
    "regions = sorted(pd.Series(df_final[\"region\"]).dropna().drop_duplicates().tolist())\n",
    "\n",
    "# Widget input\n",
    "restaurant_name = ipw.Text(placeholder=\"Type restaurant name\", description=\"Restaurant:\")\n",
    "city = ipw.Text(placeholder=\"Type city\", description=\"City:\")\n",
    "cuisine_type = ipw.Text(placeholder=\"Type cuisine\", description=\"Cuisine:\")\n",
    "price_range = ipw.IntRangeSlider(\n",
    "    value=[1, 4],\n",
    "    min=1,\n",
    "    max=4,\n",
    "    step=1,\n",
    "    description=\"Price Range:\",\n",
    ")\n",
    "\n",
    "region_checkboxes = [ipw.Checkbox(value=False, description=option) for option in regions]\n",
    "region_box = ipw.VBox(region_checkboxes)\n",
    "\n",
    "credit_card_checkboxes = [ipw.Checkbox(value=False, description=option) for option in unique_credit_cards]\n",
    "credit_card_box = ipw.VBox(credit_card_checkboxes)\n",
    "\n",
    "facility_checkboxes = [ipw.Checkbox(value=False, description=option) for option in unique_services_facilities]\n",
    "facility_box = ipw.VBox(facility_checkboxes)\n",
    "\n",
    "search_button = ipw.Button(description=\"Search\", button_style=\"success\")\n",
    "output = ipw.Output()\n",
    "\n",
    "def on_search_button_click(b):\n",
    "    print(\"Pulsante cliccato!\")\n",
    "    search_restaurants(\n",
    "        restaurant_name, city, cuisine_type, price_range, region_checkboxes,\n",
    "        credit_card_checkboxes, facility_checkboxes, output\n",
    "    )\n",
    "search_button.on_click(on_search_button_click)\n",
    "# Display dei widget\n",
    "display(restaurant_name, city, cuisine_type, price_range)\n",
    "display(ipw.Label(\"Regions:\"))\n",
    "display(region_box)\n",
    "display(ipw.Label(\"Credit Cards:\"))\n",
    "display(credit_card_box)\n",
    "display(ipw.Label(\"Services and Facilities:\"))\n",
    "display(facility_box)\n",
    "display(search_button, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-16T16:25:10.606980Z",
     "start_time": "2024-11-16T16:25:10.537643Z"
    }
   },
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "def create_inverted_index(documents):\n",
    "    \"\"\"Create an inverted index per i documenti\"\"\"\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    tfidf_matrix = vectorizer.fit_transform(documents)\n",
    "    return vectorizer, tfidf_matrix\n",
    "\n",
    "def calculate_similarity_score(query, vectorizer, tfidf_matrix):\n",
    "    \"\"\"Calcola il cosine similarity score tra la query e i documenti\"\"\"\n",
    "    if not query.strip():\n",
    "        return np.zeros(tfidf_matrix.shape[0])\n",
    "    \n",
    "    query_vector = vectorizer.transform([query])\n",
    "    similarity_scores = cosine_similarity(query_vector, tfidf_matrix).flatten()\n",
    "    return similarity_scores\n",
    "\n",
    "def get_weighted_similarity(df, queries, fields):\n",
    "    \"\"\"\n",
    "    Calcola la similarity score pesata basata sui campi compilati\n",
    "    \n",
    "    Args:\n",
    "    df: DataFrame con i dati dei ristoranti\n",
    "    queries: dict con le query per ogni campo\n",
    "    fields: lista dei campi da considerare\n",
    "    \n",
    "    Returns:\n",
    "    array con gli scores pesati\n",
    "    \"\"\"\n",
    "    # Inizializza i vectorizer e le matrici TF-IDF per ogni campo\n",
    "    field_data = {}\n",
    "    for field in fields:\n",
    "        preprocessed_documents = []\n",
    "        for doc in df[field]:\n",
    "            preprocessed_doc = engine.preprocessing(doc)\n",
    "            preprocessed_documents.append(preprocessed_doc)\n",
    "        vectorizer, tfidf_matrix = (preprocessed_documents)\n",
    "        field_data[field] = {\n",
    "            'vectorizer': vectorizer,\n",
    "            'tfidf_matrix': tfidf_matrix,\n",
    "            'score': None\n",
    "        }\n",
    "    \n",
    "    # Calcola i similarity scores per i campi compilati\n",
    "    active_fields = [field for field in fields if queries[field].strip()]\n",
    "    \n",
    "    if not active_fields:\n",
    "        return np.zeros(len(df))\n",
    "    \n",
    "    # Compute the weight structure basing on the active text fields\n",
    "    if len(active_fields) == 1:\n",
    "        weights = {field: 1.0 if field == active_fields[0] else 0.0 for field in fields}\n",
    "    elif len(active_fields) == 2 and \"restaurantName\" in active_fields:\n",
    "        weights = {\n",
    "            \"restaurantName\": 0.7,\n",
    "            \"city\": 0.3 if \"city\" in active_fields else 0.0,\n",
    "            \"cuisineType\": 0.3 if \"cuisineType\" in active_fields else 0.0\n",
    "        }\n",
    "    elif len(active_fields) == 2 and \"restaurantName\" not in active_fields:\n",
    "        weights = {\n",
    "            \"restaurantName\": 0.0,\n",
    "            \"city\": 0.7,\n",
    "            \"cuisineType\": 0.3\n",
    "        }\n",
    "    else:\n",
    "        weights = {\n",
    "            \"restaurantName\": 0.5,\n",
    "            \"city\": 0.3,\n",
    "            \"cuisineType\": 0.2\n",
    "        }\n",
    "    \n",
    "    # Compute the cosine similarity for each text with value\n",
    "    for field in active_fields:\n",
    "        score = calculate_similarity_score(\n",
    "            queries[field],\n",
    "            field_data[field]['vectorizer'],\n",
    "            field_data[field]['tfidf_matrix']\n",
    "        )\n",
    "        field_data[field]['score'] = score * weights[field]\n",
    "    \n",
    "    # Aggrega gli scores\n",
    "    total_score = sum(field_data[field]['score'] for field in active_fields)\n",
    "    return total_score / len(active_fields)\n",
    "\n",
    "# Collect all the possible values for Credit Cards, Services and facilities, regions and \n",
    "unique_credit_cards = sorted(list(set(chain(*df_final['creditCards'].apply(eval)))))\n",
    "unique_services_facilities = sorted(list(set(chain(*df_final['facilitiesServices'].apply(eval)))))\n",
    "regions = sorted(pd.Series(df_final[\"region\"]).dropna().drop_duplicates().tolist())\n",
    "cuisine_types = sorted(df_final['cuisineType'].unique().tolist())\n",
    "\n",
    "# Widget input\n",
    "restaurant_name = widgets.Text(placeholder=\"Type restaurant name\", description=\"Restaurant:\")\n",
    "city = widgets.Text(placeholder=\"Type city\", description=\"City:\")\n",
    "cuisine_type = widgets.Text(placeholder=\"Type cuisine\", description=\"Cuisine:\")\n",
    "price_range = widgets.IntRangeSlider(\n",
    "    value=[1, 4],\n",
    "    min=1,\n",
    "    max=4,\n",
    "    step=1,\n",
    "    description=\"Price Range:\",\n",
    ")\n",
    "\n",
    "# Checkbox for regions, CreditCards, Facilities & Services\n",
    "region_checkboxes = [widgets.Checkbox(value=False, description=option) for option in regions]\n",
    "region_box = widgets.VBox(region_checkboxes)\n",
    "\n",
    "credit_card_checkboxes = [widgets.Checkbox(value=False, description=option) for option in unique_credit_cards]\n",
    "credit_card_box = widgets.VBox(credit_card_checkboxes)\n",
    "\n",
    "facility_checkboxes = [widgets.Checkbox(value=False, description=option) for option in unique_services_facilities]\n",
    "facility_box = widgets.VBox(facility_checkboxes)\n",
    "\n",
    "# Pulsante cerca e output\n",
    "search_button = widgets.Button(description=\"Search\", button_style=\"success\")\n",
    "output = widgets.Output()\n",
    "\n",
    "def get_price_range_value(price_str):\n",
    "    \"\"\"Convert the € string in the number of correspondent elements\"\"\"\n",
    "    return len(price_str.strip())\n",
    "\n",
    "def enanched_search_restaurants(restaurant_name_widget, city_widget, cuisine_type_widget, \n",
    "                      price_range_widget, region_checkboxes,\n",
    "                      credit_card_checkboxes, facility_checkboxes, output):\n",
    "    with output:\n",
    "        clear_output()\n",
    "        print(\"Searching restaurants...\")\n",
    "        \n",
    "        try:\n",
    "            # Take values of input queries\n",
    "            queries = {\n",
    "                \"restaurantName\": restaurant_name_widget.value.strip().lower(),\n",
    "                \"city\": city_widget.value.strip().lower(),\n",
    "                \"cuisineType\": cuisine_type_widget.value.strip().lower()\n",
    "            }\n",
    "            \n",
    "            # Compute the weighted similarity score\n",
    "            similarity_scores = get_weighted_similarity(\n",
    "                df_final,\n",
    "                queries,\n",
    "                [\"restaurantName\", \"city\", \"cuisineType\"]\n",
    "            )\n",
    "            \n",
    "            # Crea un DataFrame temporaneo con gli scores\n",
    "            results = df_final.copy()\n",
    "            results['similarity_score'] = similarity_scores\n",
    "            \n",
    "            # Show only the rows with similarity score > 0\n",
    "            if any(queries.values()):\n",
    "                results = results[results['similarity_score'] > 0.0]\n",
    "            \n",
    "            # Collect values of the filters\n",
    "            selected_price_range = price_range_widget.value\n",
    "            selected_regions = [rc.description for rc in region_checkboxes if rc.value]\n",
    "            selected_credit_cards = [ccc.description for ccc in credit_card_checkboxes if ccc.value]\n",
    "            selected_facilities = [fc.description for fc in facility_checkboxes if fc.value]\n",
    "\n",
    "            # Apply the priceRange filter\n",
    "            results = results[\n",
    "                results[\"priceRange\"].apply(get_price_range_value).between(\n",
    "                    selected_price_range[0], \n",
    "                    selected_price_range[1]\n",
    "                )\n",
    "            ]\n",
    "\n",
    "            # Apply the Region filter\n",
    "            if selected_regions:\n",
    "                results = results[results[\"region\"].isin(selected_regions)]\n",
    "\n",
    "            # Apply the CreditCards filter\n",
    "            if selected_credit_cards:\n",
    "                results = results[\n",
    "                    results[\"creditCards\"].apply(\n",
    "                        lambda x: all(card in eval(x) for card in selected_credit_cards)\n",
    "                    )\n",
    "                ]\n",
    "\n",
    "            # Apply the services & facilities filter\n",
    "            if selected_facilities:\n",
    "                results = results[\n",
    "                    results[\"facilitiesServices\"].apply(\n",
    "                        lambda x: all(service in eval(x) for service in selected_facilities)\n",
    "                    )\n",
    "                ]\n",
    "\n",
    "            # Order by similarity score\n",
    "            if any(queries.values()):\n",
    "                results = results.sort_values('similarity_score', ascending=False)\n",
    "\n",
    "            # Show the results\n",
    "            if not results.empty:\n",
    "                display(results[[\"restaurantName\", \"address\", \"cuisineType\", \"priceRange\", \"website\"]])\n",
    "            else:\n",
    "                print(\"No result founded.\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}\")\n",
    "\n",
    "# Collegamento evento al pulsante\n",
    "search_button.on_click(lambda b: enanched_search_restaurants(\n",
    "    restaurant_name, city, cuisine_type, price_range, region_checkboxes,\n",
    "    credit_card_checkboxes, facility_checkboxes, output\n",
    "))\n",
    "\n",
    "# Display the UI (widgets)\n",
    "display(restaurant_name, city, cuisine_type, price_range)\n",
    "display(widgets.Label(\"Regions:\"))\n",
    "display(region_box)\n",
    "display(widgets.Label(\"Credit Cards:\"))\n",
    "display(credit_card_box)\n",
    "display(widgets.Label(\"Services and Facilities:\"))\n",
    "display(facility_box)\n",
    "display(search_button, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-16T15:33:35.849905Z",
     "start_time": "2024-11-16T15:33:35.763397Z"
    }
   },
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "def get_weighted_similarity(df, queries, fields):\n",
    "    \"\"\"\n",
    "    Calcola la similarity score pesata basata sui campi compilati, utilizzando la funzione top_k_cosine_similarity.\n",
    "    \n",
    "    Args:\n",
    "    df: DataFrame con i dati dei ristoranti\n",
    "    queries: dict con le query per ogni campo\n",
    "    fields: lista dei campi da considerare\n",
    "    \n",
    "    Returns:\n",
    "    array con gli scores pesati\n",
    "    \"\"\"\n",
    "    # Prepara i dati per ogni campo\n",
    "    field_data = {}\n",
    "    for field in fields:\n",
    "        documents = df[field].fillna('').str.lower().tolist()\n",
    "        field_data[field] = {\n",
    "            'documents': documents,\n",
    "            'score': None\n",
    "        }\n",
    "\n",
    "    # Campi attivi con query non vuote\n",
    "    active_fields = [field for field in fields if queries[field].strip()]\n",
    "    if not active_fields:\n",
    "        return np.zeros(len(df))\n",
    "    \n",
    "    # Struttura dei pesi basata sui campi attivi\n",
    "    if len(active_fields) == 1:\n",
    "        weights = {field: 1.0 if field == active_fields[0] else 0.0 for field in fields}\n",
    "    elif len(active_fields) == 2 and \"restaurantName\" in active_fields:\n",
    "        weights = {\n",
    "            \"restaurantName\": 0.7,\n",
    "            \"city\": 0.3 if \"city\" in active_fields else 0.0,\n",
    "            \"cuisineType\": 0.3 if \"cuisineType\" in active_fields else 0.0\n",
    "        }\n",
    "    elif len(active_fields) == 2 and \"restaurantName\" not in active_fields:\n",
    "        weights = {\n",
    "            \"restaurantName\": 0.0,\n",
    "            \"city\": 0.7,\n",
    "            \"cuisineType\": 0.3\n",
    "        }\n",
    "    else:\n",
    "        weights = {\n",
    "            \"restaurantName\": 0.5,\n",
    "            \"city\": 0.3,\n",
    "            \"cuisineType\": 0.2\n",
    "        }\n",
    "    \n",
    "    # Calcolo della similarità usando top_k_cosine_similarity\n",
    "    for field in active_fields:\n",
    "        documents = field_data[field]['documents']\n",
    "        query = queries[field].lower()\n",
    "        similarities = engine.top_k_cosine_similarity(\n",
    "            docs=pd.Series(documents),\n",
    "            query=query,\n",
    "            docs_preprocessed=False,\n",
    "            query_preprocessed=False\n",
    "        )\n",
    "        print(f\"Similarities for {field}: {similarities}\")\n",
    "        \n",
    "        # Crea un array di score con 0 come default\n",
    "        scores = np.zeros(len(documents))\n",
    "        for doc_id, similarity in similarities:\n",
    "            if similarity > 0:\n",
    "                scores[doc_id] = similarity\n",
    "        \n",
    "        # Applica il peso per il campo\n",
    "        field_data[field]['score'] = scores * weights[field]\n",
    "    \n",
    "    # Aggrega i punteggi\n",
    "    total_score = sum(field_data[field]['score'] for field in active_fields)\n",
    "    return total_score\n",
    "\n",
    "unique_credit_cards = sorted(list(set(chain(*df_final['creditCards'].apply(eval)))))\n",
    "unique_services_facilities = sorted(list(set(chain(*df_final['facilitiesServices'].apply(eval)))))\n",
    "regions = sorted(pd.Series(df_final[\"region\"]).dropna().drop_duplicates().tolist())\n",
    "\n",
    "# Widget input\n",
    "restaurant_name = widgets.Text(placeholder=\"Type restaurant name\", description=\"Restaurant:\")\n",
    "city = widgets.Text(placeholder=\"Type city\", description=\"City:\")\n",
    "cuisine_type = widgets.Text(placeholder=\"Type cuisine\", description=\"Cuisine:\")\n",
    "price_range = widgets.IntRangeSlider(\n",
    "    value=[1, 4],\n",
    "    min=1,\n",
    "    max=4,\n",
    "    step=1,\n",
    "    description=\"Price Range:\",\n",
    ")\n",
    "\n",
    "# Checkbox for regions, CreditCards, Facilities & Services\n",
    "region_checkboxes = [widgets.Checkbox(value=False, description=option) for option in regions]\n",
    "region_box = widgets.VBox(region_checkboxes)\n",
    "\n",
    "credit_card_checkboxes = [widgets.Checkbox(value=False, description=option) for option in unique_credit_cards]\n",
    "credit_card_box = widgets.VBox(credit_card_checkboxes)\n",
    "\n",
    "facility_checkboxes = [widgets.Checkbox(value=False, description=option) for option in unique_services_facilities]\n",
    "facility_box = widgets.VBox(facility_checkboxes)\n",
    "\n",
    "# Pulsante cerca e output\n",
    "search_button = widgets.Button(description=\"Search\", button_style=\"success\")\n",
    "output = widgets.Output()\n",
    "\n",
    "def get_price_range_value(price_str):\n",
    "    \"\"\"Convert the € string in the number of correspondent elements\"\"\"\n",
    "    return len(price_str.strip())\n",
    "\n",
    "def enanched_search_restaurants(restaurant_name, city, cuisine_type, \n",
    "                                price_range, region_checkboxes,\n",
    "                                credit_card_checkboxes, facility_checkboxes, output):\n",
    "    with output:\n",
    "        clear_output()\n",
    "        print(\"Searching restaurants...\")\n",
    "        \n",
    "        try:\n",
    "            # Recupera i valori delle query\n",
    "            queries = {\n",
    "                \"restaurantName\": restaurant_name.value.strip().lower(),\n",
    "                \"city\": city.value.strip().lower(),\n",
    "                \"cuisineType\": cuisine_type.value.strip().lower()\n",
    "            }\n",
    "            \n",
    "            # Calcola il punteggio di similarità pesato\n",
    "            similarity_scores = get_weighted_similarity(\n",
    "                df_final,\n",
    "                queries,\n",
    "                [\"restaurantName\", \"city\", \"cuisineType\"]\n",
    "            )\n",
    "            \n",
    "            # Crea un DataFrame temporaneo con gli scores\n",
    "            results = df_final.copy()\n",
    "            results['similarity_score'] = similarity_scores\n",
    "            \n",
    "            # Filtra solo i risultati con score maggiore di 0\n",
    "            results = results[results['similarity_score'] > 0.0]\n",
    "            \n",
    "            # Filtri aggiuntivi\n",
    "            selected_price_range = price_range.value\n",
    "            selected_regions = [rc.description for rc in region_checkboxes if rc.value]\n",
    "            selected_credit_cards = [ccc.description for ccc in credit_card_checkboxes if ccc.value]\n",
    "            selected_facilities = [fc.description for fc in facility_checkboxes if fc.value]\n",
    "\n",
    "            # Filtro per intervallo di prezzo\n",
    "            results = results[\n",
    "                results[\"priceRange\"].apply(get_price_range_value).between(\n",
    "                    selected_price_range[0], \n",
    "                    selected_price_range[1]\n",
    "                )\n",
    "            ]\n",
    "\n",
    "            # Filtro per regione\n",
    "            if selected_regions:\n",
    "                results = results[results[\"region\"].isin(selected_regions)]\n",
    "\n",
    "            # Filtro per carte di credito\n",
    "            if selected_credit_cards:\n",
    "                results = results[\n",
    "                    results[\"creditCards\"].apply(\n",
    "                        lambda x: all(card in eval(x) for card in selected_credit_cards)\n",
    "                    )\n",
    "                ]\n",
    "\n",
    "            # Filtro per servizi e strutture\n",
    "            if selected_facilities:\n",
    "                results = results[\n",
    "                    results[\"facilitiesServices\"].apply(\n",
    "                        lambda x: all(service in eval(x) for service in selected_facilities)\n",
    "                    )\n",
    "                ]\n",
    "\n",
    "            # Ordina i risultati per punteggio di similarità\n",
    "            results = results.sort_values('similarity_score', ascending=False)\n",
    "\n",
    "            # Mostra i risultati\n",
    "            if not results.empty:\n",
    "                display(results[[\"restaurantName\", \"address\", \"cuisineType\", \"priceRange\", \"website\"]])\n",
    "            else:\n",
    "                print(\"No result founded.\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}\")\n",
    "# Collegamento evento al pulsante\n",
    "search_button.on_click(lambda b: enanched_search_restaurants(\n",
    "    restaurant_name, city, cuisine_type, price_range, region_checkboxes,\n",
    "    credit_card_checkboxes, facility_checkboxes, output\n",
    "))\n",
    "\n",
    "# Display the UI (widgets)\n",
    "display(restaurant_name, city, cuisine_type, price_range)\n",
    "display(widgets.Label(\"Regions:\"))\n",
    "display(region_box)\n",
    "display(widgets.Label(\"Credit Cards:\"))\n",
    "display(credit_card_box)\n",
    "display(widgets.Label(\"Services and Facilities:\"))\n",
    "display(facility_box)\n",
    "display(search_button, output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-16T16:13:10.372089Z",
     "start_time": "2024-11-16T16:13:10.297764Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_weighted_similarity(df, queries, fields):\n",
    "    \"\"\"\n",
    "    Calcola la similarity score pesata basata sui campi compilati\n",
    "    \"\"\"\n",
    "    # Determina i campi attivi e i pesi\n",
    "    active_fields = [field for field in fields if queries[field].strip()]\n",
    "    \n",
    "    if not active_fields:\n",
    "        return np.zeros(len(df))\n",
    "    \n",
    "    # Calcola i pesi basati sui campi attivi\n",
    "    if len(active_fields) == 1:\n",
    "        weights = {field: 1.0 if field == active_fields[0] else 0.0 for field in fields}\n",
    "    elif len(active_fields) == 2 and \"restaurantName\" in active_fields:\n",
    "        weights = {\n",
    "            \"restaurantName\": 0.7,\n",
    "            \"city\": 0.3 if \"city\" in active_fields else 0.0,\n",
    "            \"cuisineType\": 0.3 if \"cuisineType\" in active_fields else 0.0\n",
    "        }\n",
    "    elif len(active_fields) == 2 and \"restaurantName\" not in active_fields:\n",
    "        weights = {\n",
    "            \"restaurantName\": 0.0,\n",
    "            \"city\": 0.7,\n",
    "            \"cuisineType\": 0.3\n",
    "        }\n",
    "    else:\n",
    "        weights = {\n",
    "            \"restaurantName\": 0.5,\n",
    "            \"city\": 0.3,\n",
    "            \"cuisineType\": 0.2\n",
    "        }\n",
    "    \n",
    "    # Calcola similarity per ogni campo attivo\n",
    "    field_similarities = defaultdict(lambda: np.zeros(len(df)))\n",
    "    for field in active_fields:\n",
    "        similarity_scores = engine.top_k_cosine_similarity(df[field], queries[field], k = 1000)\n",
    "        for doc_id, score in similarity_scores:\n",
    "            field_similarities[field][doc_id] = score * weights[field]\n",
    "    \n",
    "    # Aggrega gli scores\n",
    "    total_score = np.zeros(len(df))\n",
    "    for field in active_fields:\n",
    "        total_score += field_similarities[field]\n",
    "    \n",
    "    return total_score / len(active_fields)\n",
    "\n",
    "\n",
    "def get_price_range_value(price_str):\n",
    "    \"\"\"Converte la stringa di € nel numero corrispondente\"\"\"\n",
    "    return len(price_str.strip())\n",
    "\n",
    "def search_restaurants(restaurant_name_widget, city_widget, cuisine_type_widget, \n",
    "                      price_range_widget, region_checkboxes,\n",
    "                      credit_card_checkboxes, facility_checkboxes, output):\n",
    "    with output:\n",
    "        clear_output()\n",
    "        print(\"Avviando ricerca...\")\n",
    "        \n",
    "        try:\n",
    "            # Raccolta input testuali\n",
    "            queries = {\n",
    "                \"restaurantName\": restaurant_name_widget.value.strip().lower(),\n",
    "                \"city\": city_widget.value.strip().lower(),\n",
    "                \"cuisineType\": cuisine_type_widget.value.strip().lower()\n",
    "            }\n",
    "            print(\"Query raccolte:\", queries)  # Debugging\n",
    "\n",
    "            # Calcola similarity score pesata\n",
    "            similarity_scores = get_weighted_similarity(\n",
    "                df_final,\n",
    "                queries,\n",
    "                [\"restaurantName\", \"city\", \"cuisineType\"]\n",
    "            )\n",
    "            print(\"Punteggi di similarità calcolati:\", similarity_scores)  # Debugging\n",
    "            \n",
    "            # Crea un DataFrame temporaneo con gli scores\n",
    "            results = df_final.copy()\n",
    "            results['similarity_score'] = similarity_scores\n",
    "            \n",
    "            # Applica threshold per la similarity\n",
    "            if any(queries.values()):\n",
    "                results = results[results['similarity_score'] > 0.0]\n",
    "            print(\"Risultati dopo filtro similarity > 0:\", results.shape)  # Debugging\n",
    "            \n",
    "            # Applica filtri (aggiungi stampa per ogni filtro applicato)\n",
    "            selected_price_range = price_range_widget.value\n",
    "            selected_regions = [rc.description for rc in region_checkboxes if rc.value]\n",
    "            selected_credit_cards = [ccc.description for ccc in credit_card_checkboxes if ccc.value]\n",
    "            selected_facilities = [fc.description for fc in facility_checkboxes if fc.value]\n",
    "\n",
    "            # Filtra per intervallo di prezzo\n",
    "            if selected_price_range:\n",
    "                results = results[\n",
    "                    results[\"priceRange\"].apply(get_price_range_value).between(\n",
    "                        selected_price_range[0], \n",
    "                        selected_price_range[1]\n",
    "                    )\n",
    "                ]\n",
    "            print(\"Risultati dopo filtro prezzo:\", results.shape)  # Debugging\n",
    "\n",
    "            if selected_regions:\n",
    "                results = results[results[\"region\"].isin(selected_regions)]\n",
    "            print(\"Risultati dopo filtro regione:\", results.shape)  # Debugging\n",
    "\n",
    "            if selected_credit_cards:\n",
    "                results = results[\n",
    "                    results[\"creditCards\"].apply(\n",
    "                        lambda x: all(card in eval(x) for card in selected_credit_cards)\n",
    "                    )\n",
    "                ]\n",
    "            print(\"Risultati dopo filtro carte di credito:\", results.shape)  # Debugging\n",
    "\n",
    "            if selected_facilities:\n",
    "                results = results[\n",
    "                    results[\"facilitiesServices\"].apply(\n",
    "                        lambda x: all(service in eval(x) for service in selected_facilities)\n",
    "                    )\n",
    "                ]\n",
    "            print(\"Risultati dopo filtro servizi e strutture:\", results.shape)  # Debugging\n",
    "\n",
    "            # Ordina per similarity score\n",
    "            if any(queries.values()):\n",
    "                results = results.sort_values('similarity_score', ascending=False)\n",
    "\n",
    "            # Mostra i risultati\n",
    "            if not results.empty:\n",
    "                display(results[[\"restaurantName\", \"address\", \"cuisineType\", \"priceRange\", \"website\"]])\n",
    "            else:\n",
    "                print(\"Nessun risultato trovato.\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Errore: {e}\")\n",
    "\n",
    "\n",
    "# Widget inizializzazione e display\n",
    "# Preparazione dei dati\n",
    "unique_credit_cards = sorted(list(set(chain(*df_final['creditCards'].apply(eval)))))\n",
    "unique_services_facilities = sorted(list(set(chain(*df_final['facilitiesServices'].apply(eval)))))\n",
    "regions = sorted(pd.Series(df_final[\"region\"]).dropna().drop_duplicates().tolist())\n",
    "\n",
    "# Widget input\n",
    "restaurant_name = ipw.Text(placeholder=\"Type restaurant name\", description=\"Restaurant:\")\n",
    "city = ipw.Text(placeholder=\"Type city\", description=\"City:\")\n",
    "cuisine_type = ipw.Text(placeholder=\"Type cuisine\", description=\"Cuisine:\")\n",
    "price_range = ipw.IntRangeSlider(\n",
    "    value=[1, 4],\n",
    "    min=1,\n",
    "    max=4,\n",
    "    step=1,\n",
    "    description=\"Price Range:\",\n",
    ")\n",
    "\n",
    "region_checkboxes = [ipw.Checkbox(value=False, description=option) for option in regions]\n",
    "region_box = widgets.VBox(region_checkboxes)\n",
    "\n",
    "credit_card_checkboxes = [ipw.Checkbox(value=False, description=option) for option in unique_credit_cards]\n",
    "credit_card_box = widgets.VBox(credit_card_checkboxes)\n",
    "\n",
    "facility_checkboxes = [ipw.Checkbox(value=False, description=option) for option in unique_services_facilities]\n",
    "facility_box = widgets.VBox(facility_checkboxes)\n",
    "\n",
    "search_button = ipw.Button(description=\"Search\", button_style=\"success\")\n",
    "output = widgets.Output()\n",
    "\n",
    "def on_search_button_click(b):\n",
    "    print(\"Pulsante cliccato!\")\n",
    "    search_restaurants(\n",
    "        restaurant_name, city, cuisine_type, price_range, region_checkboxes,\n",
    "        credit_card_checkboxes, facility_checkboxes, output\n",
    "    )\n",
    "search_button.on_click(on_search_button_click)\n",
    "# Display dei widget\n",
    "display(restaurant_name, city, cuisine_type, price_range)\n",
    "display(widgets.Label(\"Regions:\"))\n",
    "display(region_box)\n",
    "display(widgets.Label(\"Credit Cards:\"))\n",
    "display(credit_card_box)\n",
    "display(widgets.Label(\"Services and Facilities:\"))\n",
    "display(facility_box)\n",
    "display(search_button, output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithmic Question (AQ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Pseudocode\n",
    "\n",
    "The intuition is that, starting from the origin (0, 0) in the first quadrant where all packages are located, the first package is always reachable. Given that we can only move up or right, we can only reach packages that are above or to the right of the current one. Therefore, for each package reached, we need to check the next one: if it is below or to the left, we can print \"NO\" because it’s unreachable. Otherwise, we proceed, but to ensure the lexicographically smallest path, we need to sort all packages in ascending order by their coordinates.\n",
    "\n",
    "Below is the pseudocode of an algorithm that solves this problem:\n",
    "\n",
    "$ \\mathbf{PackageCollector(t)} $\n",
    "\n",
    "(0) $ \\textbf{for text case t}: $\n",
    "\n",
    "* (1) $ read(n) $\n",
    "\n",
    "* (2) $ \\text{packages} ← \\text{[ ]} $\n",
    "\n",
    "* (3) $ \\textbf{for i=1 to n:} $ // $O(n)$\n",
    "\n",
    " * (4) $ read(x[i]), read(y[i]) $\n",
    " * (5) $ \\text{packages} \\leftarrow \\text{packages} + [(x[i], y[i])] $\n",
    "* (6) $ \\textbf{Sort} \\text{ packages by x and then y coordinate in ascending order}$ // $ O(n \\log(n)) $\n",
    "* (7) $ \\text{x_current} \\leftarrow 0 $\n",
    "* (8) $ \\text{y_current} \\leftarrow 0 $\n",
    "* (9) $ \\text{path } \\leftarrow \\text{' '}$\n",
    "* (10) $ \\text{possible} \\leftarrow \\text{TRUE} $\n",
    "\n",
    "* (11) $\\textbf{for i=1 to n:} $ // $O(n)$\n",
    "\n",
    "  * (12) $ \\textbf{if } \\mathbf{x[i]<}\\textbf{x_current or } \\mathbf{y[i]<}\\textbf{y_current:} $\n",
    "    * (13) $ \\text{possible} \\leftarrow \\text{FALSE} $\n",
    "    * (14) $ break $\n",
    "  * $ \\textbf{end if} $\n",
    "  * (15) $ \\text{num_right_moves} \\leftarrow x[i]-\\text{x_current} $\n",
    "  * (16) $ \\text{num_up_moves} \\leftarrow y[i]-\\text{y_current} $\n",
    "  * (17) $ \\text{path} \\leftarrow \\text{path} + \\text{'R'} \\cdot \\text{num_right_moves} $\n",
    "  * (18) $ \\text{path} \\leftarrow \\text{path} + \\text{'U'} \\cdot \\text{num_up_moves} $\n",
    "  * (19) $ \\text{x_current} \\leftarrow x[i]$\n",
    "  * (20) $ \\text{y_current} \\leftarrow y[i]$\n",
    "* $ \\textbf{end for} $\n",
    "* (21) $ \\textbf{if possible:} $\n",
    "    * (22) $ output(\\text{'YES'}) $\n",
    "    * (23) $ output(\\text{path}) $\n",
    "* $ \\textbf{end if} $\n",
    "* (24) $ \\textbf{else:} $\n",
    "  * (25) $ output(\\text{'NO'}) $\n",
    "\n",
    "$ \\textbf{end for} $\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "### Proof of Correctness\n",
    "\n",
    "The algorithm aims to determine a path from the origin $(0,0)$ to each package coordinate $(x[i],y[i])$, using only right and up movements. We will show that the algorithm checks when such a path is possible, and, if it is, how to build a valid sequence of right ```R``` and up ```U``` movements to visit all the target locations in order.\n",
    "\n",
    "The algorithm works on a set of inputs whose general structure is known. It first reads the number $n$ of packages (1), and then their coordinates (4).\n",
    "\n",
    "Since the robot can move right and up, similar to a staircase, it is able to reach any package that is in the first quadrant of the moving reference system centered in the current robot's cell. To do this, the robot just needs to move the number of steps to the right that it takes to reach the package's x coordinate, and move up for a number of steps corresponding to the difference in y coordinates between robot and package.\n",
    "\n",
    "Every time there is at least one package in the robot's top-right quadrant, the algorithm must make sure that the robot does not skip packages, if it is avoidable. Otherwise, it might erroneously conclude that there is no path to reach all the packages. The sorting (6) ensures that the sequence of coordinates is non-decreasing in the x- and y-axes, and the robot visits them in the natural order tailored to its freedom of movement.\n",
    "\n",
    "Step (12) evaluates whether the next package in the sequence is reachable by the robot. If only one of the coordinates of the next package in line is smaller than the robot's current position coordinates, the algorithm assigns a ```False``` value to the variable ```possible``` and later prints 'NO' in (25).\n",
    "\n",
    "If all package coordinates are reachable in the sorted order, the algorithm constructs the path as follows:\n",
    "   - For each package coordinate $(x[i], y[i])$, add `R` repeated $ x[i] - \\text{x_current} $ times to move to the right (15)\n",
    "   - Then, add `U` repeated $ y[i] - \\text{y_current} $ times to move upward (16)\n",
    "\n",
    "This process continues for all packages until a complete path is generated from $(0, 0)$ to the final destination.\n",
    "\n",
    "The algorithm correctly identifies and implements a path when it exists because of the sorting step (6), the validity check in (12) and the path construction steps in (15)-(18). These passages enable the robot to traverse the grid and collect packages without backtracking.\n",
    "\n",
    "On the other hand, if a path through all the package coordinates does not exist, this fact will emerge from the check (12). It can happen when, for example, the next package in the sequence is close in x coordinate and high in the y coordinate, but a later package that is next in the x coordinate, has a lower y coordinate. This is because we prioritized horizontal coordinates over vertical ones. Thanks to (12), the algorithm will detect cases like these.\n",
    "\n",
    "**Termination**: The loop iterates through all $n$ packages exactly once, and each reachable package updates ```x_current``` and ```y_current``` without backtracking. Therefore, the algorithm terminates after a finite umber of steps.\n",
    "\n",
    "**Correct Path**: If the algorithm outputs 'YES' and a path, then all packages are reachable following the non-decreasing sequence of ```x``` and ```y``` coordinates. The resulting path ensures each package is visited in sorted order.\n",
    "\n",
    "**Verifying Existence**: If a path crossing all the packages starting from $(0,0)$ and moving only right and up does not exist, the algorithm detects it in the validity check and outputs 'NO'.\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "### Algorithm Complexity\n",
    "\n",
    "Let us look at the algorithm step by step and calculate its complexity.\n",
    "\n",
    "* The algorithm starts with a loop over the test cases (0), so it is executed $t$ times. Therefore, the total running time of the algorithm will be the running time of the operations inside this for loop, times $t$\n",
    "* Afterwards, the algorithm reads $n$, the number of packages (1), and initializes the variable $\\text{packages}$ where the package coordinates will be stored (2). These two operations take constant time $O(1)$\n",
    "* Next, we find a for loop (3) that is executed $n$ times, once for each package whose coordinates need to be read. Reading the coordinates $x[i]$ and $y[i]$ happens in (4), then the coordinates are added to the $\\text{packages}$ array (5). Both (4) and (5) require constant time, and since the for loop is called $n$ times, for a single test case this segment will cost $O(n)$.\n",
    "* Step (6) sorts the package locations by x and y coordinates. This means that the coordinates are primarily sorted by their first entry, and if two locations have the same x coordinate, they will be sorted by their second coordinate. In the worst case, sorting will take $O(2 \\cdot n \\log(n))$, which is equivalent to $O(n \\log(n))$.\n",
    "* Steps (7) and (8) initialize the coordinates of the robot's current location, which initially is $(0,0)$, in $O(1)$ time\n",
    "* Step (9) initializes the $\\text{path}$ string ($O(1)$) where the moves of the robot will be saved, and step (10) initializes a boolean variable $\\text{possible}$ ($O(1)$), 'True' by default, which will be converted to 'False' in case it is not possible to construct the path through all the packages\n",
    "* After this, we have another for loop (11) that iterates over the coordinates in the $packages$ array and is executed at most $n$ times.\n",
    "* The for loop begins with an if loop (12) that checks if the coordinates $x[i]$ and $y[i]$ are out of reach for the robot from its current position. If they are reachable, the algorithm ignores the operations in the if cycle and continues to build the path. If the coordinates are not reachable, the $\\text{possible}$ variable is set to 'False' in (13) ($O(1)$) and the algorithm exits the for loop over the packages (14) ($O(1)$).\n",
    "* In case the coordinate validity check is positive, the algorithm continues to execute lines (15) to (20). Here, it first calculates how many steps the robot has to move right and up to reach the next package ((15) and (16), $O(1)$), then updates the $\\text{path}$ variable to include the new right and up moves ((17) and (18), $O(1)$). Finally, the current position of the robot is set to the current package's coordinates ((19) and (20), $O(1)$). All these operations together require twelve steps, considering addition, multiplication and assignement, so they all take constant time $O(1)$.\n",
    "* This concludes the for loop starting at (11), which executes constant operations at least $n$ times. Therefore, this loop costs $O(n)$ time in total.\n",
    "* At the end, we have an if loop (21) that checks if the $\\text{possible}$ variable is true. If yes, it prints 'YES' (22) and the previously computed $\\text{path}$ (23), requiring constant time $O(1)$. In case $\\text{possible}$ is False, an else block (24) is triggered, printing 'NO' (25). \n",
    "\n",
    "Putting all of this together, we get a worst-case total running time of $O(n\\log(n) + n)$ for each test case. Since $n\\log(n)$ is asymptotically stronger than $n$, we can rewrite this in big-O notation as $O(n\\log(n))$. This is the complexity for one test case. Considering all $t$ test cases, we get $O(t \\cdot n\\log(n))$. The most expensive part is the sorting step at (6), and all other segments are at most linear.\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "### LLM Complexity Evaluation\n",
    "\n",
    "Here is the complexity analysis of the algorithm provided by the LLM ChatGPT:\n",
    "\n",
    "### Step-by-Step Analysis of Time Complexity\n",
    "\n",
    "#### 1. Input Reading and Initialization (Steps 1-2):\n",
    "- Reading $n$ takes $O(1)$.\n",
    "- Initializing the `packages` list takes $O(1)$.\n",
    "\n",
    "#### 2. Reading Package Coordinates (Steps 3-5):\n",
    "- The loop runs $n$ times, and in each iteration:\n",
    "  - Reading $x[i]$ and $y[i]$ takes $O(1)$.\n",
    "  - Adding a tuple to the list takes $O(1)$.\n",
    "- **Total for this loop**: $O(n)$.\n",
    "\n",
    "#### 3. Sorting the Packages (Step 6):\n",
    "- Sorting $n$ elements based on two keys takes $O(n \\log n)$.\n",
    "\n",
    "#### 4. Path Construction and Validation (Steps 11-20):\n",
    "- The loop runs $n$ times, and in each iteration:\n",
    "  - Comparing $x[i]$ and $y[i]$ with `x_current` and `y_current` takes $O(1)$ (Step 12).\n",
    "  - Updating the `path` string involves concatenating strings for right and up moves. Let $k$ represent the total number of moves across all packages. Since $k \\leq n$ in the worst case:\n",
    "    - Adding characters to the string takes $O(k)$ in total.\n",
    "  - Updating `x_current` and `y_current` takes $O(1)$.\n",
    "- **Total for this loop**: $O(n)$.\n",
    "\n",
    "#### 5. Output Result (Steps 21-25):\n",
    "- Printing \"YES\" or \"NO\" and the path involves $O(n)$ for the path string output in the worst case.\n",
    "\n",
    "### Per Test Case Complexity:\n",
    "Summing the complexities for a single test case:\n",
    "- Reading input: $O(n)$\n",
    "- Sorting: $O(n \\log n)$\n",
    "- Path construction: $O(n)$\n",
    "- Outputs: $O(n)$\n",
    "\n",
    "Thus, the total complexity for a single test case is:\n",
    "$ O(n + n \\log n + n) = O(n \\log n)$\n",
    "\n",
    "### Accounting for $t$ Test Cases:\n",
    "With $t$ test cases, the above steps are repeated $t$ times. Therefore, the total complexity is: $O(t \\cdot n \\log n)$\n",
    "\n",
    "### Final Time Complexity:\n",
    "$O(t \\cdot n \\log n)$\n",
    "\n",
    "Both our analysis and the one provided by the LLM reach the same conclusion. The analysis is accurate because we are evaluating the worst-case running times in big-O notations for each test case, and then multiplying them by the number of test cases $t$. For each test case, we have: \n",
    "\n",
    "$O(1)$ (read $n$ and initialize $\\text{packages}$) $+ O(n)$ (read $2\\cdot n$ coordinates) $+O(n\\log(n))$ (sort coordinates) $+O(n)$ (for loop over coordinates with internal constant time operations) $+O(1)$ (final if-else block to print results) $=O(n\\log(n))$\n",
    "\n",
    "For $t$ test cases, this becomes $O(t \\cdot n\\log(n))$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Greedy Algorithm\n",
    "\n",
    "A simplified pseudocode of a greedy algorithm that finds a path to collect all the packages is the following:\n",
    "\n",
    "### $ \\mathbf{GreedyPackageCollector(t)} $\n",
    "\n",
    "(0) $ \\textbf{for text case t} $:\n",
    "    \n",
    "* (1) $ read(n) $\n",
    "* (2) $ \\text{packages} \\leftarrow \\text{[ ]} $\n",
    "* (3) $ \\textbf{for i=1 to n}$: // $ O(n) $\n",
    "    * (4) $ read(x[i]), \\text{read}(y[i]) $\n",
    "    * (5) $ \\text{packages} \\leftarrow \\text{packages} + [(x[i], y[i])] $\n",
    "\n",
    "* (6) $ \\text{x_current} \\leftarrow 0 $\n",
    "* (7) $ \\text{y_current} \\leftarrow 0 $\n",
    "* (8) $ \\text{path} \\leftarrow \\text{''} $\n",
    "\n",
    "* (9) $ \\textbf{while packages} \\neq \\text{[ ]} $: // Continue until all packages are collected\n",
    "  * (10) $ \\text{min_distance} \\leftarrow \\infty $\n",
    "  * (11) $ \\text{closest_package} \\leftarrow \\text{None} $\n",
    "  * (12) $ \\textbf{for (x, y)  in packages} $: // $ O(k) $, where $ k $ is the number of remaining packages\n",
    "    * (13) $ \\text{distance} \\leftarrow |x - \\text{x_current}| + |y - \\text{y_current}| $\n",
    "    * (14) $ \\textbf{if distance} < \\textbf{min_distance} $:\n",
    "      * (15) $ \\text{min_distance} \\leftarrow \\text{distance} $\n",
    "      * (16) $ \\text{closest_package} \\leftarrow (x, y) $\n",
    "  * (17) $ (\\text{x_closest}, \\text{y_closest}) \\leftarrow \\text{closest_package} $\n",
    "  * (18) $ \\text{packages} \\leftarrow \\text{packages} ((\\text{x_closest}, \\text{y_closest})) $\n",
    "  \n",
    "  * (19) $ \\text{num_right_moves} \\leftarrow \\max(0, \\text{x_closest} - \\text{x_current}) $\n",
    "  * (20) $ \\text{num_left_moves} \\leftarrow \\max(0, \\text{x_current} - \\text{x_closest}) $\n",
    "  * (21) $ \\text{num_up_moves} \\leftarrow \\max(0, \\text{y_closest} - \\text{y_current}) $\n",
    "  * (22) $ \\text{num_down_moves} \\leftarrow \\max(0, \\text{y_current} - \\text{y_closest}) $\n",
    "\n",
    "  * (23) $ \\text{path} \\leftarrow \\text{path} + \\text{'R'} \\cdot \\text{num_right_moves} $\n",
    "  * (24) $ \\text{path} \\leftarrow \\text{path} + \\text{'L'} \\cdot \\text{num_left_moves} $\n",
    "  * (25) $ \\text{path} \\leftarrow \\text{path} + \\text{'U'} \\cdot \\text{num_up_moves} $\n",
    "  * (26) $ \\text{path} \\leftarrow \\text{path} + \\text{'D'} \\cdot \\text{num_down_moves} $\n",
    "\n",
    "  * (27) $ \\text{x_current} \\leftarrow \\text{x_closest} $\n",
    "  * (28) $ \\text{y_current} \\leftarrow \\text{y_closest} $\n",
    "\n",
    "* (29) $ output(\\text{path}) $\n",
    "\n",
    "$ \\textbf{end for} $\n",
    "\n",
    "\n",
    "This algorithm uses a greedy approach to move to the packages that are currently closest, minimizing the Manhattan distance at each step. It always calculates a path that includes all the packages because it can move in every direction, but the distance travelled is not always optimal.\n",
    "\n",
    "We can consider this counterexample: suppose the robot starts at position $(0,0)$ and the packages are distributed in these cells: $p_1:(1,0)$, $p_2:(2,0)$, $p_3:(3,0)$, $p_4:(4,0)$, $p_5: (5,0)$, $p_6: (6,0)$, $p_7: (7,0)$ and $p_8: (0,2)$. Initially, the algorithms calculates the distances between the robot and each package, and finds that the closest package is $p_1$, so it moves to $(1,0)$. After this, the algorithm searches for the next closest neighbour, which is $p_2$. Following the algorithm's logic, the robot will continue to collect packages $p_3$ to $p_7$ in order, and finally $p_8$.\n",
    "\n",
    "The total distance that the robot travels using the greedy approach in this scenario is 16 units (1 unit = length of a square in the grid), because it takes the path 'RRRRRRRLLLLLLLUU'. However, if the robot would have first visited package $p_2$, which initially was not the closest package, and then all the others in order, it would only have travelled a distance of 11 units along the path 'UUDDRRRRRRR'.\n",
    "\n",
    "The plot below illustrates this specific case of the problem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Coordinates\n",
    "packages = [(1, 0), (2, 0), (3, 0), (4,0), (5,0), (6,0), (7, 0), (0, 2)]\n",
    "x_coords, y_coords = zip(*packages)\n",
    "robot = (0,0)\n",
    "\n",
    "# Plot points\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.scatter(x_coords, y_coords, color='blue', label='Points')\n",
    "plt.scatter(robot[0], robot[1], color='red', label='Robot', marker='x')\n",
    "\n",
    "# Add labels to points\n",
    "for x, y in packages:\n",
    "    plt.text(x + 0.1, y + 0.1, f\"({x},{y})\", fontsize=9)\n",
    "plt.text(0.1, 0.1, \"Robot\", fontsize=9)\n",
    "\n",
    "# Set plot limits for better visualization\n",
    "plt.xlim(-1, max(x_coords) + 2)\n",
    "plt.ylim(-1, max(y_coords) + 2)\n",
    "\n",
    "# Adjust plot\n",
    "plt.gca().set_aspect('equal', adjustable='box')\n",
    "\n",
    "# Add grid and labels\n",
    "plt.axhline(0, color='black', linewidth=0.5, linestyle='--')\n",
    "plt.axvline(0, color='black', linewidth=0.5, linestyle='--')\n",
    "plt.grid(color='gray', linestyle='--', linewidth=0.5, alpha=0.7)\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "plt.grid(True)\n",
    "plt.xticks(range(1, 9))\n",
    "plt.title('Robot in the Warehouse')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "The following code implements the PackageCollector algorithm explained in the first three points:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PackageCollector(t):\n",
    "    '''\n",
    "    Function that determines if a path traversing all the packages exists, and if it does, it outputs that path\n",
    "    Input:\n",
    "    t = number of test cases\n",
    "    Output:\n",
    "    None\n",
    "    '''\n",
    "    for _ in range(t):  # Loop over each test case\n",
    "        n = int(input())  # Read the number of packages\n",
    "        packages = []\n",
    "\n",
    "        # Read packages\n",
    "        for i in range(n):\n",
    "            x, y = map(int, input().split())  # Read coordinates of the i-th package\n",
    "            packages.append((x, y))\n",
    "\n",
    "        packages = sorted(packages)  # Sort packages by x and y coordinates\n",
    "\n",
    "        # Initializations\n",
    "        x_current = 0  # current x-coordinate (starting at (0, 0))\n",
    "        y_current = 0  # current y-coordinate (starting at (0, 0))\n",
    "        path = \"\"  # initialize path\n",
    "        possible = True  # True by default, turns False if a path is not possible\n",
    "\n",
    "        for i in range(n):\n",
    "            x, y = packages[i]\n",
    "\n",
    "            if x < x_current or y < y_current: # check if package is reacheable\n",
    "                possible = False  # cannot reach this package if it's behind in x or y\n",
    "                break\n",
    "\n",
    "            # Calculate the number of right and up moves\n",
    "            num_right_moves = x - x_current\n",
    "            num_up_moves = y - y_current\n",
    "            \n",
    "            path += 'R' * num_right_moves # Add the right moves to the path\n",
    "            path += 'U' * num_up_moves # Add the up moves to the path\n",
    "\n",
    "            # Update the current position to the current package's coordinates\n",
    "            x_current = x\n",
    "            y_current = y\n",
    "\n",
    "        # Output results based on whether the path is possible\n",
    "        if possible:\n",
    "            print(\"YES\")\n",
    "            print(path)\n",
    "        else:\n",
    "            print(\"NO\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we test the algorithm on a specific set of inputs:\n",
    "\n",
    "3\n",
    "\n",
    "5\n",
    "\n",
    "1 3\n",
    "\n",
    "1 2\n",
    "\n",
    "3 3\n",
    "\n",
    "5 5\n",
    "\n",
    "4 3\n",
    "\n",
    "2\n",
    "\n",
    "1 0\n",
    "\n",
    "0 1\n",
    "\n",
    "1\n",
    "\n",
    "4 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = int(input())  # Number of test cases\n",
    "PackageCollector(t)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
